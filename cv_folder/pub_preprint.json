{
  "config": {
    "id": "36a3b0b5-bad0-4a04-b79b-441c7cef77db",
    "label": "BetterBibTeX JSON",
    "preferences": {
      "ascii": "",
      "asciiBibLaTeX": true,
      "asciiBibTeX": true,
      "autoAbbrev": false,
      "autoExport": "immediate",
      "autoExportDelay": 2,
      "autoExportIdleWait": 10,
      "autoExportPathReplaceDiacritics": false,
      "autoExportPathReplaceDirSep": "-",
      "autoExportPathReplaceSpace": " ",
      "automaticTags": false,
      "autoPinDelay": 0,
      "auxImport": false,
      "baseAttachmentPath": "",
      "biblatexExtendedDateFormat": true,
      "biblatexExtendedNameFormat": true,
      "biblatexExtractEprint": true,
      "biblatexUsePrefix": true,
      "bibtexEditionOrdinal": false,
      "bibtexParticleNoOp": false,
      "bibtexURL": "off",
      "cache": true,
      "cacheDelete": false,
      "charmap": "",
      "chinese": false,
      "chineseSplitName": true,
      "citeCommand": "cite",
      "citekeyCaseInsensitive": true,
      "citekeyFold": true,
      "citekeyFormat": "auth.fold.lower + year + shorttitle(1, 1).lower",
      "citekeySearch": true,
      "citekeyUnsafeChars": "\\\"#%'(),={}~",
      "csquotes": "",
      "DOIandURL": "doi",
      "exportBibTeXStrings": "off",
      "exportBraceProtection": true,
      "exportSort": "citekey",
      "exportTitleCase": true,
      "extraMergeCitekeys": true,
      "extraMergeCSL": true,
      "extraMergeTeX": true,
      "git": "config",
      "import": true,
      "importBibTeXStrings": true,
      "importCaseProtection": "as-needed",
      "importCitationKey": true,
      "importDetectURLs": true,
      "importExtra": true,
      "importJabRefAbbreviations": true,
      "importJabRefStrings": true,
      "importNoteToExtra": "",
      "importPlaceEvent": "inproceedings,conference,presentation,talk",
      "importSentenceCase": "on+guess",
      "importSentenceCaseQuoted": true,
      "importUnknownTexCommand": "ignore",
      "itemObserverDelay": 5,
      "jabrefFormat": 0,
      "japanese": false,
      "keyConflictPolicy": "change",
      "keyScope": "library",
      "language": "language",
      "mapMath": "",
      "mapText": "",
      "packages": "",
      "parseParticles": true,
      "patchDates": "dateadded=dateAdded, date-added=dateAdded, datemodified=dateModified, date-modified=dateModified",
      "postscript": "if (Translator.BetterBibTeX && zotero.itemType === 'journalArticle') {\n  tex.remove('doi');\n}\n\nif (Translator.BetterTeX && zotero.arXiv && zotero.itemType !== 'conferencePaper' && zotero.itemType !== 'journalArticle') {\n  tex.add({name: 'journal', bibtex: '{arXiv preprint arXiv:' + zotero.arXiv.id + '}'});\n  tex.remove('doi');\n  tex.entrytype = 'article';\n}\n\nif (zotero.creators && zotero.creators.length > 6) {\n  let authors = zotero.creators.slice(0, 6).map(author => {\n    return author.lastName ? author.lastName : author.name;\n  });\n  authors.push('et al.');\n  tex.add({ name: 'author', bibtex: '{' + authors.join(' and ') + '}' });\n}",
      "postscriptOverride": "",
      "preferencesOverride": "",
      "qualityReport": false,
      "quickCopyEta": "Users:\n<ul>\n\n</ul>",
      "quickCopyMode": "citekeys",
      "quickCopyOrgMode": "citationkey",
      "quickCopyPandocBrackets": false,
      "quickCopySelectLink": "zotero",
      "rawImports": false,
      "rawLaTag": "#LaTeX",
      "relativeFilePaths": false,
      "separatorList": "and",
      "separatorNames": "and",
      "skipFields": "file, keywords, shorttitle, annotation, number, month, ISSN",
      "skipWords": "a,ab,aboard,about,above,across,after,against,al,along,amid,among,an,and,anti,around,as,at,before,behind,below,beneath,beside,besides,between,beyond,but,by,d,da,das,de,del,dell,dello,dei,degli,della,dell,delle,dem,den,der,des,despite,die,do,down,du,during,ein,eine,einem,einen,einer,eines,el,en,et,except,for,from,gli,i,il,in,inside,into,is,l,la,las,le,les,like,lo,los,near,nor,of,off,on,onto,or,over,past,per,plus,round,save,since,so,some,sur,than,the,through,to,toward,towards,un,una,unas,under,underneath,une,unlike,uno,unos,until,up,upon,versus,via,von,while,with,within,without,yet,zu,zum",
      "startupProgress": "popup",
      "strings": "",
      "stringsOverride": "",
      "verbatimFields": "url,doi,file,pdf,ids,eprint,/^verb[a-z]$/,groups,/^citeulike-linkout-[0-9]+$/, /^bdsk-url-[0-9]+$/, keywords",
      "warnBulkModify": 10,
      "warnTitleCased": false
    },
    "options": {
      "Items": true,
      "Normalize": false,
      "Preferences": true,
      "exportFileData": false,
      "exportNotes": true,
      "keepUpdated": true,
      "worker": true,
      "exportDir": "/Users/zengh/PAR/Resource/L04 Profile 个人档案/academic_personal_website/zenghao-stat.github.io/cv_folder",
      "exportPath": "/Users/zengh/PAR/Resource/L04 Profile 个人档案/academic_personal_website/zenghao-stat.github.io/cv_folder/pub_preprint.json"
    }
  },
  "version": {
    "zotero": "7.0.29",
    "bbt": "7.0.67"
  },
  "collections": {},
  "items": [
    {
      "key": "2XTNQABP",
      "version": 44331,
      "itemType": "journalArticle",
      "title": "Match of the bimaxillary basal bone arches and its variations among individuals",
      "abstractNote": "Introduction. This study is aimed at illustrating the bimaxillary basal bone contours, to clarify the match of the basal bone arches of the upper and lower, especially the posterior segments, including the second molar and retromolar region. Methods. Based on 100 cone-beam computed tomography (CBCT) images (50 males and 50 females), we obtained 100 pairs of basal bone arches, which were the horizontal inner cortex contours passing the furcation of the first molar paralleled to the lower occlusal plane. The Generalized Procrustes Analysis (GPA) was applied to depict average contours and calculate the ratio and difference width of both upper and lower dental arches in different positions. Variations of the basal bone morphology among individuals were revealed using Principal Component Analysis (PCA). Results. The width discrepancy occurred at 7-7 segment (male: upper 65.62 mm and lower 68.81 mm and female: upper 62.98 mm and lower 68.38 mm) and the retromolar region (male: upper 64.67 mm and lower 71.96 mm and female: upper 62.34 mm and lower 71.44 mm). The ratio (p = 0.006) and difference value (p = 0.009) of 7-7 segment and the ratio of retromolar region (p = 0.044) differed in genders. Setting 2 mm overjet, the upper basal bone arch was wider than the lower by approximate 2 mm on both sides, except the second molar and retromolar region. According to PCA, the variation of basal bone arches appeared mainly at terminal segments. Conclusions. For both male and female, the bimaxillary basal bone matched except terminal segments. Mismatch of female bimaxillary posterior basal bone was more pronounced than male. The basal bone arches of male were wider and longer than that of female.",
      "date": "2021-11-05",
      "language": "en",
      "libraryCatalog": "Wiley Online Library",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/9625893",
      "accessDate": "2024-12-19T03:24:01Z",
      "rights": "Copyright © 2021 Wenqian Chen et al.",
      "extra": "GSCC: 0000001 2025-10-19T06:08:52.046Z 0.00 \n_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1155/2021/9625893\nTLDR: For both male and female, the bimaxillary basal bone matched except terminal segments, and the basal bone arches of male were wider and longer than that of female.",
      "volume": "2021",
      "pages": "9625893",
      "publicationTitle": "Scanning",
      "DOI": "10.1155/2021/9625893",
      "issue": "1",
      "ISSN": "1932-8745",
      "creators": [
        {
          "firstName": "Wenqian",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Luna",
          "lastName": "Sun",
          "creatorType": "author"
        },
        {
          "firstName": "Qiuping",
          "lastName": "Xu",
          "creatorType": "author"
        },
        {
          "firstName": "Zhenxue",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Yunhan",
          "lastName": "Sun",
          "creatorType": "author"
        },
        {
          "firstName": "Qi",
          "lastName": "Jia",
          "creatorType": "author"
        },
        {
          "firstName": "Chengyun",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Jing",
          "lastName": "Guo",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "inPublications": true,
      "dateAdded": "2024-12-19T03:24:01Z",
      "dateModified": "2025-10-19T06:08:52Z",
      "uri": "http://zotero.org/users/4752290/items/2XTNQABP",
      "itemID": 4260,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Full Text PDF",
          "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1155/2021/9625893",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-12-19T03:24:04Z",
          "dateModified": "2024-12-19T03:24:04Z",
          "uri": "http://zotero.org/users/4752290/items/E9AZQJLS",
          "path": "/Users/zengh/Zotero/storage/E9AZQJLS/2021 - Chen et al. - Match of the Bimaxillary Basal Bone Arches and Its Variations among Individuals.pdf",
          "select": "zotero://select/library/items/E9AZQJLS"
        },
        {
          "itemType": "attachment",
          "title": "Snapshot",
          "url": "https://onlinelibrary.wiley.com/doi/full/10.1155/2021/9625893",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-12-19T03:24:07Z",
          "dateModified": "2024-12-19T03:24:07Z",
          "uri": "http://zotero.org/users/4752290/items/GKLB5CJ7",
          "path": "/Users/zengh/Zotero/storage/GKLB5CJ7/9625893.html",
          "select": "zotero://select/library/items/GKLB5CJ7"
        }
      ],
      "notes": [
        {
          "key": "LN5HNBTX",
          "version": 45341,
          "itemType": "note",
          "parentItem": "2XTNQABP",
          "note": "<h2>AI 管家 - Match of the bimaxillary basal bone arches and its variations among individuals</h2>\n<div><p>好的，这是对该学术文章的中文总结。</p>\n<h3>0. 标题、作者、摘要及贡献总结</h3>\n<ul>\n<li><strong>标题 (英文)</strong>: Match of the Bimaxillary Basal Bone Arches and Its Variations among Individuals</li>\n<li><strong>作者信息</strong>: Wenqian Chen, Hao Zeng, Luna Sun, Qiuping Xu, Zhenxue Chen, Yunhan Sun, Qi Jia, Chengyun Liu, and Jing Guo</li>\n<li><strong>摘要总结</strong>: 该研究旨在阐明上、下颌基骨弓的轮廓及其匹配关系，特别关注包括第二磨牙和磨牙后区的后段区域。研究基于100例锥形束CT（CBCT）图像（50名男性，50名女性），定义并通过广义普氏分析（GPA）来描绘平均基骨弓形态，计算并比较了上、下颌在不同位置的宽度比和宽度差。同时，使用主成分分析（PCA）揭示了个体间基骨弓形态的变异。研究发现，在第二磨牙和磨牙后区存在明显的宽度不匹配，且这种不匹配在性别间存在差异，女性比男性更显著。PCA结果显示，基骨弓形态的主要变异发生在末端区域。</li>\n<li><strong>一句话贡献和创新</strong>: 本文首次使用广义普氏分析（GPA）和主成分分析（PCA）对包含舌侧和磨牙后区的完整双颌基骨弓轮廓进行了定量形态学分析，揭示了基骨弓在后段存在固有的横向不匹配，且其变异主要发生在后部区域。</li>\n</ul>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><strong>基本任务</strong>: 本文的核心任务是定量分析和比较上颌（maxillary）与下颌（mandibular）基骨弓的形态、尺寸及其匹配性，并探究这些特征在不同性别和个体间的差异。</li>\n<li><strong>模型设定</strong>:<ul>\n<li><strong>解剖学模型</strong>: 研究将“基骨弓”定义为一个二维轮廓，即“在平行于下颌咬合平面的水平面上，穿过第一磨牙根分叉处的内侧骨皮质轮廓”。这个定义将一个三维解剖结构简化为一个标准化的二维几何形状以便于分析。</li>\n<li><strong>数学模型</strong>: 采用基于界标点（landmarks）的几何形态测量学（Geometric Morphometrics）模型。每个基骨弓轮廓被表示为一组有序的二维坐标点（上颌80个，下颌72个），这些点的集合在数学上定义了该基骨弓的形状。</li>\n</ul>\n</li>\n<li><strong>问题示例</strong>:<ul>\n<li><strong>数据</strong>: 一位年轻成年人的头部锥形束CT（CBCT）三维扫描影像。</li>\n<li><strong>任务</strong>:<ol>\n<li>在CBCT影像中，根据解剖标志点校正头部姿态，确定标准化的水平切面（穿过第一磨牙根分叉）。</li>\n<li>在该水平切面上，分别描绘出上颌和下颌的内侧骨皮质轮廓。</li>\n<li>在轮廓上标记出预设的界标点（如上颌80个点），获得这些点的二维坐标 <span class=\"math\">$L_i^U = (x_i, y_i), i=1, \\dots, 80$</span> 和 <span class=\"math\">$L_j^L = (x_j, y_j), j=1, \\dots, 72$</span>。</li>\n<li>对来自100个个体的数据集进行统计分析，以回答“上、下颌基骨弓的平均形状是什么样的？”、“它们在后牙区域是否匹配？”、“男性和女性的基骨弓有何不同？”等问题。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法</h3>\n<p>本文主要使用了两种经典的几何形态测量与统计分析方法：</p>\n<ul>\n<li><strong>广义普氏分析 (Generalized Procrustes Analysis, GPA)</strong>: GPA用于消除非形状因素（位置、大小、旋转）的干扰，从而提取并对齐所有样本的纯粹形状信息，并计算出平均形状。<ul>\n<li>数学表达: 对于<span class=\"math\">$N$</span>个样本，每个样本的形状由<span class=\"math\">$k$</span>个界标点的坐标矩阵 <span class=\"math\">$X_i \\in \\mathbb{R}^{k \\times 2}$</span> 表示。GPA旨在通过寻找最优的平移向量<span class=\"math\">$t_i$</span>、缩放因子<span class=\"math\">$s_i$</span>和旋转矩阵<span class=\"math\">$R_i$</span>，最小化所有形状到其平均形状<span class=\"math\">$\\bar{X}$</span>的距离平方和。目标函数为：\n<pre class=\"math\">$$\n    \\min_{t_i, s_i, R_i, \\bar{X}} \\sum_{i=1}^N || s_i X_i R_i + \\mathbf{1}t_i^T - \\bar{X} ||_F^2\n    $$</pre>\n其中 <span class=\"math\">$|| \\cdot ||_F$</span> 是弗罗贝尼乌斯范数，<span class=\"math\">$\\mathbf{1}$</span>是全1列向量。通过迭代算法求解，最终得到所有对齐后的形状及平均形状<span class=\"math\">$\\bar{X}$</span>。</li>\n</ul>\n</li>\n<li><strong>主成分分析 (Principal Component Analysis, PCA)</strong>: 在GPA对齐所有形状后，PCA被用来分析形状的主要变异模式。它将高维的形状空间进行降维，找到方差最大的几个方向，即主成分（PCs）。<ul>\n<li>数学表达: 将GPA对齐后的<span class=\"math\">$N$</span>个形状向量化，构成一个数据矩阵<span class=\"math\">$A \\in \\mathbb{R}^{N \\times 2k}$</span>。对<span class=\"math\">$A$</span>进行中心化后，计算其协方差矩阵<span class=\"math\">$C$</span>：\n<pre class=\"math\">$$\n    C = \\frac{1}{N-1} A'^T A'\n    $$</pre>\n通过对<span class=\"math\">$C$</span>进行特征值分解 <span class=\"math\">$C v_j = \\lambda_j v_j$</span>，得到特征向量<span class=\"math\">$v_j$</span>（即主成分PC）和特征值<span class=\"math\">$\\lambda_j$</span>（表示在该方向上的方差）。任何一个개体的形状<span class=\"math\">$X_{ind}$</span>都可以由平均形状<span class=\"math\">$\\bar{X}$</span>和主成分的线性组合来近似表示：\n<pre class=\"math\">$$\n    X_{ind} \\approx \\bar{X} + \\sum_{j=1}^p \\alpha_j v_j\n    $$</pre>\n其中<span class=\"math\">$\\alpha_j$</span>是该个体在第<span class=\"math\">$j$</span>个主成分上的得分。</li>\n</ul>\n</li>\n</ul>\n<h3>3. 理论与效果</h3>\n<ul>\n<li><strong>方法有效性</strong>:<ul>\n<li>GPA的有效性在于它能客观地分离形状和非形状变异。在比较解剖结构时，我们关心的是其几何外形，而不是它在扫描图像中的位置或绝对大小。GPA通过最小二乘法对齐，提供了比较纯粹形状的基础。</li>\n<li>PCA的有效性在于它能将复杂的、多维度的形状差异简化为几个主要的、可解释的变异模式。例如，PC1可能代表整体的“宽窄”变化，PC2可能代表后部的“开合”变化，这使得理解群体内的形态差异变得直观。</li>\n</ul>\n</li>\n<li><strong>理论保证</strong>:<ul>\n<li><strong>GPA</strong>: GPA的理论保证是，它能在最小二乘意义下找到一组形状的最佳对齐方式，使得对齐后样本间的普氏距离（Procrustes distance）总和最小，从而得到最具代表性的平均形状。</li>\n<li><strong>PCA</strong>: PCA的理论保证是，其找到的主成分是相互正交的单位向量，并且每个主成分都指向数据方差最大的方向。前<span class=\"math\">$p$</span>个主成分张成的子空间是所有<span class=\"math\">$p$</span>维子空间中，能够以最小均方误差重构原始数据的最优子空间。</li>\n</ul>\n</li>\n<li><strong>理论贡献</strong>:<ul>\n<li>本文的理论贡献不在于提出新的数学理论，而在于将成熟的几何形态测量学理论（GPA和PCA）创新性地应用于一个具体的口腔解剖学问题——对完整的双颌基骨弓形态进行量化分析。</li>\n<li>它提供了一个数学框架来验证和量化一个临床观察：上、下颌牙弓在后段可能不协调。通过数学化地定义“不匹配”（如宽度差 <span class=\"math\">$W_{upper}-W_{lower}$</span> 和宽度比 <span class=\"math\">$W_{upper}/W_{lower}$</span>），并将形状变异分解为主成分，研究将模糊的形态学描述转化为了精确的、可检验的科学结论。</li>\n</ul>\n</li>\n</ul>\n<h3>4. 算法</h3>\n<p>本文所用算法即GPA和PCA的计算流程。</p>\n<ul>\n<li><strong>GPA 算法</strong>:<ol>\n<li><strong>初始化</strong>: 随机选择一个样本 <span class=\"math\">$X_1$</span> 作为初始的平均形状 <span class=\"math\">$\\bar{X}^{(0)}$</span>。</li>\n<li><strong>对齐</strong>: 将所有样本 <span class=\"math\">$X_i$</span> (包括 <span class=\"math\">$X_1$</span>) 通过平移、旋转和缩放，使其与当前的平均形状 <span class=\"math\">$\\bar{X}^{(t)}$</span> 对齐（即普氏叠合）。</li>\n<li><strong>更新平均形状</strong>: 将所有对齐后的样本取算术平均，得到新的平均形状 <span class=\"math\">$\\bar{X}^{(t+1)}$</span>。</li>\n<li><strong>迭代</strong>: 重复步骤2和3，直到平均形状的变化小于一个预设的阈值，算法收敛。</li>\n</ol>\n</li>\n<li><strong>PCA 算法</strong>:<ol>\n<li><strong>数据准备</strong>: 使用GPA算法对所有样本的界标点数据进行对齐。</li>\n<li><strong>中心化</strong>: 将每个样本的向量化坐标减去所有样本的平均坐标，得到中心化数据矩阵<span class=\"math\">$A'$</span>。</li>\n<li><strong>计算协方差矩阵</strong>: 计算 <span class=\"math\">$C = \\frac{1}{N-1}A'^T A'$</span>。</li>\n<li><strong>特征分解</strong>: 对协方差矩阵<span class=\"math\">$C$</span>进行特征分解，得到按大小排序的特征值 <span class=\"math\">$\\lambda_1 \\ge \\lambda_2 \\ge \\dots$</span> 及其对应的特征向量 <span class=\"math\">$v_1, v_2, \\dots$</span>（即主成分）。</li>\n<li><strong>结果分析</strong>: 分析前几个主成分（如PC1, PC2, PC3）所代表的形状变化模式，例如通过可视化平均形状 <span class=\"math\">$\\bar{X} \\pm \\text{sd} \\cdot v_j$</span> 来展示。</li>\n</ol>\n</li>\n</ul>\n<h3>5. 实验设计与结果</h3>\n<ul>\n<li><strong>实验设计</strong>:<ol>\n<li><strong>样本</strong>: 选取了100名牙列完整的年轻成年人（50男，50女）的CBCT影像数据。</li>\n<li><strong>数据采集与处理</strong>: 对每份CBCT影像进行三维重建和姿态校正。在标准化的水平切面上，手动标注上、下颌基骨弓轮廓的界标点。</li>\n<li><strong>分组比较</strong>: 将100个样本按性别分为两组（男性组和女性组）。</li>\n<li><strong>平均形态与匹配性分析</strong>: 对每组分别使用GPA计算平均的上、下颌基骨弓形状。测量并比较从门牙到磨牙后区不同位置的宽度，计算上/下颌宽度比和宽度差，并用t检验分析这些指标在性别间的差异是否显著。</li>\n<li><strong>变异模式分析</strong>: 对每个亚组（如男性上颌、男性下颌等）的对齐后数据进行PCA分析，找出导致个体形态差异的主要因素，并观察这些变异主要发生在基骨弓的哪个部位。</li>\n</ol>\n</li>\n<li><strong>实验结果</strong>:<ul>\n<li><strong>性别差异</strong>: 总体上，男性的基骨弓比女性的更宽、更长。</li>\n<li><strong>双颌匹配性</strong>: 从前牙区到第一磨牙区，上颌基骨弓均比下颌宽（这是正常覆盖关系的基础）。然而，在后段，即<strong>第二磨牙及磨牙后区，情况发生逆转，上颌基骨弓反而比下颌窄</strong>，形成了明显的横向不匹配。</li>\n<li><strong>不匹配的性别差异</strong>: 这种后段的不匹配在<strong>女性中比男性更严重</strong>。例如，女性在第二磨牙区的上下颌宽度差的绝对值（上颌减下颌为负值）显著大于男性。</li>\n<li><strong>个体变异来源</strong>: PCA分析显示，无论男性还是女性，基骨弓形态的<strong>主要个体差异都集中在末端区域（即磨牙后区）</strong>。相比之下，前牙区的形态在个体间则相对稳定。</li>\n</ul>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:06:23Z",
          "dateModified": "2025-11-06T07:06:23Z",
          "uri": "http://zotero.org/users/4752290/items/LN5HNBTX"
        }
      ],
      "citationKey": "chen2021match",
      "itemKey": "2XTNQABP",
      "libraryID": 1,
      "select": "zotero://select/library/items/2XTNQABP"
    },
    {
      "key": "9Z8M5844",
      "version": 44332,
      "itemType": "journalArticle",
      "title": "A structural equation modeling approach to determine the correlation between the vertical and sagittal skeletal patterns and posterior basal bones mismatching in patients with skeletal Class III malocclusion",
      "abstractNote": "Introduction: Matching the maxillomandibular basal bone width is essential to the stability of orthodontic treatment. We aimed to determine the relationship between basal bone width mismatching and the vertical and sagittal skeletal pattern in patients with skeletal Class III malocclusion through shape analysis and structural equation modeling (SEM). Methods: Cone-beam computed tomography images were collected from 45 men and 51 women. Width mismatching of the basal bone was determined using generalized Procrustes analysis. Twenty-two parameters from the synthesized cephalogram were measured, followed by factor analysis and SEM. Results: Mismatch occurred at the second molar (men, 4.29 6 4.32 mm; women, 5.55 6 4.43 mm) and retromolar regions (men, 8.49 6 5.11 mm; women: 8.93 6 5.25 mm). The sum of angles had the largest loading for vertical-1 (extracted from 18 vertical cephalometric measurements) (men, 0.9477; women, 0.9489), followed by MP-SN angle (0.9408) in men and N-Me/S-Go (0.9342) in women. Wits appraisal and anteroposterior dysplasia indicator were largest for Sagittal-1. SEM showed a positive effect of male vertical-1 and 2 on width difference in the retromolar region (P \\0.001; B .0). Female vertical-1 had a significant positive effect on DW7 (P \\0.001; B 5 5.535) and DWR (P 5 0.016; B 5 3.427) as vertical-2. Sagittal-1 showed a negative correlation with DW7 in both genders (P \\0.05; B \\0) and with DWR in men. Conclusions: Basal bone width mismatching occurred at the second molar and retromolar regions, especially in low-angle and patients with severe skeletal Class III malocclusion.",
      "date": "2022-12-28",
      "language": "en",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S088954062200542X",
      "accessDate": "2024-12-15T08:46:34Z",
      "extra": "GSCC: 0000003 2025-10-19T06:08:57.873Z 0.02 \nTLDR: Basal bone width mismatching occurred at the second molar and retromolar regions, especially in low-angle and patients with severe skeletal Class III malocclusion.",
      "volume": "162",
      "pages": "e277-e294",
      "publicationTitle": "American Journal of Orthodontics and Dentofacial Orthopedics",
      "DOI": "10.1016/j.ajodo.2022.08.015",
      "issue": "6",
      "ISSN": "08895406",
      "creators": [
        {
          "firstName": "Wenqian",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Xiaoya",
          "lastName": "Wang",
          "creatorType": "author"
        },
        {
          "firstName": "Qiuping",
          "lastName": "Xu",
          "creatorType": "author"
        },
        {
          "firstName": "Panpan",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Liwei",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Yingyue",
          "lastName": "Hou",
          "creatorType": "author"
        },
        {
          "firstName": "Qing",
          "lastName": "Luo",
          "creatorType": "author"
        },
        {
          "firstName": "Xueye",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Zhe",
          "lastName": "Jiang",
          "creatorType": "author"
        },
        {
          "firstName": "Zhiyuan",
          "lastName": "Zhou",
          "creatorType": "author"
        },
        {
          "firstName": "Jiang",
          "lastName": "Chen",
          "creatorType": "author"
        },
        {
          "firstName": "Jing",
          "lastName": "Guo",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "inPublications": true,
      "dateAdded": "2024-12-15T08:46:34Z",
      "dateModified": "2025-10-19T06:08:57Z",
      "uri": "http://zotero.org/users/4752290/items/9Z8M5844",
      "itemID": 4248,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "2022 - Chen et al. - A structural equation modeling approach to determine the correlation between the vertical and sagittal skeletal patterns and posterior basal bones mismatching in patients with skeletal Class III maloc.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-12-15T08:46:27Z",
          "dateModified": "2024-12-15T14:39:25Z",
          "uri": "http://zotero.org/users/4752290/items/4JYVZZD5",
          "path": "/Users/zengh/Zotero/storage/4JYVZZD5/2022 - Chen et al. - A structural equation modeling approach to determine the correlation between the vertical and sagittal skeletal patterns and posterior basal bones mismatching in patients with skeletal Class III maloc.pdf",
          "select": "zotero://select/library/items/4JYVZZD5"
        },
        {
          "itemType": "attachment",
          "title": "siyuan://blocks/20241215221044-ngu0008",
          "url": "siyuan://blocks/20241215221044-ngu0008",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-12-15T14:10:44Z",
          "dateModified": "2025-03-26T15:01:16Z",
          "uri": "http://zotero.org/users/4752290/items/V8NJ5FMZ",
          "select": "zotero://select/library/items/V8NJ5FMZ"
        }
      ],
      "notes": [
        {
          "key": "RYTFBTQW",
          "version": 45342,
          "itemType": "note",
          "parentItem": "9Z8M5844",
          "note": "<h2>AI 管家 - A structural equation modeling approach to determine the correlation between the vertical and sagitt...</h2>\n<div><p>好的，这是对这篇文章的简洁易懂且数学化的中文总结。</p>\n<h3>0. 标题：原文标题、作者信息及其摘要中文总结；一句话总结贡献和创新</h3>\n<ul>\n<li><strong>标题 (英文)</strong>: A structural equation modeling approach to determine the correlation between the vertical and sagittal skeletal patterns and posterior basal bones mismatching in patients with skeletal Class III malocclusion</li>\n<li><strong>作者</strong>: Wenqian Chen, Hao Zeng, Xiaoya Wang 等。</li>\n<li><strong>摘要总结</strong>: 本文旨在通过形态学分析和结构方程模型（SEM）方法，探究骨性III类错颌畸形患者的基骨宽度不匹配与垂直向、矢状向骨骼模式之间的关系。研究收集了96名（45男，51女）患者的锥形束CT（CBCT）数据，使用广义普氏分析（GPA）确定基骨宽度不匹配程度，并通过因子分析与SEM分析了22个头影测量参数。结果发现，宽度不匹配主要发生在第二磨牙和磨牙后区。SEM结果显示，垂直向骨骼模式对后牙区宽度不匹配有显著正向影响（即低角型患者不匹配更严重），而矢状向骨骼模式有显著负向影响（即III类错颌越严重，不匹配也越严重）。</li>\n<li><strong>贡献与创新</strong>: <strong>本文首次使用结构方程模型（SEM）系统地量化了骨性III类错颌患者复杂的骨骼模式（作为潜在变量）与后牙区基骨宽度不匹配（作为观测变量）之间的相关性。</strong></li>\n</ul>\n<hr>\n<h3>1. 这篇文章的基本任务是什么？是在什么模型下设定的？给出问题的简单例子。（任务和模型）</h3>\n<ul>\n<li><strong>基本任务</strong>: 本研究的核心任务是<strong>量化并确定骨性III类错颌畸形患者的两种面部骨骼特征与其上下颌骨后部宽度不匹配程度之间的相关关系</strong>。这两种特征是：<ol>\n<li><strong>垂直向骨骼模式 (Vertical skeletal pattern)</strong>：即面部的高低角型（长脸/方脸）。</li>\n<li><strong>矢状向骨骼模式 (Sagittal skeletal pattern)</strong>：即“地包天”的严重程度。</li>\n</ol>\n</li>\n<li><strong>模型设定</strong>: 研究是在一个<strong>基于临床观测数据的统计模型</strong>下进行的。它假设患者的多种头影测量指标（如面角、面高等）可以归纳为几个无法直接测量的“潜在因子”（即垂直向和矢状向模式），而这些潜在因子会影响可直接测量的“观测变量”（即上下颌骨在后牙区的宽度差异）。</li>\n<li><strong>简单例子</strong>:<ul>\n<li><strong>数据</strong>: 医生为一名骨性III类错颌患者 A 拍摄了CBCT。通过CBCT数据，我们可以得到：<ol>\n<li><strong>宽度不匹配数据</strong>: 在第二磨牙位置，测量出其上颌骨宽度为62mm，下颌骨宽度为67mm。则宽度不匹配值 <span class=\"math\">$DW_7 = 62 - 67 = -5$</span> mm。负值表示下颌比上颌宽。</li>\n<li><strong>骨骼模式数据</strong>: 从该患者的头颅侧位片中测量出一系列角度，例如下颌平面角 <span class=\"math\">$MP-SN = 25^\\circ$</span>（这是一个低角型指标）。</li>\n</ol>\n</li>\n<li><strong>任务</strong>: 研究的问题就是，是否像患者A这样具有低 <span class=\"math\">$MP-SN$</span> 值的“低角型”患者，其 <span class=\"math\">$DW_7$</span> 的负值普遍会更大（即宽度不匹配更严重）？这种关系有多强？能否建立一个数学模型来描述它？</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>2. 解决方法是什么？使用了哪些方法？ 数学化地表达出来。（方法）</h3>\n<p>研究采用了三种核心统计学方法来构建从数据到结论的分析路径：</p>\n<ol>\n<li><strong>广义普氏分析 (Generalized Procrustes Analysis, GPA)</strong>：用于标准化和对齐所有患者的上下颌骨三维形态，从而精确计算宽度不匹配。<ul>\n<li><strong>数学表达</strong>: 设上、下颌骨在第 <span class=\"math\">$i$</span> 个牙齿位置对应标志点的横坐标分别为 <span class=\"math\">$x_{upper, i}$</span> 和 <span class=\"math\">$x_{lower, i}$</span>。则该位置的宽度差异 (Width Mismatch, DW) 定义为：\n<pre class=\"math\">$<span class=\"math\">$DW_i = x_{upper, i} - x_{lower, i}$</span>$</pre>\n本文重点关注第二磨牙 (<span class=\"math\">$DW_7$</span>) 和磨牙后区 (<span class=\"math\">$DWR$</span>)。</li>\n</ul>\n</li>\n<li><strong>因子分析 (Factor Analysis, FA)</strong>：用于降维，将22个相关的头影测量指标简化为少数几个独立的潜在因子（即垂直向和矢状向骨骼模式）。<ul>\n<li><strong>数学表达</strong>: 设观测到的 <span class=\"math\">$p$</span> 个头影测量变量构成的向量为 <span class=\"math\">$X = (X_1, ..., X_p)^T$</span>。因子分析将其模型化为：\n<pre class=\"math\">$<span class=\"math\">$X = \\Lambda F + \\epsilon$</span>$</pre>\n其中，<span class=\"math\">$F = (F_1, ..., F_k)^T$</span> 是 <span class=\"math\">$k$</span> 个公共因子向量（<span class=\"math\">$k \\ll p$</span>，例如本文中的垂直向因子-1、矢状向因子-1等），<span class=\"math\">$\\Lambda$</span> 是因子载荷矩阵，表示观测变量与公共因子的关系强度，<span class=\"math\">$\\epsilon$</span> 是特殊因子（误差）向量。</li>\n</ul>\n</li>\n<li><strong>结构方程模型 (Structural Equation Modeling, SEM)</strong>：用于检验并量化因子分析得到的潜在因子（自变量）与GPA计算出的宽度不匹配（因变量）之间的假设关系。<ul>\n<li><strong>数学表达</strong>: SEM建立了一组线性回归方程来描述变量间的关系。例如，对于女性患者，宽度不匹配 <span class=\"math\">$DW_7$</span> 可由四个潜在因子预测：\n<pre class=\"math\">$<span class=\"math\">$DW_7 = \\beta_1 \\cdot \\text{Vertical-1} + \\beta_2 \\cdot \\text{Vertical-2} + \\beta_3 \\cdot \\text{Sagittal-1} + \\beta_4 \\cdot \\text{Sagittal-2} + \\zeta_1$</span>$</pre>\n<pre class=\"math\">$<span class=\"math\">$DWR = \\gamma_1 \\cdot \\text{Vertical-1} + \\gamma_2 \\cdot \\text{Vertical-2} + \\gamma_3 \\cdot \\text{Sagittal-1} + \\gamma_4 \\cdot \\text{Sagittal-2} + \\zeta_2$</span>$</pre>\n其中，<span class=\"math\">$\\beta_i$</span> 和 <span class=\"math\">$\\gamma_i$</span> 是路径系数（Path Coefficients），表示每个因子对宽度不匹配的影响大小和方向, <span class=\"math\">$\\zeta_i$</span> 是残差项。研究的核心目标就是估计这些系数并检验其统计显著性。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3>3. 为什么这个方法是有效果的？其理论保证是什么？ 有什么理论贡献？数学化地表达出来。（理论）</h3>\n<ul>\n<li><strong>方法有效性</strong>:<ul>\n<li><strong>处理复杂性</strong>: SEM能够同时处理多个因变量，并分析不可直接观测的潜在变量（如“骨骼生长模式”）之间的关系，这比传统的回归分析更强大。</li>\n<li><strong>减少测量误差</strong>: 因子分析将多个相关指标综合成一个因子，减少了单一测量指标带来的误差和随机性，使得对“骨骼模式”的表征更稳定和准确。</li>\n<li><strong>模型整体评估</strong>: SEM提供了一套完整的模型拟合度评估体系，可以从整体上判断理论模型与实际数据是否吻合。</li>\n</ul>\n</li>\n<li><strong>理论保证</strong>:<ul>\n<li>其理论保证是基于<strong>统计学的大样本理论</strong>和<strong>协方差结构分析</strong>。通过比较模型隐含的协方差矩阵 <span class=\"math\">$\\Sigma(\\theta)$</span> 与样本数据的协方差矩阵 <span class=\"math\">$S$</span> 的差异来估计模型参数 <span class=\"math\">$\\theta$</span> 并评估模型。</li>\n<li><strong>数学表达</strong>: 模型拟合度的评估依赖于一系列指数，例如：<ul>\n<li>卡方/自由度比 (<pre class=\"math\">$<span class=\"math\">$\\chi^2/df$</span><span class=\"math\">$</pre>)：<pre class=\"math\">$</span><span class=\"math\">$ \\chi^2/df < 3 $</span>$</pre></li>\n<li>拟合优度指数 (GFI), 比较拟合指数 (CFI) 等： <pre class=\"math\">$<span class=\"math\">$GFI, CFI > 0.9$</span>$</pre></li>\n<li>近似误差均方根 (RMSEA)：<pre class=\"math\">$<span class=\"math\">$RMSEA < 0.1$</span>$</pre>\n当模型的各项拟合指数达到可接受的标准时，我们就有统计学上的信心认为该模型是数据的一个合理解释。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>理论贡献</strong>:<ul>\n<li>本文的理论贡献在于<strong>构建并验证了一个量化模型</strong>，证实了临床上关于“低角型（方脸）和重度地包天患者后牙区宽度更容易不调”的经验性观察。</li>\n<li>它明确区分了垂直向和矢状向模式是两个<strong>不同的潜在构造</strong>，并且它们对宽度不匹配有<strong>相反方向的影响</strong>（垂直向正相关，矢状向负相关），这为临床诊断和治疗方案设计提供了理论依据。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>4. 使用了什么算法？数学化地表达出来。（算法）</h3>\n<p>本文使用了一个<strong>统计分析流程 (Statistical Analysis Pipeline)</strong>，而非单一算法。</p>\n<ol>\n<li><strong>三维数据对齐与测量算法 (GPA-based Measurement Algorithm)</strong>:<ul>\n<li><strong>输入</strong>: <span class=\"math\">$N$</span> 名患者的三维标志点坐标集 <span class=\"math\">$\\{C_1, C_2, ..., C_N\\}$</span>。</li>\n<li><strong>步骤</strong>:<ol>\n<li>移除每个坐标集的平移、旋转和缩放差异，使其对齐到同一个公共坐标系中。这是通过最小化所有对应点之间的距离平方和（Procrustes distance）实现的。\n<pre class=\"math\">$<span class=\"math\">$\\min_{R_i, t_i, s_i} \\sum_{i=1}^N \\sum_{j=1}^p \\| s_i C_i R_i + t_i - \\bar{C}_j \\|^2$</span>$</pre></li>\n<li>计算平均形态 <span class=\"math\">$\\bar{C}$</span>。</li>\n<li>在对齐后的坐标系中，计算每个患者的宽度不匹配值 <span class=\"math\">$DW_i = x_{upper, i} - x_{lower, i}$</span>。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><strong>因子提取算法 (Factor Extraction Algorithm - e.g., Principal Axis Factoring)</strong>:<ul>\n<li><strong>输入</strong>: 22个头影测量变量的 <span class=\"math\">$N \\times 22$</span> 数据矩阵 <span class=\"math\">$X$</span>。</li>\n<li><strong>步骤</strong>:<ol>\n<li>计算变量间的相关系数矩阵 <span class=\"math\">$R$</span>。</li>\n<li>估计公共因子方差，并进行迭代求解因子载荷矩阵 <span class=\"math\">$\\Lambda$</span> 和唯一性方差。</li>\n<li>根据特征值（Eigenvalue）大于1的准则，确定因子数量 <span class=\"math\">$k$</span>。</li>\n<li>对因子载荷矩阵进行旋转（如方差最大化旋转 Varimax）以简化解释。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><strong>SEM参数估计算法 (SEM Parameter Estimation Algorithm - e.g., Maximum Likelihood Estimation)</strong>:<ul>\n<li><strong>目标</strong>: 找到模型参数 <span class=\"math\">$\\theta$</span>（包含路径系数 <span class=\"math\">$\\beta, \\gamma$</span> 和方差等），使得模型隐含的协方差矩阵 <span class=\"math\">$\\Sigma(\\theta)$</span> 与样本协方差矩阵 <span class=\"math\">$S$</span> 之间的差异最小。</li>\n<li><strong>优化函数 (最小化)</strong>:\n<pre class=\"math\">$<span class=\"math\">$F_{ML}(\\theta) = \\log|\\Sigma(\\theta)| + \\text{tr}(S\\Sigma(\\theta)^{-1}) - \\log|S| - p$</span>$</pre>\n其中 <span class=\"math\">$p$</span> 是观测变量的数量。通过迭代算法（如牛顿-拉弗森法）找到使 <span class=\"math\">$F_{ML}$</span> 最小的 <span class=\"math\">$\\theta$</span> 值。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3>5. 实验是如何设计的？用简单易懂的语言描述实验设计和结果，越具体越好。（实验）</h3>\n<ul>\n<li><strong>实验设计</strong>:<ul>\n<li><strong>类型</strong>: 这是一项<strong>回顾性横断面研究</strong>。</li>\n<li><strong>对象</strong>: 选取了96名（45男，51女）已确诊为骨性III类错颌（地包天）且未接受过正畸治疗的成年患者。筛选标准很严格，以确保患者群体的一致性。</li>\n<li><strong>数据采集</strong>: 从这些患者的治疗前CBCT影像中提取两种数据：<ol>\n<li><strong>三维颌骨形态</strong>: 在三维模型上手动标记了上、下颌骨的多个标志点，以重建其基骨形态。</li>\n<li><strong>二维头影测量</strong>: 从CBCT数据中生成标准的头颅侧位片，并测量了22个经典的颅面角度和距离（如面部高度、下颌角等）。</li>\n</ol>\n</li>\n<li><strong>分析方法</strong>:<ol>\n<li>使用GPA算法处理三维标志点数据，计算出每位患者在第二磨牙区（DW7）和磨牙后区（DWR）的上下颌骨宽度差。</li>\n<li>将22个头影测量数据进行因子分析，提炼出能代表“垂直面型”和“矢状向严重程度”的几个核心因子。</li>\n<li>最后，将这些因子和宽度差数据放入结构方程模型（SEM）中，分性别进行分析，检验因子对宽度差的影响是否显著。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><strong>实验结果</strong>:<ul>\n<li><strong>不匹配在哪里最严重？</strong>：结果显示，上下颌骨的宽度不匹配主要发生在口腔后部。在<strong>第二磨牙区 (DW7)</strong>，女性下颌平均比上颌宽5.55mm；在更靠后的<strong>磨牙后区 (DWR)</strong>，不匹配更严重，女性下颌平均比上颌宽8.93mm。（男性的数据类似但稍小）。</li>\n<li><strong>什么样的人不匹配更严重？</strong>：<ol>\n<li><strong>垂直面型的影响</strong>: SEM模型显示，代表“低角型”（即脸型偏短、偏方）的垂直向因子与宽度不匹配呈<strong>显著正相关</strong>。举例来说，对于女性，垂直因子-1的路径系数为 <strong>B=5.535 (<span class=\"math\">$P<0.001$</span>)</strong>。通俗地说，<strong>脸型越偏向方脸型，其后牙区的宽度不匹配问题就越严重</strong>。</li>\n<li><strong>矢状向严重程度的影响</strong>: 代表“III类错颌严重程度”的矢状向因子与宽度不匹配呈<strong>显著负相关</strong>。例如，对于男性，矢状因子-1的路径系数为 <strong>B=-4.792 (<span class=\"math\">$P=0.002$</span>)</strong>。简单理解就是，<strong>“地包天”畸形越严重，其后牙区的宽度不匹配也越严重</strong>。</li>\n</ol>\n</li>\n<li><strong>哪些指标最关键？</strong>: 因子分析显示，<strong>“角度总和 (Sum of angles)”</strong> 和 <strong>“下颌平面角 (MP-SN)”</strong> 是判断垂直面型的最重要指标；而 <strong>“Wits评估”</strong> 和 <strong>“前后向骨面型不调指标 (APDI)”</strong> 是判断“地包天”严重程度最有效的指标。这些指标可以帮助医生快速判断患者是否存在严重的后牙宽度不匹配风险。</li>\n</ul>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:06:33Z",
          "dateModified": "2025-11-06T07:06:33Z",
          "uri": "http://zotero.org/users/4752290/items/RYTFBTQW"
        }
      ],
      "citationKey": "chen2022structural",
      "itemKey": "9Z8M5844",
      "libraryID": 1,
      "select": "zotero://select/library/items/9Z8M5844"
    },
    {
      "key": "WAT59EYP",
      "version": 41567,
      "itemType": "preprint",
      "title": "Exploring imbalanced annotations for effective in-context learning",
      "abstractNote": "Large language models (LLMs) have shown impressive performance on downstream tasks through in-context learning (ICL), which heavily relies on the demonstrations selected from annotated datasets. Existing selection methods may hinge on the distribution of annotated datasets, which can often be long-tailed in real-world scenarios. In this work, we show that imbalanced class distributions in annotated datasets significantly degrade the performance of ICL across various tasks and selection methods. Moreover, traditional rebalance methods fail to ameliorate the issue of class imbalance in ICL. Our method is motivated by decomposing the distributional differences between annotated and test datasets into two-component weights: class-wise weights and conditional bias. The key idea behind our method is to estimate the conditional bias by minimizing the empirical error on a balanced validation dataset and to employ the two-component weights to modify the original scoring functions during selection. Our approach can prevent selecting too many demonstrations from a single class while preserving the effectiveness of the original selection methods. Extensive experiments demonstrate the effectiveness of our method, improving the average accuracy by up to 5.46 on common benchmarks with imbalanced datasets.",
      "date": "2025-02-06",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2502.04037",
      "accessDate": "2025-05-23T02:23:06Z",
      "extra": "arXiv:2502.04037 [cs]\nTLDR: This work proposes Reweighting with Conditional Bias (dubbed RCB), a simple and complementary approach to enhance ICL performance under class imbalance, which prevents over-selection from dominant classes while preserving the efficacy of current selection methods.",
      "DOI": "10.48550/arXiv.2502.04037",
      "repository": "arXiv",
      "archiveID": "arXiv:2502.04037",
      "creators": [
        {
          "firstName": "Hongfu",
          "lastName": "Gao",
          "creatorType": "author"
        },
        {
          "firstName": "Feipeng",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Deyu",
          "lastName": "Meng",
          "creatorType": "author"
        },
        {
          "firstName": "Bingyi",
          "lastName": "Jing",
          "creatorType": "author"
        },
        {
          "firstName": "Hongxin",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "inPublications": true,
      "dateAdded": "2025-05-23T02:23:06Z",
      "dateModified": "2025-08-13T01:59:16Z",
      "uri": "http://zotero.org/users/4752290/items/WAT59EYP",
      "itemID": 5504,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "2025_Gao et al._Exploring Imbalanced Annotations for Effective In-Context Learning.pdf",
          "url": "http://arxiv.org/pdf/2502.04037v1",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-05-23T02:23:10Z",
          "dateModified": "2025-05-23T02:23:11Z",
          "uri": "http://zotero.org/users/4752290/items/YSHIVUID",
          "path": "/Users/zengh/Zotero/storage/YSHIVUID/2025_Gao et al._Exploring Imbalanced Annotations for Effective In-Context Learning.pdf",
          "select": "zotero://select/library/items/YSHIVUID"
        }
      ],
      "notes": [
        {
          "key": "IZNLGXJ9",
          "version": 45344,
          "itemType": "note",
          "parentItem": "WAT59EYP",
          "note": "<h2>AI 管家 - Exploring imbalanced annotations for effective in-context learning</h2>\n<div><p>好的，这是一篇关于不平衡数据下 In-Context Learning (ICL) 的论文总结。</p>\n<h3>0. 标题、作者、摘要与贡献</h3>\n<ul>\n<li><strong>标题</strong>: Exploring Imbalanced Annotations for Effective In-Context Learning (探索不平衡标注以实现有效的上下文学习)</li>\n<li><strong>作者</strong>: Hongfu Gao, Feipeng Zhang, Hao Zeng, Deyu Meng, Bingyi Jing, Hongxin Wei</li>\n<li><strong>摘要总结</strong>: 大型语言模型（LLM）的上下文学习（ICL）性能严重依赖于从标注数据集中挑选的示例（demonstrations）。现实世界中的标注数据集常常存在类别不平衡（长尾分布）问题，这会显著降低 ICL 的性能。传统的重平衡方法在 ICL 场景下效果不佳，甚至会恶化问题。本文提出了一种新方法，通过将标注数据集和测试集之间的分布差异分解为“类别权重”和“条件偏差”两个部分来解决此问题。该方法通过在一个平衡的验证集上最小化经验误差来估计条件偏差，并结合两种权重来修正示例选择时的评分函数，从而有效提升了在不平衡数据集上的 ICL 性能。</li>\n<li><strong>一句话贡献与创新</strong>: 本文首次系统地研究并解决了 ICL 在类别不平衡标注数据下的性能下降问题，其创新在于提出了一个将分布差异分解为类别权重和条件偏差的两部分重加权框架，以修正示例选择过程。</li>\n</ul>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><strong>基本任务</strong>: 本文研究的是在<strong>上下文学习 (In-Context Learning, ICL)</strong> 框架下的<strong>分类 (Classification)</strong> 和<strong>生成 (Generation)</strong> 任务。</li>\n<li><strong>模型设定</strong>: 设定在一个更贴近现实的<strong>类别不平衡 (class-imbalanced)</strong> 场景下。具体来说，用于选择示例 (demonstrations) 的大型标注数据集 <span class=\"math\">$D_c$</span> 遵循长尾分布，即某些“头类”拥有大量样本，而大量“尾类”的样本非常稀少。然而，模型的测试数据集 <span class=\"math\">$D_t$</span> 是类别均衡的。ICL 的目标是在这种数据分布不匹配的情况下，依然能对所有类别（尤其是尾类）做出准确的预测。</li>\n<li><strong>简单例子</strong>:<ul>\n<li><strong>数据</strong>: 情感分类数据集。标注数据集 <span class=\"math\">$D_c$</span> 中包含 1000 条“喜悦”的句子，800 条“悲伤”的句子，但只有 50 条“惊讶”和 30 条“爱”的句子。</li>\n<li><strong>任务</strong>: 对于一个新的测试句子，例如“这太出乎我的意料了！”，LLM 需要通过 ICL 来判断其情感类别。</li>\n<li><strong>挑战</strong>: 由于“惊讶”在标注数据中是尾类，模型在挑选示例时很可能倾向于选择“喜悦”等头类样本，从而错误地预测新句子的情感，导致在尾类上的性能急剧下降。</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法</h3>\n<p>本文提出的解决方法是通过<strong>修正示例选择的评分函数</strong>来对抗类别不平衡。其核心思想是将标注数据集分布 <span class=\"math\">$P_c(x, y)$</span> 和测试数据集分布 <span class=\"math\">$P_t(x, y)$</span> 之间的差异分解为两个部分进行补偿。</p>\n<ol>\n<li><strong>分布差异分解</strong>:\n利用重要性采样原理，测试集上的期望误差可以转化为在标注数据集上的期望误差，其转换权重为 <span class=\"math\">$\\frac{P_t(x, y)}{P_c(x, y)}$</span>。该权重被进一步分解为两部分：<ul>\n<li><strong>类别权重 (Class-wise weights) <span class=\"math\">$w$</span></strong>: 衡量类别先验概率的差异。\n<pre class=\"math\">$<span class=\"math\">$w = \\frac{P_t(Y)}{P_c(Y)}$</span>$</pre></li>\n<li><strong>条件偏差 (Conditional bias) <span class=\"math\">$\\beta$</span></strong>: 衡量在给定类别下，数据条件概率分布的差异。\n<pre class=\"math\">$<span class=\"math\">$\\beta = \\frac{P_t(X|Y)}{P_c(X|Y)} - 1$</span>$</pre>\n因此，总的修正权重可以表示为 <span class=\"math\">$w(1+\\beta)$</span>。</li>\n</ul>\n</li>\n<li><strong>修正评分函数</strong>:\n对于一个给定的测试输入 <span class=\"math\">$x_t$</span>，在选择一个候选示例 <span class=\"math\">$c_i$</span> 时，原始的评分函数为 <span class=\"math\">$s(c_i, x_t)$</span>。本文提出的方法使用上述分解的权重来调整该分数。如果示例 <span class=\"math\">$c_i$</span> 属于类别 <span class=\"math\">$j$</span>，则其修正后的新分数为：\n<pre class=\"math\">$<span class=\"math\">$s'(c_i, x_t) = (w_j + \\beta_j) \\times s(c_i, x_t)$</span>$</pre>\n其中 <span class=\"math\">$w_j$</span> 是类别 <span class=\"math\">$j$</span> 的类别权重，<span class=\"math\">$\\beta_j$</span> 是类别 <span class=\"math\">$j$</span> 的条件偏差。注意这里作者将 <span class=\"math\">$w_j(1+\\beta_j)$</span> 简化为了 <span class=\"math\">$(w_j+\\beta_j)$</span> （将 <span class=\"math\">$w_j\\beta_j$</span> 合并为新的 <span class=\"math\">$\\beta_j$</span>）。</li>\n<li><strong>权重和偏差的估计</strong>:<ul>\n<li><strong>类别权重 <span class=\"math\">$w_j$</span></strong>：直接使用现有工作中成熟的 <strong>有效样本数 (effective number)</strong> 方法来计算，该方法能很好地处理长尾分布。</li>\n<li><strong>条件偏差 <span class=\"math\">$\\beta_j$</span></strong>: 无法直接计算。作者提出通过在一个从 <span class=\"math\">$D_c$</span> 中构建的<strong>平衡验证集 <span class=\"math\">$D_b$</span></strong> 上进行优化来估计 <span class=\"math\">$\\beta$</span>。具体来说，通过最小化在 <span class=\"math\">$D_b$</span> 上的经验误差来求解最优的 <span class=\"math\">$\\beta$</span>。</li>\n</ul>\n</li>\n</ol>\n<h3>3. 理论保证与贡献</h3>\n<ul>\n<li><strong>有效性原因</strong>: 传统重加权方法只考虑了类别先验概率的差异（即只用了 <span class=\"math\">$w$</span>），并隐含地假设了 <span class=\"math\">$P_c(X|Y) = P_t(X|Y)$</span>（即 <span class=\"math\">$\\beta=0$</span>）。本文通过实验（图4的KL散度计算）证明这个假设在现实中不成立。本文方法之所以有效，是因为它<strong>同时建模并修正了类别先验差异和数据条件分布差异</strong>，使得对整体分布差异的估计更全面、更准确，从而能更有效地指导示例选择。</li>\n<li><strong>理论贡献</strong>: 本文的主要理论贡献是提出了一个用于分析 ICL 场景下数据不平衡问题的<strong>分布差异分解框架</strong>。\n将 <span class=\"math\">$P_t$</span> 和 <span class=\"math\">$P_c$</span> 的差异分解为 <span class=\"math\">$w$</span> 和 <span class=\"math\">$\\beta$</span> 提供了一个更深刻的视角来理解为什么 ICL 在不平衡数据上会失败，并为解决该问题提供了理论依据。其核心数学表达为：\n<pre class=\"math\">$<span class=\"math\">$ \\mathbb{E}_{P_t(x,y)}[\\mathcal{L}] = \\mathbb{E}_{P_c(x,y)} \\left[\\mathcal{L} \\cdot \\frac{P_t(x, y)}{P_c(x, y)}\\right] $</span>$</pre>\n以及权重的分解：\n<pre class=\"math\">$<span class=\"math\">$ \\frac{P_t(x, y)}{P_c(x, y)} = \\frac{P_t(Y)}{P_c(Y)} \\cdot \\frac{P_t(X|Y)}{P_c(X|Y)} = w \\cdot (1+\\beta) $</span>$</pre>\n这个框架明确了需要从<strong>类别层面</strong>和<strong>类别内部数据</strong>两个维度进行校准。</li>\n</ul>\n<h3>4. 算法</h3>\n<p>本文的算法流程可以概括为以下三个步骤：\n<strong>第一步：构建平衡验证集与计算类别权重</strong></p>\n<ol>\n<li>从不平衡的标注数据集 <span class=\"math\">$D_c$</span> 的每个类别中，随机抽取少量（如 <span class=\"math\">$n_b$</span> 个）样本，构建一个类别平衡的验证集 <span class=\"math\">$D_b$</span>。剩余的数据集记为 <span class=\"math\">$D_r$</span>。</li>\n<li>使用“有效样本数”方法计算每个类别的类别权重 <span class=\"math\">$w_j$</span>。公式为 <span class=\"math\">$w_j = (1-\\alpha)/(1-\\alpha^{n_j})$</span>，其中 <span class=\"math\">$n_j$</span> 是类别 <span class=\"math\">$j$</span> 的样本数，<span class=\"math\">$\\alpha = (N-1)/N$</span>，<span class=\"math\">$N$</span> 是总样本数。\n<strong>第二步：通过贝叶斯优化估计条件偏差 <span class=\"math\">$\\beta$</span></strong></li>\n<li>定义一个关于 <span class=\"math\">$\\beta$</span> 的黑盒目标函数，即在平衡验证集 <span class=\"math\">$D_b$</span> 上的平均任务表现（如准确率）。对于 <span class=\"math\">$D_b$</span>中的每个样本 <span class=\"math\">$(x_b, y_b)$</span>，其表现取决于从 <span class=\"math\">$D_r$</span> 中使用修正评分 <span class=\"math\">$(w_j+\\beta_j) \\times s(c_j, x_b)$</span> 选择出的 Top-K 示例。\n<pre class=\"math\">$<span class=\"math\">$F(\\beta) = \\frac{1}{|D_b|} \\sum_{(x_b, y_b) \\in D_b} \\text{Performance}(f_\\theta(\\text{TopK}_{c_j \\in D_r}(\\{(w_j+\\beta_j)s(c_j, x_b)\\}), x_b), y_b)$</span>$</pre></li>\n<li>由于该函数不可微，使用<strong>贝叶斯优化 (Bayesian Optimization)</strong> 来寻找使 <span class=\"math\">$F(\\beta)$</span> 最大化的最优 <span class=\"math\">$\\beta^*$</span>。\n<strong>第三步：在推理时使用修正后的评分进行示例选择</strong></li>\n<li>当有一个新的测试输入 <span class=\"math\">$x_t$</span> 时，计算所有候选示例 <span class=\"math\">$c_i$</span> 的原始分数 <span class=\"math\">$s(c_i, x_t)$</span>。</li>\n<li>使用第一步得到的 <span class=\"math\">$w$</span> 和第二步估计出的 <span class=\"math\">$\\beta^*$</span> 来计算修正后的分数 <span class=\"math\">$s'(c_i, x_t) = (w_j + \\beta^*_j) \\times s(c_i, x_t)$</span>。</li>\n<li>根据修正后的分数对所有候选示例进行排序，并选择分数最高的 <span class=\"math\">$K$</span> 个作为最终的示例 <span class=\"math\">$C_K$</span> 来进行 ICL 推理。</li>\n</ol>\n<h3>5. 实验设计与结果</h3>\n<p>实验设计得非常全面，旨在验证方法的有效性、鲁棒性和通用性。</p>\n<ul>\n<li><strong>实验设置</strong>:<ul>\n<li><strong>数据集</strong>: 在 4 个经典的文本分类数据集（Amazon, AgNews, Yelp, Yahoo）和 2 个生成任务数据集（NQ 问答, CodeSearchNet 代码摘要）上进行实验。</li>\n<li><strong>不平衡模拟</strong>: 人为地将训练集处理成不同不平衡比率（Imbalance Ratio，头尾类样本数之比）的长尾分布，而测试集保持类别平衡。</li>\n<li><strong>基线方法</strong>:<ol>\n<li><strong>现有选择方法</strong>: 将本文方法（标记为<code>+Ours</code>）集成到 6 种主流的示例选择方法（如 Random, TopK, DPP）上，对比集成前后的性能。</li>\n<li><strong>经典重平衡方法</strong>: 与传统的重采样（过采样、欠采样、分层采样）和重加权方法进行比较。</li>\n</ol>\n</li>\n<li><strong>LLM 模型</strong>: 在多种开源和闭源模型上进行了测试，包括 OPT-6.7B, Llama3-8B, Mistral-7B 和 ChatGPT-3.5-Turbo。</li>\n</ul>\n</li>\n<li><strong>实验结果</strong>:<ol>\n<li><strong>显著优于基线</strong>: 实验结果（如表1）表明，本文方法能够<strong>显著且一致地</strong>提升所有现有示例选择方法在不平衡数据下的性能。例如，在不平衡比率为 100 的极端情况下，平均准确率提升了 <strong>5.46%</strong>。</li>\n<li><strong>优于传统重平衡方法</strong>: 实验（如图3）显示，过采样、欠采样等传统方法在 ICL 场景下效果有限，甚至会损害性能，而本文方法的效果远超它们。这证明了传统方法无法直接适用于 ICL。</li>\n<li><strong>模型和超参数鲁棒性</strong>: 消融实验（如图5）表明，该方法对平衡验证集 <span class=\"math\">$D_b$</span> 的大小不敏感，并且在各种不同架构的 LLM 上都取得了稳定提升，证明了其<strong>模型无关性 (model-agnostic)</strong> 和易用性。</li>\n<li><strong>真实世界数据有效性</strong>: 在一个天然不平衡的数据集 Emotion 上，本文方法同样取得了最佳性能，证明了其在真实场景中的应用价值。</li>\n</ol>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:09:39Z",
          "dateModified": "2025-11-06T07:09:39Z",
          "uri": "http://zotero.org/users/4752290/items/IZNLGXJ9"
        }
      ],
      "citationKey": "gao2025exploring",
      "itemKey": "WAT59EYP",
      "libraryID": 1,
      "select": "zotero://select/library/items/WAT59EYP"
    },
    {
      "key": "AYUAART7",
      "version": 44914,
      "itemType": "preprint",
      "title": "Selective Labeling with False Discovery Rate Control",
      "abstractNote": "Obtaining high-quality labels for large datasets is expensive, requiring massive annotations from human experts. While AI models offer a cost-effective alternative by predicting labels, their label quality is compromised by the unavoidable labeling errors. Existing methods mitigate this issue through selective labeling, where AI labels a subset and human labels the remainder. However, these methods lack theoretical guarantees on the quality of AI-assigned labels, often resulting in unacceptably high labeling error within the AI-labeled subset. To address this, we introduce \\textbf{Conformal Labeling}, a novel method to identify instances where AI predictions can be provably trusted. This is achieved by controlling the false discovery rate (FDR), the proportion of incorrect labels within the selected subset. In particular, we construct a conformal $p$-value for each test instance by comparing AI models' predicted confidence to those of calibration instances mislabeled by AI models. Then, we select test instances whose $p$-values are below a data-dependent threshold, certifying AI models' predictions as trustworthy. We provide theoretical guarantees that Conformal Labeling controls the FDR below the nominal level, ensuring that a predefined fraction of AI-assigned labels is correct on average. Extensive experiments demonstrate that our method achieves tight FDR control with high power across various tasks, including image and text labeling, and LLM QA.",
      "date": "2025-10-16",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2510.14581",
      "accessDate": "2025-10-27T01:02:49Z",
      "extra": "arXiv:2510.14581 [cs]\nTLDR: Conformal Labeling is introduced, a novel method to identify instances where AI predictions can be provably trusted, achieved by controlling the false discovery rate (FDR), the proportion of incorrect labels within the selected subset.",
      "DOI": "10.48550/arXiv.2510.14581",
      "repository": "arXiv",
      "archiveID": "arXiv:2510.14581",
      "creators": [
        {
          "firstName": "Huipeng",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Wenbo",
          "lastName": "Liao",
          "creatorType": "author"
        },
        {
          "firstName": "Huajun",
          "lastName": "Xi",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Mengchen",
          "lastName": "Zhao",
          "creatorType": "author"
        },
        {
          "firstName": "Hongxin",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2025-10-27T01:02:49Z",
      "dateModified": "2025-11-15T15:45:25Z",
      "uri": "http://zotero.org/users/4752290/items/AYUAART7",
      "itemID": 6937,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Preprint PDF",
          "url": "http://arxiv.org/pdf/2510.14581v1",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-10-27T01:02:50Z",
          "dateModified": "2025-10-27T01:02:50Z",
          "uri": "http://zotero.org/users/4752290/items/MVH532FM",
          "path": "/Users/zengh/Zotero/storage/MVH532FM/2025_Huang et al._Selective Labeling with False Discovery Rate Control.pdf",
          "select": "zotero://select/library/items/MVH532FM"
        }
      ],
      "notes": [
        {
          "key": "E56ZDQJQ",
          "version": 45347,
          "itemType": "note",
          "parentItem": "AYUAART7",
          "note": "<h2>AI 管家 - Selective Labeling with False Discovery Rate Control</h2>\n<div><p>好的，这是一份对该文章的简洁易懂且数学化的中文总结。</p>\n<h3>0. 标题、作者、摘要与贡献</h3>\n<ul>\n<li><strong>标题</strong>: Selective Labeling with False Discovery Rate Control (带有错误发现率控制的选择性标注)</li>\n<li><strong>作者</strong>: Huipeng Huang¹, Wenbo Liao¹,²*, Huajun Xi¹, Hao Zeng¹, Mengchen Zhao³, Hongxin Wei¹†</li>\n<li><strong>摘要总结</strong>: 获取大规模高质量标注数据成本高昂。虽然AI模型可以低成本地预测标签，但其固有的错误会影响标签质量。现有方法通过选择性标注（AI标注一部分，人类标注剩余部分）来平衡成本与质量，但通常缺乏对AI标注子集质量的理论保证。为解决此问题，本文提出了一种名为<strong>Conformal Labeling (保形标注)<strong>的新方法。该方法通过控制</strong>错误发现率 (False Discovery Rate, FDR)</strong>，即AI标注子集中错误标签的比例，来确保标注质量。具体来说，它为每个测试样本计算一个保形p值 (conformal p-value)，该p值通过比较该样本的预测置信度与校准集中已知被AI错误分类样本的置信度而得到。然后，方法选择p值低于某个数据驱动阈值的样本进行AI标注。该方法有严格的理论保证，能将所选子集的FDR控制在预设水平之下。实验表明，该方法在图像标注、文本标注和大型语言模型问答 (LLM QA) 等多种任务上，均能以高“功效”（Power，即高标注比例）实现紧密的FDR控制。</li>\n<li><strong>一句话贡献与创新</strong>: 本文首次将选择性标注问题形式化为多重假设检验问题，并提出Conformal Labeling方法，通过保形推断来严格控制AI标注子集的错误发现率（FDR），从而为AI标注的质量提供了理论保证。</li>\n</ul>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><strong>基本任务</strong>:\n给定一个预训练的AI模型 <span class=\"math\">$f$</span> 和一个大规模未标注的测试数据集 <span class=\"math\">$D_{\\text{test}} = \\{X_j\\}_{j=1}^m$</span>，任务是从中选择一个尽可能大的子集 <span class=\"math\">$R \\subseteq \\{1, \\dots, m\\}$</span>，交由AI模型进行标注。其核心要求是，必须保证在这个AI标注的子集 <span class=\"math\">$R$</span> 中，错误标注的比例（即错误发现率FDR）被严格控制在一个用户预设的水平 <span class=\"math\">$\\alpha$</span> 以下。\n<pre class=\"math\">$$\n    \\text{FDR} = \\mathbb{E}\\left[\\frac{|\\{j \\in R : Y_j \\neq \\hat{Y}_j\\}|}{\\max(|R|, 1)}\\right] \\le \\alpha\n    $$</pre>\n其中 <span class=\"math\">$Y_j$</span> 是真实标签，<span class=\"math\">$\\hat{Y}_j$</span> 是AI模型的预测标签。</li>\n<li><strong>模型设定</strong>:\n这是一个多分类问题设定。我们拥有：<ol>\n<li>一个预训练的AI模型 <span class=\"math\">$f: \\mathcal{X} \\to \\mathbb{R}^{|\\mathcal{Y}|}$</span>，它为输入 <span class=\"math\">$X$</span> 输出在所有类别 <span class=\"math\">$\\mathcal{Y}=\\{1, \\dots, K\\}$</span> 上的概率（或logits）。</li>\n<li>一个小的、带有人工标注的<strong>校准数据集</strong> (calibration dataset) <span class=\"math\">$D_{\\text{cal}} = \\{(X_i, Y_i)\\}_{i=1}^n$</span>。</li>\n<li>一个大的、未标注的<strong>测试数据集</strong> (test dataset) <span class=\"math\">$D_{\\text{test}} = \\{X_j\\}_{j=1}^m$</span>。\n我们假设校准数据和测试数据是独立同分布的 (i.i.d.)。</li>\n</ol>\n</li>\n<li><strong>简单例子</strong>:<ul>\n<li><strong>数据</strong>: 有一个包含100万张猫狗图片的测试集 (test set) 和一个包含1000张已正确标注的猫狗图片的校准集 (calibration set)。</li>\n<li><strong>模型</strong>: 一个预训练好的用于猫狗分类的卷积神经网络 (CNN)。</li>\n<li><strong>任务</strong>: 从100万张图片中筛选出一部分，让CNN自动为它们打上“猫”或“狗”的标签。目标是让CNN标注的图片尽可能多，同时保证在这些被CNN标注的图片里，错误的标签不超过5% (即 <span class=\"math\">$\\alpha=0.05$</span>)。剩余的未被选中的图片将交由人类专家标注。</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法</h3>\n<p>该解决方法称为 <strong>Conformal Labeling</strong>，包含三个核心步骤：</p>\n<ol>\n<li><strong>量化不确定性 (Uncertainty Quantification)</strong>:\n为每个数据点 <span class=\"math\">$X$</span> 定义一个不确定性分数 <span class=\"math\">$S(X)$</span>，分数越高表示模型对该点的预测越不确定。一个常用的不确定性分数是基于最大softmax概率 (MSP) 定义的：\n<pre class=\"math\">$$\n    S(X) = 1 - \\max_{y \\in \\mathcal{Y}} f_y(X)\n    $$</pre>\n其中 <span class=\"math\">$f_y(X)$</span> 是模型预测 <span class=\"math\">$X$</span> 属于类别 <span class=\"math\">$y$</span> 的概率。</li>\n<li><strong>构建保形p值 (Conformal p-value)</strong>:\n该方法将选择问题视为一个多重假设检验问题。对每个测试样本 <span class=\"math\">$X_{n+j}$</span>，设立原假设 <span class=\"math\">$H_j^0$</span>: “模型对 <span class=\"math\">$X_{n+j}$</span> 的预测是错误的”。拒绝 <span class=\"math\">$H_j^0$</span> 则意味着我们采纳模型的预测。\n为了进行检验，需要为每个 <span class=\"math\">$H_j^0$</span> 计算一个p值。这个p值通过比较测试样本的不确定性分数 <span class=\"math\">$S_{n+j}$</span> 与校准集中<strong>被模型错误分类</strong>的样本的不确定性分数来构造。<ul>\n<li>首先，在校准集 <span class=\"math\">$D_{\\text{cal}}$</span> 中找出所有被模型错误预测的样本，构成集合 <span class=\"math\">$D_{\\text{cal}}^0 = \\{(X_i, Y_i) \\in D_{\\text{cal}} : \\hat{Y}_i \\neq Y_i\\}$</span>，其大小为 <span class=\"math\">$n_0 = |D_{\\text{cal}}^0|$</span>。</li>\n<li>对于每个测试样本 <span class=\"math\">$X_{n+j}$</span>，其保形p值 <span class=\"math\">$\\hat{p}_j$</span> 计算如下：\n<pre class=\"math\">$$\n    \\hat{p}_j = \\frac{\\sum_{i=1}^{n_0} \\mathbf{1}\\{S_i < S_{n+j}\\} + (1+\\sum_{i=1}^{n_0} \\mathbf{1}\\{S_i = S_{n+j}\\}) \\cdot U_j}{n_0+1}\n    $$</pre>\n其中 <span class=\"math\">$S_i$</span> 是 <span class=\"math\">$D_{\\text{cal}}^0$</span> 中样本的不确定性分数，<span class=\"math\">$U_j \\sim \\text{Uniform}[0,1]$</span> 是一个用于处理平局情况 (ties) 的随机数。这个p值直观地表示了：一个测试样本的不确定性，在所有已知错误样本的不确定性中所处的“排名”。p值越小，说明该样本比绝大多数错误样本都“更确定”，因此其预测正确的可能性很高。</li>\n</ul>\n</li>\n<li><strong>阈值选择 (Thresholding)</strong>:\n获得所有测试样本的p值后，使用一种受Benjamini-Hochberg (BH) 过程启发的方法来确定一个统一的p值阈值，从而选择要拒绝的原假设集合（即AI标注的样本集）。<ul>\n<li>将所有p值从小到大排序：<span class=\"math\">$\\hat{p}_{(1)} \\le \\hat{p}_{(2)} \\le \\dots \\le \\hat{p}_{(m)}$</span>。</li>\n<li>找到最大的索引 <span class=\"math\">$j^*$</span>，使其满足：\n<pre class=\"math\">$$\n    \\hat{p}_{(j^*)} \\le \\frac{\\alpha j^* (n+1)}{m(n_0+1)}\n    $$</pre></li>\n<li>最终选择的样本集合为 <span class=\"math\">$R = \\{j : \\hat{p}_j \\le \\hat{p}_{(j^*)}\\}$</span>。</li>\n</ul>\n</li>\n</ol>\n<h3>3. 理论保证</h3>\n<ul>\n<li><strong>有效性原理</strong>:\n该方法的核心在于保形p值的统计特性。根据保形推断理论，如果一个测试样本 <span class=\"math\">$X_{n+j}$</span> 的真实标签确实被模型预测错误（即原假设 <span class=\"math\">$H_j^0$</span> 为真），那么计算出的p值 <span class=\"math\">$\\hat{p}_j$</span> 在 <span class=\"math\">$[0, 1]$</span> 区间上是超均匀分布的 (super-uniformly distributed)，即 <span class=\"math\">$\\mathbb{P}(\\hat{p}_j \\le \\delta | H_j^0 \\text{ is true}) \\le \\delta$</span>。这意味着错误样本的p值倾向于均匀分布在 <span class=\"math\">$[0, 1]$</span> 之间。相反，被正确分类的样本，其不确定性通常远低于错误样本，因此它们的p值会集中在接近0的很小的值。阈值选择步骤正是利用了这种分布上的差异，来有效地区分正确和错误的预测，从而控制FDR。</li>\n<li><strong>理论保证 (Theorem 3.1)</strong>:\n本文提供了严格的理论证明，确保 Conformal Labeling 方法能够将FDR控制在目标水平 <span class=\"math\">$\\alpha$</span> 以下。\n<strong>定理 3.1</strong>: 假设校准样本和测试样本是独立同分布的，令 <span class=\"math\">$p = \\mathbb{P}(\\hat{Y} \\neq Y)$</span> 为模型预测错误的概率。由算法1确定的选择集 <span class=\"math\">$R$</span> 满足：\n<pre class=\"math\">$$\n    \\text{FDR} \\le [1 - (1-p)^{n+1}]\\alpha \\le \\alpha\n    $$</pre>\n这个不等式表明，无论AI模型的性能如何（即不论 <span class=\"math\">$p$</span> 值大小），该方法都能保证FDR被控制在 <span class=\"math\">$\\alpha$</span> 以下。</li>\n<li><strong>理论贡献</strong>:\n本文为选择性标注领域提供了一个全新的、具有严格统计学保证的理论框架。它将该问题与多重假设检验联系起来，是第一个能够为AI标注子集的质量提供FDR控制保证的方法，解决了现有启发式方法缺乏理论依据的关键痛点。</li>\n</ul>\n<h3>4. 算法</h3>\n<p><strong>算法1: Conformal Labeling</strong></p>\n<ol>\n<li><strong>输入</strong>:<ul>\n<li>校准数据集 <span class=\"math\">$D_{\\text{cal}} = \\{(X_i, Y_i)\\}_{i=1}^n$</span>，大小为 <span class=\"math\">$n$</span>。</li>\n<li>测试数据集 <span class=\"math\">$\\{X_{n+j}\\}_{j=1}^m$</span>，大小为 <span class=\"math\">$m$</span>。</li>\n<li>预训练分类器 <span class=\"math\">$f$</span>。</li>\n<li>目标FDR水平 <span class=\"math\">$\\alpha \\in (0, 1)$</span>。</li>\n</ul>\n</li>\n<li><strong>步骤</strong>:<ul>\n<li><strong>1. 计算不确定性分数</strong>:<ul>\n<li>找出 <span class=\"math\">$D_{\\text{cal}}$</span> 中所有被 <span class=\"math\">$f$</span> 错误分类的样本，得到 <span class=\"math\">$D_{\\text{cal}}^0$</span>，其大小为 <span class=\"math\">$n_0$</span>。</li>\n<li>为 <span class=\"math\">$D_{\\text{cal}}^0$</span> 中的每个样本和所有测试样本计算不确定性分数 <span class=\"math\">$S_i$</span>。</li>\n</ul>\n</li>\n<li><strong>2. 构建保形p值</strong>:<ul>\n<li>对每个测试样本 <span class=\"math\">$j=1, \\dots, m$</span>，根据公式计算其p值 <span class=\"math\">$\\hat{p}_j$</span>：\n<pre class=\"math\">$$\n        \\hat{p}_j = \\frac{\\sum_{i=1}^{n_0} \\mathbf{1}\\{S_i < S_{n+j}\\} + (1+\\sum_{i=1}^{n_0} \\mathbf{1}\\{S_i = S_{n+j}\\}) \\cdot U_j}{n_0+1}\n        $$</pre></li>\n</ul>\n</li>\n<li><strong>3. 阈值选择</strong>:<ul>\n<li>将p值排序: <span class=\"math\">$\\hat{p}_{(1)} \\le \\dots \\le \\hat{p}_{(m)}$</span>。</li>\n<li>计算 <span class=\"math\">$j^* = \\max \\left\\{ j \\in \\{1, \\dots, m\\} : \\hat{p}_{(j)} \\le \\frac{\\alpha j (n+1)}{m(n_0+1)} \\right\\}$</span> (若集合为空则 <span class=\"math\">$j^*=0$</span>）。</li>\n<li>设置阈值为 <span class=\"math\">$T = \\hat{p}_{(j^*)}$</span>。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>输出</strong>:<ul>\n<li>选择的样本索引集合 <span class=\"math\">$R = \\{j : \\hat{p}_j \\le T\\}$</span>。</li>\n</ul>\n</li>\n</ol>\n<h3>5. 实验设计与结果</h3>\n<ul>\n<li><strong>实验设计</strong>:\n作者在三类任务上全面评估了Conformal Labeling方法的性能：<ol>\n<li><strong>图像标注</strong>: 在ImageNet和ImageNet-V2数据集上，使用ResNet、DenseNet等经典图像分类模型。</li>\n<li><strong>文本标注</strong>: 在“全球变暖立场检测”和“虚假信息检测”数据集上，使用Llama、Qwen等大语言模型 (LLM)。</li>\n<li><strong>LLM问答 (QA)</strong>: 在MedMCQA、MMLU等标准QA基准上，使用不同规模的LLM。\n<strong>对比基线 (Baselines)</strong>:</li>\n</ol>\n<ul>\n<li><strong>朴素阈值法 (Naive)</strong>: 用AI标注所有不确定性分数低于某个固定阈值（如0.1）的样本。</li>\n<li><strong>AI全体标注 (AI only)</strong>: 用AI标注全部测试数据。\n<strong>评估指标</strong>:</li>\n<li><strong>FDR</strong>: 实际的错误发现率，验证其是否小于等于目标 <span class=\"math\">$\\alpha$</span>。</li>\n<li><strong>Power (功效) / AI标注比例</strong>: 被AI成功标注的样本占总样本的比例，越高越好。</li>\n</ul>\n</li>\n<li><strong>实验结果</strong>:<ol>\n<li><strong>FDR控制非常有效且紧密</strong>: 在所有任务、数据集和模型上，Conformal Labeling都能将实际的FDR严格控制在预设的目标水平（如 <span class=\"math\">$\\alpha=0.1$</span>）附近或以下。例如，在多数实验中，实际FDR都在9.5%到10.0%之间，控制非常精准。相比之下，两个基线方法都无法控制FDR，其错误率常常远高于目标值。</li>\n<li><strong>功效 (Power) 高</strong>: 在严格控制错误率的同时，该方法还能让AI标注大量数据。例如，在ImageNet上，ResNet-34的整体错误率超过25%，但使用Conformal Labeling (目标FDR=10%)，可以自动标注58.67%的数据，且这部分数据的错误率被控制在10%以下，极大地降低了人工标注成本。</li>\n<li><strong>模型越强，效果越好</strong>: 实验表明，AI模型的准确率越高（例如，使用参数更多的LLM），Conformal Labeling的Power也越高。这符合直觉：一个更强大的模型在更多样本上表现得更自信、更可靠，因此方法能够安全地选择更大比例的数据进行AI标注。</li>\n<li><strong>对校准集大小鲁棒</strong>: 实验发现，该方法对校准集的大小不敏感。即使只使用数据总量的5%作为校准集，也能有效控制FDR。使用10%的校准集在成本和性能方差之间取得了很好的平衡。</li>\n</ol>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:11:25Z",
          "dateModified": "2025-11-06T07:11:25Z",
          "uri": "http://zotero.org/users/4752290/items/E56ZDQJQ"
        }
      ],
      "citationKey": "huang2025selective",
      "itemKey": "AYUAART7",
      "libraryID": 1,
      "select": "zotero://select/library/items/AYUAART7"
    },
    {
      "key": "XPML4HYP",
      "version": 44641,
      "itemType": "conferencePaper",
      "title": "C-adapter: Adapting deep classifiers for efficient conformal prediction sets",
      "abstractNote": "Conformal prediction, as an emerging uncertainty quantification technique, typically functions as post-hoc processing for the outputs of trained classifiers. To optimize the classifier for maximum predictive efficiency, Conformal Training rectifies the training objective with a regularization that minimizes the average prediction set size at a specific error rate. However, the regularization term inevitably deteriorates the classification accuracy and leads to suboptimal efficiency of conformal predictors. To address this issue, we introduce \\textbf{Conformal Adapter} (C-Adapter), an adapter-based tuning method to enhance the efficiency of conformal predictors without sacrificing accuracy. In particular, we implement the adapter as a class of intra order-preserving functions and tune it with our proposed loss that maximizes the discriminability of non-conformity scores between correctly and randomly matched data-label pairs. Using C-Adapter, the model tends to produce extremely high non-conformity scores for incorrect labels, thereby enhancing the efficiency of prediction sets across different coverage rates. Extensive experiments demonstrate that C-Adapter can effectively adapt various classifiers for efficient prediction sets, as well as enhance the conformal training method.",
      "date": "2025-07-11",
      "language": "en",
      "shortTitle": "C-adapter",
      "accessDate": "2025-02-05T01:46:48Z",
      "extra": "https://openreview.net/forum?id=8Gqz2opok1\nremark: C-adapter\ntitleTranslation: C-适配器：为高效共形预测集适配深度分类器",
      "proceedingsTitle": "28th European Conference on Artificial Intelligence",
      "conferenceName": "European Conference on Artificial Intelligence",
      "creators": [
        {
          "firstName": "Kangdao",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Jianguo",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Huiping",
          "lastName": "Zhuang",
          "creatorType": "author"
        },
        {
          "firstName": "Chi Man",
          "lastName": "Vong",
          "creatorType": "author"
        },
        {
          "firstName": "Hongxin",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "#method/conformal-prediction"
        }
      ],
      "relations": {
        "dc:replaces": [
          "http://zotero.org/users/4752290/items/T8KEDG63"
        ]
      },
      "inPublications": true,
      "dateAdded": "2024-12-28T11:54:35Z",
      "dateModified": "2025-08-25T17:08:14Z",
      "uri": "http://zotero.org/users/4752290/items/XPML4HYP",
      "itemID": 4336,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "arXiv",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-12-31T06:17:24Z",
          "dateModified": "2025-08-13T02:19:57Z",
          "uri": "http://zotero.org/users/4752290/items/BLT275LG",
          "path": "/Users/zengh/Zotero/storage/BLT275LG/2024 - Liu et al. - C-Adapter Adapting Deep Classifiers for Efficient Conformal Prediction Sets.pdf",
          "select": "zotero://select/library/items/BLT275LG"
        },
        {
          "itemType": "attachment",
          "title": "ECAI",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-08-19T12:17:57Z",
          "dateModified": "2025-08-19T12:18:22Z",
          "uri": "http://zotero.org/users/4752290/items/HLA34PXC",
          "path": "/Users/zengh/Zotero/storage/HLA34PXC/2025_Liu et al._C-adapter Adapting deep classifiers for efficient conformal prediction sets.pdf",
          "select": "zotero://select/library/items/HLA34PXC"
        },
        {
          "itemType": "attachment",
          "title": "ICLR",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-03-05T11:32:35Z",
          "dateModified": "2025-08-13T02:19:42Z",
          "uri": "http://zotero.org/users/4752290/items/GUZFWWS4",
          "path": "/Users/zengh/Zotero/storage/GUZFWWS4/2025_Liu et al._C-adapter adapting deep classifiers for efficient conformal prediction sets.pdf",
          "select": "zotero://select/library/items/GUZFWWS4"
        },
        {
          "itemType": "attachment",
          "title": "Preprint URL",
          "url": "http://arxiv.org/abs/2410.09408",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-02-05T01:47:01Z",
          "dateModified": "2025-02-05T01:47:01Z",
          "uri": "http://zotero.org/users/4752290/items/VX9XY9WX",
          "select": "zotero://select/library/items/VX9XY9WX"
        }
      ],
      "notes": [
        {
          "key": "WEIX9JFC",
          "version": 45253,
          "itemType": "note",
          "parentItem": "XPML4HYP",
          "note": "<h2>AI 管家 - C-adapter: Adapting deep classifiers for efficient conformal prediction sets</h2>\n<div><p>好的，这是一篇关于提升共形预测（Conformal Prediction）效率的论文总结。</p>\n<h3>0. 标题、作者、摘要及贡献</h3>\n<ul>\n<li><strong>标题</strong>: C-ADAPTER: ADAPTING DEEP CLASSIFIERS FOR EFFICIENT CONFORMAL PREDICTION SETS (C-Adapter：为高效的共形预测集适配深度分类器)</li>\n<li><strong>作者</strong>: Kangdao Liu, Hao Zeng, Jianguo Huang, Huiping Zhuang, Chi-Man Vong, Hongxin Wei</li>\n<li><strong>摘要总结</strong>: 共形预测是一种为分类器提供严格不确定性量化的方法，但其预测集的效率（即大小）依赖于分类器的输出。现有方法如“共形训练”（Conformal Training）试图通过在训练目标中加入正则项来最小化预测集大小，但这往往会损害模型的分类准确率。为解决此问题，本文提出了一种名为**共形适配器（C-Adapter）**的新方法。它是一个附加在已训练好的分类器之上的轻量级模块，通过一个专门设计的损失函数进行微调。该适配器能在不改变模型预测排序（从而不牺牲准确率）的前提下，调整模型的输出，使得错误标签的“非符合度分数”变得极高。这能有效区分正确与错误的标签，从而在不同的置信水平下都能生成更小、更高效的预测集。</li>\n<li><strong>一句话总结贡献和创新</strong>: 本文提出了一种即插即用的适配器模块 C-Adapter，它通过一种创新的损失函数来优化一个保序函数，能够在不降低原分类器准确率的前提下，显著提升共形预测的效率。</li>\n</ul>\n<hr>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><strong>基本任务</strong>: 本文旨在解决多分类问题中的<strong>不确定性量化</strong>任务。具体来说，不是预测一个单一的类别，而是生成一个<strong>预测集</strong>（Prediction Set）<span class=\"math\">$C(x)$</span>，并保证真实标签 <span class=\"math\">$Y$</span> 以不低于预设概率 <span class=\"math\">$1-\\alpha$</span>（例如95%）落入该集合中，即 <span class=\"math\">$P(Y \\in C(x)) \\ge 1-\\alpha$</span>。任务的核心挑战是在满足该概率保证的前提下，让预测集的平均大小（Size）尽可能小，这被称为提升共形预测的<strong>效率</strong>（Efficiency）。</li>\n<li><strong>模型设定</strong>:<ul>\n<li>文章设定在<strong>分割式共形预测 (Split Conformal Prediction)</strong> 框架下。该框架需要一个预训练好的分类器 <span class=\"math\">$f(x;\\theta)$</span> 和一个独立的<strong>校准数据集</strong> (Calibration Set) <span class=\"math\">$D_{cal}=\\{(x_i, y_i)\\}_{i=1}^n$</span>。</li>\n<li>通过在校准集上计算每个样本的<strong>非符合度分数 (non-conformity score)</strong> <span class=\"math\">$s_i = S(x_i, y_i; f)$</span>，可以确定一个阈值 <span class=\"math\">$q$</span>。</li>\n<li>对于新的测试样本 <span class=\"math\">$x_{new}$</span>，其预测集由所有非符合度分数不超过该阈值的候选标签组成，即：\n<pre class=\"math\">$<span class=\"math\">$C(x_{new}) = \\{y \\in \\mathcal{Y} \\mid S(x_{new}, y; f) \\le q\\}$</span>$</pre></li>\n</ul>\n</li>\n<li><strong>简单例子</strong>:<ul>\n<li><strong>数据</strong>: 一张来自 ImageNet 数据集的图片 <span class=\"math\">$x$</span>，其真实标签是 <span class=\"math\">$y=\\text{猫}$</span>。</li>\n<li><strong>分类器</strong>: 一个预训练好的 ResNet 模型 <span class=\"math\">$f$</span>。</li>\n<li><strong>任务</strong>: 假设我们设定的错误率 <span class=\"math\">$\\alpha=0.1$</span>（即置信度为90%）。<ul>\n<li><strong>低效的预测集</strong>: 模型可能输出 <span class=\"math\">$C(x) = \\{\\text{猫}, \\text{狗}, \\text{老虎}\\}$</span>。这个集合虽然包含了真实标签“猫”，但尺寸为3，不够精确。</li>\n<li><strong>高效的预测集</strong>: 通过本文方法优化后，模型可能输出 <span class=\"math\">$C(x) = \\{\\text{猫}\\}$</span>。这个集合尺寸为1，效率更高，同时仍然满足90%的置信度保证。</li>\n</ul>\n</li>\n<li>本文的任务就是设计一种方法，将分类器 <span class=\"math\">$f$</span> 调整为一个新的有效分类器 <span class=\"math\">$f'$</span>，使得其生成的预测集从前者变为后者。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>2. 解决方法</h3>\n<p>本文提出的解决方法是<strong>C-Adapter</strong>，一个附加在预训练分类器 <span class=\"math\">$f$</span> 输出 logits 层之后的小模块 <span class=\"math\">$g(f;\\omega)$</span>，其中 <span class=\"math\">$\\omega$</span> 是可训练参数。</p>\n<ol>\n<li><strong>保序函数 (Intra Order-Preserving Function)</strong>:\n为了不损害原分类器的 Top-K 准确率，C-Adapter被设计成一类特殊的<strong>保序函数</strong>。这意味着如果原模型认为类别 <span class=\"math\">$i$</span> 的置信度高于类别 <span class=\"math\">$j$</span>，那么经过 C-Adapter 调整后，这个顺序关系保持不变。其数学形式为：\n<pre class=\"math\">$<span class=\"math\">$g(f; \\omega) = R(f)^{-1} U \\Psi(f)$</span>$</pre>\n其中 <span class=\"math\">$R(f)$</span> 是对 <span class=\"math\">$f$</span> 的 logits 进行排序的置换矩阵，<span class=\"math\">$U$</span> 是一个上三角全1矩阵，而 <span class=\"math\">$\\Psi(f)$</span> 是一个包含可学习参数 <span class=\"math\">$\\omega$</span> 的函数，其第 <span class=\"math\">$i$</span> 项定义为：\n<pre class=\"math\">$<span class=\"math\">$\\Psi_i(f) = \\begin{cases} \\sqrt{(r_i - r_{i+1})} \\sigma(\\varphi_i(f)) & \\text{for } i<K \\\\ \\varphi_K(f) & \\text{for } i=K \\end{cases}$</span>$</pre>\n这里 <span class=\"math\">$r_i$</span> 是排序后的 logits，<span class=\"math\">$ \\varphi(f) = w \\cdot f + w' $</span> 是一个简单的线性层。</li>\n<li><strong>新的损失函数</strong>:\nC-Adapter 的优化目标不是像 Conformal Training 那样直接最小化某个特定 <span class=\"math\">$\\alpha$</span> 下的预测集大小，而是最大化<strong>正确数据-标签对</strong> <span class=\"math\">$(X, Y)$</span> 和<strong>随机匹配的数据-标签对</strong> <span class=\"math\">$(X, \\hat{Y})$</span> 之间非符合度分数的<strong>可区分性</strong>。其中 <span class=\"math\">$Y$</span> 是真实标签，<span class=\"math\">$\\hat{Y}$</span> 是从所有类别中随机抽取的标签。\n理想情况下，我们希望正确匹配的分数远小于错误匹配的分数。这等价于最小化以下概率：\n<pre class=\"math\">$<span class=\"math\">$P(S(X,Y;\\pi_\\omega) \\ge S(X, \\hat{Y}; \\pi_\\omega))$</span>$</pre>\n由于指示函数不可导，文章使用 Sigmoid 函数 <span class=\"math\">$\\sigma_T(\\cdot)$</span> 作为其平滑代理，最终的损失函数是：\n<pre class=\"math\">$<span class=\"math\">$\\tilde{\\mathcal{L}}(\\omega) = \\mathbb{E} \\left[ \\sigma_T \\left( S(X,Y;\\pi_\\omega) - S(X, \\hat{Y}; \\pi_\\omega) \\right) \\right]$</span>$</pre>\n其中 <span class=\"math\">$S$</span> 是非符合度分数函数，<span class=\"math\">$\\pi_\\omega$</span> 是经过 C-Adapter 调整后的模型输出的概率。通过最小化这个损失，模型会学习将错误标签的非符合度分数推向极高值，从而在构建预测集时更容易排除它们。</li>\n</ol>\n<hr>\n<h3>3. 理论保证</h3>\n<p>该方法有效性的理论保证来自于<strong>命题 1 (Proposition 1)</strong>，它建立了本文提出的损失函数与共形预测整体效率之间的等价关系。</p>\n<ul>\n<li><strong>理论贡献</strong>: 命题1证明了<strong>最小化“分数倒置”概率</strong>（即正确匹配的分数不小于随机匹配的分数）等价于<strong>最小化在所有可能错误率 <span class=\"math\">$\\alpha \\in (0,1)$</span> 下积分的平均预测集大小</strong>。</li>\n<li><strong>数学化表达</strong>:\n令 <span class=\"math\">$\\pi$</span> 和 <span class=\"math\">$\\pi'$</span> 为两个不同的预测器（例如，原始模型和经 C-Adapter 适配后的模型）。以下两个条件是等价的：<ol>\n<li>随机匹配对的分数超过正确匹配对分数的概率更低：\n<pre class=\"math\">$<span class=\"math\">$\\mathbb{P}(S(X,Y;\\pi) \\ge S(X,\\hat{Y};\\pi)) > \\mathbb{P}(S(X,Y;\\pi') \\ge S(X,\\hat{Y};\\pi'))$</span>$</pre></li>\n<li>在所有 <span class=\"math\">$\\alpha$</span> 水平上积分的期望预测集大小更小：\n<pre class=\"math\">$<span class=\"math\">$\\mathbb{E}_{X} \\left[ \\int_0^1 |C(X; F_{S\\pi}^{-1}(1-\\alpha), \\pi)| d\\alpha \\right] > \\mathbb{E}_{X} \\left[ \\int_0^1 |C(X; F_{S\\pi'}^{-1}(1-\\alpha), \\pi')| d\\alpha \\right]$</span>$</pre>\n其中 <span class=\"math\">$F_S^{-1}(1-\\alpha)$</span> 表示分数的 <span class=\"math\">$(1-\\alpha)$</span>-分位数，即共形预测的阈值。</li>\n</ol>\n</li>\n<li><strong>意义</strong>: 这个理论保证了我们优化设计的损失函数（条件1的代理）确实能够提升共形预测的整体效率（条件2），而不仅是在某个特定 <span class=\"math\">$\\alpha$</span> 点上。此外，通过使用保序函数，理论上保证了模型的分类性能（如Top-K准确率）不会下降。</li>\n</ul>\n<hr>\n<h3>4. 算法</h3>\n<p>本文的算法是在一个固定的、预训练好的分类器 <span class=\"math\">$f$</span> 上，对 C-Adapter 的参数 <span class=\"math\">$\\omega$</span> 进行批处理优化。</p>\n<ul>\n<li><strong>算法核心</strong>: 在第 <span class=\"math\">$t$</span> 次迭代中，使用小批量（mini-batch）数据更新 <span class=\"math\">$\\omega$</span>。</li>\n<li><strong>数学化表达</strong>:\n对于一个大小为 <span class=\"math\">$|B_t|$</span> 的小批量数据 <span class=\"math\">$B_t$</span>，C-Adapter 参数 <span class=\"math\">$\\omega$</span> 的更新规则如下：\n<pre class=\"math\">$<span class=\"math\">$w^{(t)} \\leftarrow w^{(t-1)} - \\eta_t \\cdot \\nabla_w \\left[ \\frac{1}{|B_t|} \\sum_{(x,y) \\in B_t} \\frac{1}{|\\mathcal{Y}|} \\sum_{\\hat{y} \\in \\mathcal{Y}} \\sigma_T \\left( S(x,y;\\pi_w) - S(x,\\hat{y};\\pi_w) \\right) \\right]$</span>$</pre><ul>\n<li><span class=\"math\">$w^{(t)}$</span> 是第 <span class=\"math\">$t$</span> 步的参数。</li>\n<li><span class=\"math\">$\\eta_t$</span> 是学习率。</li>\n<li><span class=\"math\">$(x,y) \\in B_t$</span> 是来自小批量的真实数据-标签对。</li>\n<li><span class=\"math\">$\\hat{y} \\in \\mathcal{Y}$</span> 遍历所有可能的类别标签，形成随机匹配对 <span class=\"math\">$(x, \\hat{y})$</span>。</li>\n<li><span class=\"math\">$S(\\cdot)$</span> 是非符合度分数函数，例如 <span class=\"math\">$S_{THR}(x,y;\\pi_w) = 1-\\pi_w(y|x)$</span>。</li>\n<li><span class=\"math\">$\\sigma_T(\\cdot)$</span> 是带温度参数 <span class=\"math\">$T$</span> 的 Sigmoid 函数。\n整个过程中，原始分类器 <span class=\"math\">$f$</span> 的参数保持冻结，只更新 C-Adapter 的参数 <span class=\"math\">$\\omega$</span>。这使得训练过程非常高效。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>5. 实验设计与结果</h3>\n<p>实验设计非常全面，旨在验证 C-Adapter 在多种场景下的有效性、灵活性和优越性。</p>\n<ul>\n<li><strong>数据集与模型</strong>: 实验在 CIFAR-100 和 ImageNet 这两个标准图像分类基准上进行，使用了 ResNet、DenseNet、ResNeXt 等多种主流深度学习模型，以及一个视觉语言模型 CLIP。</li>\n<li><strong>核心实验1：有效性验证 (Table 1)</strong><ul>\n<li><strong>设计</strong>: 在多个模型和数据集上，比较使用 C-Adapter 和不使用 C-Adapter (Baseline) 时的预测集大小，覆盖了 THR, APS, RAPS 三种主流的非符合度分数函数和不同的错误率 <span class=\"math\">$\\alpha$</span> (如0.05, 0.1)。</li>\n<li><strong>结果</strong>: C-Adapter 取得了压倒性优势。例如，在 ImageNet 上使用 DenseNet121 模型和 APS 分数 (置信度90%)，预测集平均大小从 <strong>9.21</strong> 急剧降低到 <strong>2.86</strong>。这个效果在所有设置下都非常显著，证明了 C-Adapter 的普适性和有效性。</li>\n</ul>\n</li>\n<li><strong>核心实验2：与 Conformal Training (ConfTr) 对比 (Figure 5)</strong><ul>\n<li><strong>设计</strong>: 将 C-Adapter 与当前主流的训练时优化方法 ConfTr 进行对比。同时，还设计了“ConfTr+C-Adapter”的组合，即在经过 ConfTr 优化的模型上再应用 C-Adapter。</li>\n<li><strong>结果</strong>: C-Adapter 全面优于 ConfTr。特别是在 THR 分数上，ConfTr 甚至会因为损害模型准确率而导致预测集变大，而 C-Adapter 依然能有效减小预测集。此外，C-Adapter 还能在 ConfTr 的基础上进一步提升效率，证明了它是对现有方法的一个强大补充。</li>\n</ul>\n</li>\n<li><strong>核心实验3：适配策略的消融研究 (Figures 6, 7)</strong><ul>\n<li><strong>设计</strong>: 比较了三种不同的模型适配策略：1) <strong>C-Adapter</strong> (固定主模型，只调适配器)；2) <strong>Retraining</strong> (用本文的损失函数从头训练整个模型)；3) <strong>Fine-tuning</strong> (用本文的损失函数微调模型的最后一层)。</li>\n<li><strong>结果</strong>: Retraining 和 Fine-tuning 都会导致模型的基础分类准确率下降3-5%，这反而限制了预测集效率的提升。只有 C-Adapter 策略能够在保持准确率的同时，最大化效率提升，证明了其架构设计的优越性。</li>\n</ul>\n</li>\n<li><strong>其他实验</strong>:<ul>\n<li><strong>对分布变化的鲁棒性 (Table 4)</strong>: 在 ImageNet 上训练 C-Adapter，然后在有分布变化的 ImageNet-V2 数据集上测试。结果显示 C-Adapter 的性能提升是稳健的。</li>\n<li><strong>对超参数不敏感</strong>: 实验表明 C-Adapter 对其唯一的超参数（Sigmoid 中的温度 T）不敏感，易于使用。</li>\n<li><strong>灵活性</strong>: 即使在训练 C-Adapter 时使用一种分数函数（如THR），在测试时换用另一种（如APS），其性能提升效果依然很好，展示了其灵活性。</li>\n</ul>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T00:14:45Z",
          "dateModified": "2025-11-06T00:14:45Z",
          "uri": "http://zotero.org/users/4752290/items/WEIX9JFC"
        }
      ],
      "citationKey": "liu2025cadapter",
      "itemKey": "XPML4HYP",
      "libraryID": 1,
      "select": "zotero://select/library/items/XPML4HYP"
    },
    {
      "key": "X5J6TYMI",
      "version": 44914,
      "itemType": "preprint",
      "title": "High-Power Training Data Identification with Provable Statistical Guarantees",
      "abstractNote": "Identifying training data within large-scale models is critical for copyright litigation, privacy auditing, and ensuring fair evaluation. The conventional approaches treat it as a simple binary classification task without statistical guarantees. A recent approach is designed to control the false discovery rate (FDR), but its guarantees rely on strong, easily violated assumptions. In this paper, we introduce Provable Training Data Identification (PTDI), a rigorous method that identifies a set of training data with strict false discovery rate (FDR) control. Specifically, our method computes p-values for each data point using a set of known unseen data, and then constructs a conservative estimator for the data usage proportion of the test set, which allows us to scale these p-values. Our approach then selects the final set of training data by identifying all points whose scaled p-values fall below a data-dependent threshold. This entire procedure enables the discovery of training data with provable, strict FDR control and significantly boosted power. Extensive experiments across a wide range of models (LLMs and VLMs), and datasets demonstrate that PTDI strictly controls the FDR and achieves higher power.",
      "date": "2025-10-10",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2510.09717",
      "accessDate": "2025-10-27T01:02:47Z",
      "extra": "arXiv:2510.09717 [cs]\nTLDR: This paper introduces Provable Training Data Identification (PTDI), a rigorous method that identifies a set of training data with strict false discovery rate (FDR) control and achieves higher power.",
      "DOI": "10.48550/arXiv.2510.09717",
      "repository": "arXiv",
      "archiveID": "arXiv:2510.09717",
      "creators": [
        {
          "firstName": "Zhenlong",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Weiran",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Hongxin",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2025-10-27T01:02:47Z",
      "dateModified": "2025-11-14T05:23:31Z",
      "uri": "http://zotero.org/users/4752290/items/X5J6TYMI",
      "itemID": 6936,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Preprint PDF",
          "url": "http://arxiv.org/pdf/2510.09717v1",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-10-27T01:02:50Z",
          "dateModified": "2025-10-27T01:02:50Z",
          "uri": "http://zotero.org/users/4752290/items/2UWWIKMX",
          "path": "/Users/zengh/Zotero/storage/2UWWIKMX/2025_Liu et al._High-Power Training Data Identification with Provable Statistical Guarantees.pdf",
          "select": "zotero://select/library/items/2UWWIKMX"
        }
      ],
      "notes": [
        {
          "key": "GHM45NHL",
          "version": 45347,
          "itemType": "note",
          "parentItem": "X5J6TYMI",
          "note": "<h2>AI 管家 - High-Power Training Data Identification with Provable Statistical Guarantees</h2>\n<div><p>好的，这是对这篇文章的简洁易懂且数学化的中文总结。</p>\n<h3>0. 标题、作者、摘要及贡献</h3>\n<ul>\n<li><strong>标题 (英文):</strong> HIGH-POWER TRAINING DATA IDENTIFICATION WITH PROVABLE STATISTICAL GUARANTEES</li>\n<li><strong>作者:</strong> Zhenlong Liu¹,², Hao Zeng¹, Weiran Huang²,³, and Hongxin Wei¹,†</li>\n<li><strong>摘要总结:</strong> 本文旨在解决在大型模型中识别训练数据的关键问题，尤其是在版权诉讼、隐私审计等需要严格证据的场景。传统方法通常将其视为一个没有统计保障的二元分类任务。虽然近期有方法尝试控制错误发现率（False Discovery Rate, FDR），但其依赖于容易被违反的强假设。本文提出了一种名为 <strong>可证明的训练数据识别 (Provable Training Data Identification, PTDI)</strong> 的新方法。该方法首先利用一个已知不属于训练集的校准数据集（calibration set）来为每个待测数据点计算 p 值。然后，它构造了一个对测试集中训练数据占比的保守估计，并用该估计值来缩放 p 值，以提升统计功效（power）。最后，通过一个依赖于数据的阈值来筛选缩放后的 p 值，从而确定最终的训练数据识别集。该方法能够在保证严格 FDR 控制的同时，显著提升发现真实训练数据的能力，且无需对数据分布做强假设。</li>\n<li><strong>一句话贡献和创新:</strong> 本文的核心创新是提出了一种通过估计测试集中训练数据的比例来缩放保形 p 值（conformal p-values）的方法，从而在保证错误发现率（FDR）严格可控的理论前提下，显著提升了识别训练数据的统计功效。</li>\n</ul>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><p><strong>基本任务:</strong> 本文的任务是<strong>训练数据识别 (Training Data Identification)</strong>。给定一个目标模型 <span class=\"math\">$\\theta$</span> 和一个由 <span class=\"math\">$m$</span> 个候选数据点组成的测试集 <span class=\"math\">$D_{\\text{test}}=\\{X_{n+j}\\}_{j=1}^m$</span>，任务是从中识别出一个子集 <span class=\"math\">$S$</span>，该子集中的样本有很大概率是模型 <span class=\"math\">$\\theta$</span> 的真实训练数据。</p>\n</li>\n<li><p><strong>模型设定:</strong> 该任务被设定在一个<strong>多重假设检验 (multiple-hypothesis testing)</strong> 的框架下。对于测试集中的每一个数据点 <span class=\"math\">$X_{n+j}$</span>，我们都检验一个零假设 <span class=\"math\">$H_j$</span>:\n<pre class=\"math\">$<span class=\"math\">$H_j: M_{n+j}=0$</span>$</pre>\n其中 <span class=\"math\">$M_{n+j}=1$</span> 表示 <span class=\"math\">$X_{n+j}$</span> 是训练数据， <span class=\"math\">$M_{n+j}=0$</span> 表示它不是。拒绝 <span class=\"math\">$H_j$</span> 就意味着我们将 <span class=\"math\">$X_{n+j}$</span> 识别为训练数据。</p>\n<p>目标是找到一个拒绝集合 <span class=\"math\">$S$</span>（即识别出的训练数据索引集），同时将<strong>错误发现率 (False Discovery Rate, FDR)</strong> 控制在一个用户预设的水平 <span class=\"math\">$\\alpha$</span> 以下：\n<pre class=\"math\">$<span class=\"math\">$FDR = \\mathbb{E}\\left[\\frac{\\text{错误发现的数量}}{\\text{总发现的数量}}\\right] = \\mathbb{E}\\left[\\frac{\\sum_{j \\in S} \\mathbb{I}\\{M_{n+j}=0\\}}{\\max(|S|, 1)}\\right] \\le \\alpha$</span>$</pre>\n同时，我们希望最大化<strong>统计功效 (Power)</strong>，即找到尽可能多的真实训练数据：\n<pre class=\"math\">$<span class=\"math\">$Power = \\mathbb{E}\\left[\\frac{\\text{正确发现的数量}}{\\text{真实成员的总数}}\\right] = \\mathbb{E}\\left[\\frac{\\sum_{j \\in S} \\mathbb{I}\\{M_{n+j}=1\\}}{\\max(1, \\sum_{j=1}^m \\mathbb{I}\\{M_{n+j}=1\\})}\\right]$</span>$</pre></p>\n</li>\n<li><p><strong>简单例子:</strong></p>\n<ul>\n<li><strong>数据:</strong><ol>\n<li><strong>目标模型 <span class=\"math\">$\\theta$</span></strong>: 一个已经训练好的大语言模型，如 LLaMA-7B。</li>\n<li><strong>测试集 <span class=\"math\">$D_{\\text{test}}$</span></strong>: 一批网络文本，我们想知道其中哪些被用于训练 LLaMA-7B。</li>\n<li><strong>校准集 <span class=\"math\">$D_{\\text{cal}}$</span></strong>: 一批我们<strong>确定</strong>没有被用于训练的文本（例如，在模型发布后才出现的文本）。</li>\n</ol>\n</li>\n<li><strong>任务:</strong> 产出一个列表 <span class=\"math\">$S$</span>，列出 <span class=\"math\">$D_{\\text{test}}$</span> 中那些被判定为训练数据的文本，并保证这个列表中平均只有不到 <span class=\"math\">$\\alpha$</span>（例如 5%）的文本是误判的。</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法</h3>\n<p>该解决方法（PTDI）可以分解为以下几个数学步骤：</p>\n<ol>\n<li><strong>计算检测分数:</strong> 对校准集 <span class=\"math\">$D_{\\text{cal}}$</span> 和测试集 <span class=\"math\">$D_{\\text{test}}$</span> 中的每个数据点 <span class=\"math\">$X_i$</span>，使用模型 <span class=\"math\">$\\theta$</span> 计算一个<strong>检测分数 <span class=\"math\">$T_i = T(X_i; \\theta)$</span></strong>。按照惯例，分数越低，越有可能是训练数据（例如，模型的困惑度 Perplexity）。</li>\n<li><strong>构造保形 p 值:</strong> 对于测试集中的每个数据点 <span class=\"math\">$X_{n+j}$</span> (<span class=\"math\">$j=1, \\dots, m$</span>)，利用大小为 <span class=\"math\">$n$</span> 的校准集（其中所有样本都满足 <span class=\"math\">$M_i=0$</span>）来计算其<strong>保形 p 值 (conformal p-value)</strong>：\n<pre class=\"math\">$<span class=\"math\">$p_j = \\frac{1 + \\sum_{i=1}^{n} \\mathbb{I}\\{T_i \\le T_{n+j}\\}}{n+1}$</span>$</pre>\n这个 p 值衡量了测试点的分数相对于已知非训练数据的“异常”程度。</li>\n<li><strong>估计训练数据比例:</strong> 这是提升功效的关键。估计测试集中训练数据所占的真实比例 <span class=\"math\">$\\pi_{\\text{test}} = \\text{Pr}(M=1)$</span>。本文提出了一种名为**“减法估计器” (subtraction estimator)** 的方法。其核心思想是，在检测分数的一个特定区域 <span class=\"math\">$\\mathcal{R}$</span>（例如分数很高的区域，理论上很少有训练数据落入），测试集数据的密度约等于 <span class=\"math\">$(1-\\pi_{\\text{test}})$</span> 乘以非训练集数据的密度。通过比较来自测试集和校准集的经验密度，可以得到一个保守的估计 <span class=\"math\">$\\hat{\\pi}_{\\text{test}}$</span>。\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\pi}_{\\text{test}} = \\hat{\\pi}_{\\text{sub}} = 1 - \\frac{\\frac{1}{m}(m+1)^{-1}(1 + \\sum_{j=1}^{m} \\mathbb{I}\\{T(X_{n+j}) \\in \\mathcal{R}\\})}{\\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{I}\\{T(X_i) \\in \\mathcal{R}\\}}$</span>$</pre>\n(注：原文公式(12)有一个小笔误，这里给出了修正后的概念形式，原文为 <span class=\"math\">$m\\sum_{i=1}^{n} \\dots$</span> 应为 <span class=\"math\">$\\frac{1}{n}\\sum_{i=1}^{n} \\dots$</span> 的形式)</li>\n<li><strong>缩放 p 值:</strong> 使用上一步的估计值来<strong>缩放 p 值</strong>，以抵消标准多重检验方法的保守性：\n<pre class=\"math\">$<span class=\"math\">$\\tilde{p}_j = (1 - \\hat{\\pi}_{\\text{test}}) p_j$</span>$</pre></li>\n<li><strong>应用 BH 过程:</strong> 对缩放后的 p 值 <span class=\"math\">$\\{\\tilde{p}_j\\}_{j=1}^m$</span> 应用经典的 <strong>Benjamini-Hochberg (BH) 过程</strong>。首先将 p 值排序 <span class=\"math\">$\\tilde{p}_{(1)} \\le \\tilde{p}_{(2)} \\le \\dots \\le \\tilde{p}_{(m)}$</span>，然后找到最大的 <span class=\"math\">$k$</span> 满足：\n<pre class=\"math\">$<span class=\"math\">$k^* = \\max\\left\\{k \\mid \\tilde{p}_{(k)} \\le \\frac{k}{m}\\alpha\\right\\}$</span>$</pre>\n最终的发现集 <span class=\"math\">$S$</span> 就是所有满足 <span class=\"math\">$\\tilde{p}_j \\le \\frac{k^*}{m}\\alpha$</span> 的样本 <span class=\"math\">$j$</span> 的集合。</li>\n</ol>\n<h3>3. 理论保证和贡献</h3>\n<ul>\n<li><strong>有效性原因:</strong><ol>\n<li><strong>p 值的有效性:</strong> 通过保形推断构造的 p 值 <span class=\"math\">$p_j$</span>在零假设（即数据点为非训练数据）下是有效的（数学上称为超均匀分布, super-uniformly distributed），这是 BH 过程能控制 FDR 的基本前提。</li>\n<li><strong>p 值缩放的合理性:</strong> 标准 BH 过程的 FDR 保证是 <span class=\"math\">$FDR \\le \\frac{m_0}{m}\\alpha$</span>，其中 <span class=\"math\">$m_0$</span> 是真实零假设（非训练数据）的数量。这个过程是保守的，因为 <span class=\"math\">$\\frac{m_0}{m} \\le 1$</span>。本文的方法通过估计项 <span class=\"math\">$(1-\\hat{\\pi}_{\\text{test}})$</span> 来近似 <span class=\"math\">$\\frac{m_0}{m}$</span>，然后将 p 值乘以它，相当于将检验的阈值从 <span class=\"math\">$\\frac{k}{m}\\alpha$</span> 提高到 <span class=\"math\">$\\frac{k}{m}\\frac{\\alpha}{1-\\hat{\\pi}_{\\text{test}}}$</span>，从而使得检验更加宽松（功效更高），同时理论上仍然能将 FDR 控制在 <span class=\"math\">$\\alpha$</span> 以下。</li>\n</ol>\n</li>\n<li><strong>理论保证:</strong>\n本文的核心理论贡献是 <strong>Theorem 1</strong>，它严格证明了 PTDI 方法能够控制 FDR。即对于任意用户指定的目标水平 <span class=\"math\">$\\alpha \\in (0, 1)$</span>，算法输出的集合 <span class=\"math\">$S$</span> 满足：\n<pre class=\"math\">$<span class=\"math\">$FDR = \\mathbb{E}\\left[\\frac{\\sum_{j=1}^{m}\\mathbb{I}\\{M_{n+j}=0, j \\in S\\}}{\\max(|S|, 1)}\\right] \\le \\alpha$</span>$</pre></li>\n<li><strong>理论贡献:</strong>\n主要的理论贡献是证明了使用<strong>数据依赖的、估计出的比例 <span class=\"math\">$\\hat{\\pi}_{\\text{test}}$</span></strong> 来缩放 p 值，仍然能保持严格的 FDR 保证。这是高度不平凡的。证明的关键在于 <strong>Proposition 1</strong>，它表明本文提出的“减法估计器”是保守的，即在期望意义下，它不会高估非训练数据的比例：\n<pre class=\"math\">$<span class=\"math\">$\\mathbb{E}\\left[\\frac{1-\\pi_{\\text{test}}}{1-\\hat{\\pi}_{\\text{sub}}}\\right] \\le 1$</span>$</pre>\n这个不等式是连接估计步骤和最终 FDR 保证的桥梁。</li>\n</ul>\n<h3>4. 算法</h3>\n<p>本文提出的 <strong>PTDI 算法 (Algorithm 1)</strong> 的数学化表达如下：\n<strong>输入:</strong> 目标模型 <span class=\"math\">$\\theta$</span>，校准集 <span class=\"math\">$D_{\\text{cal}}$</span> (大小为 <span class=\"math\">$n$</span>)，测试集 <span class=\"math\">$D_{\\text{test}}$</span> (大小为 <span class=\"math\">$m$</span>)，目标 FDR 水平 <span class=\"math\">$\\alpha$</span>，检测分数函数 <span class=\"math\">$T(\\cdot)$</span>，比例估计器 <span class=\"math\">$\\mathcal{E}$</span>。</p>\n<ol>\n<li><strong>计算分数:</strong> 对所有 <span class=\"math\">$X_i \\in D_{\\text{cal}} \\cup D_{\\text{test}}$</span>，计算分数 <span class=\"math\">$T_i \\leftarrow T(X_i; \\theta)$</span>。</li>\n<li><strong>构造 p 值:</strong> 对 <span class=\"math\">$j=1, \\dots, m$</span>，计算\n<pre class=\"math\">$<span class=\"math\">$p_j \\leftarrow \\frac{1 + \\sum_{i=1}^{n} \\mathbb{I}\\{T_i \\le T_{n+j}\\}}{n+1}$</span>$</pre></li>\n<li><strong>估计比例:</strong> \n<pre class=\"math\">$<span class=\"math\">$\\hat{\\pi}_{\\text{test}} \\leftarrow \\mathcal{E}(D_{\\text{cal}}, D_{\\text{test}})$</span>$</pre></li>\n<li><strong>缩放 p 值:</strong> 对 <span class=\"math\">$j=1, \\dots, m$</span>，计算\n<pre class=\"math\">$<span class=\"math\">$\\tilde{p}_j \\leftarrow (1-\\hat{\\pi}_{\\text{test}})p_j$</span>$</pre></li>\n<li><strong>排序 p 值:</strong> 将 <span class=\"math\">$\\{\\tilde{p}_j\\}$</span> 升序排列得到 <span class=\"math\">$\\{\\tilde{p}_{(k)}\\}_{k=1}^m$</span>。</li>\n<li><strong>寻找 BH 阈值:</strong> 找到\n<pre class=\"math\">$<span class=\"math\">$k^* \\leftarrow \\max\\{k \\mid \\tilde{p}_{(k)} \\le \\frac{k}{m}\\alpha\\}$</span>$</pre></li>\n<li><strong>输出发现集:</strong> 如果 <span class=\"math\">$k^*$</span> 存在，则返回 <span class=\"math\">$S = \\{j \\mid \\tilde{p}_j \\le \\frac{k^*}{m}\\alpha\\}$</span>；否则返回 <span class=\"math\">$S = \\emptyset$</span>。</li>\n</ol>\n<h3>5. 实验设计与结果</h3>\n<ul>\n<li><strong>实验设计:</strong>\n实验旨在验证 PTDI 方法的两个核心特性：<strong>FDR 控制的严格性</strong>和<strong>统计功效的优越性</strong>。<ul>\n<li><strong>模型与数据:</strong> 实验覆盖了多种大语言模型（如 GPT-NeoX, LLaMA-7B, Pythia-6.9B）和视觉语言模型（MiniGPT-4），并在多个基准数据集（如 WikiMIA, ArXivTection, XSum）上进行测试。</li>\n<li><strong>对比方法:</strong><ol>\n<li><strong>Vanilla (基线):</strong> 使用相同的保形 p 值但不进行缩放，直接应用 BH 过程。这用于验证 p 值缩放步骤的有效性。</li>\n<li><strong>KTD (基于 Knockoff 的方法):</strong> 这是另一种旨在控制 FDR 的先进方法，用于证明 PTDI 相对于现有方法的优越性。</li>\n</ol>\n</li>\n<li><strong>评价指标:</strong><ol>\n<li><strong>经验 FDR:</strong> 多次重复实验，计算实际的错误发现比例的平均值。理想情况下，该值应始终低于或等于预设的目标 FDR <span class=\"math\">$\\alpha$</span>。</li>\n<li><strong>功效 (Power):</strong> 计算被正确识别出的真实训练数据占所有真实训练数据的比例。该值越高越好。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><strong>实验结果:</strong><ul>\n<li><strong>FDR 控制:</strong> 实验结果（如图1和图2）清晰地表明，在所有设置下，<strong>PTDI 的经验 FDR (实线) 始终保持在目标 FDR 水平 <span class=\"math\">$\\alpha$</span> (虚线对角线) 以下</strong>，证明了其理论保证的有效性。相比之下，KTD 方法在某些情况下会<strong>失控</strong>，其经验 FDR 显著超过 <span class=\"math\">$\\alpha$</span>。例如，在 WikiMIA 和 5% 目标 FDR下，PTDI 的 FDR 为 4.94%，而 KTD 为 13.11%。</li>\n<li><strong>功效提升:</strong> 实验结果（如表1）显示，与不缩放 p 值的 Vanilla 基线相比，<strong>PTDI 的功效显著更高</strong>。例如，在 WikiMIA 数据集和 NeoX-20B 模型上，当目标 FDR 为 0.5 时，PTDI 使用 MIN-K% 分数将功效从 0.44 (Vanilla) 提升到了 0.75。这证明了 p 值缩放策略是成功的。在与 KTD 的比较中，PTDI 不仅保证了 FDR 控制，其功效也通常具有竞争力甚至更优。</li>\n<li><strong>稳健性分析:</strong> 实验还探究了校准集大小等超参数的影响，结果表明增加校准集大小可以降低结果的方差，使识别更加稳定，验证了方法的稳健性。</li>\n</ul>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:11:27Z",
          "dateModified": "2025-11-06T07:11:27Z",
          "uri": "http://zotero.org/users/4752290/items/GHM45NHL"
        }
      ],
      "citationKey": "liu2025highpower",
      "itemKey": "X5J6TYMI",
      "libraryID": 1,
      "select": "zotero://select/library/items/X5J6TYMI"
    },
    {
      "key": "S7GQBUGC",
      "version": 44911,
      "itemType": "journalArticle",
      "title": "Spatial-aware conformal prediction for trustworthy hyperspectral image classification",
      "abstractNote": "Hyperspectral image (HSI) classification involves assigning unique labels to each pixel to identify various land cover categories. While deep classifiers have achieved high predictive accuracy in this field, they lack the ability to rigorously quantify confidence in their predictions. This limitation restricts their application in critical contexts where the cost of prediction errors is significant, as quantifying the uncertainty of model predictions is crucial for the safe deployment of predictive models. To address this limitation, a rigorous theoretical proof is presented first, which demonstrates the validity of Conformal Prediction, an emerging uncertainty quantification technique, in the context of HSI classification. Building on this foundation, a conformal procedure is designed to equip any pre-trained HSI classifier with trustworthy prediction sets, ensuring that the true labels are included with a user-defined probability (e.g., 95%). Furthermore, a novel framework of Conformal Prediction specifically designed for HSI data, called Spatial-Aware Conformal Prediction ( SACP ), is proposed. This framework integrates essential spatial information of HSI by aggregating the non-conformity scores of pixels with high spatial correlation, effectively improving the statistical efficiency of prediction sets. Both theoretical and empirical results validate the effectiveness of the proposed approaches. The source code is available at https://github.com/J4ckLiu/SACP",
      "date": "2025-09",
      "language": "en-US",
      "libraryCatalog": "IEEE Xplore",
      "url": "https://ieeexplore.ieee.org/document/10960721",
      "accessDate": "2025-09-24T02:41:23Z",
      "extra": "tex.ids= liu2025spatialaware\nremark: HIC高光谱应用\npublisher: IEEE\nTLDR: A rigorous theoretical proof is presented, which demonstrates the validity of Conformal Prediction, an emerging uncertainty quantification technique, in the context of HSI classification, and a novel framework of Conformal Prediction specifically designed for HSI data, called Spatial-Aware Conformal Prediction ( SACP).",
      "volume": "35",
      "pages": "8754-8766",
      "publicationTitle": "IEEE Transactions on Circuits and Systems for Video Technology",
      "DOI": "10.1109/TCSVT.2025.3558753",
      "issue": "9",
      "ISSN": "1558-2205",
      "creators": [
        {
          "firstName": "Kangdao",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Tianhao",
          "lastName": "Sun",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Yongshan",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Chi-Man",
          "lastName": "Pun",
          "creatorType": "author"
        },
        {
          "firstName": "Chi-Man",
          "lastName": "Vong",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "#method/conformal-prediction"
        }
      ],
      "relations": {
        "dc:replaces": [
          "http://zotero.org/users/4752290/items/XRCMUBPR"
        ]
      },
      "dateAdded": "2025-05-23T01:53:28Z",
      "dateModified": "2025-09-24T07:18:33Z",
      "uri": "http://zotero.org/users/4752290/items/S7GQBUGC",
      "itemID": 6771,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "2025_Liu et al._Spatial-aware conformal prediction for trustworthy hyperspectral image classification.pdf",
          "url": "https://arxiv.org/pdf/2409.01236",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-05-23T01:53:32Z",
          "dateModified": "2025-09-24T02:42:16Z",
          "uri": "http://zotero.org/users/4752290/items/LZSAA4FW",
          "path": "/Users/zengh/Zotero/storage/LZSAA4FW/2025_Liu et al._Spatial-aware conformal prediction for trustworthy hyperspectral image classification.pdf",
          "select": "zotero://select/library/items/LZSAA4FW"
        },
        {
          "itemType": "attachment",
          "title": "Snapshot",
          "url": "https://ieeexplore.ieee.org/document/10960721",
          "tags": [],
          "relations": {
            "dc:replaces": [
              "http://zotero.org/users/4752290/items/K4UCAZDE"
            ]
          },
          "dateAdded": "2025-09-24T02:41:34Z",
          "dateModified": "2025-09-24T02:42:16Z",
          "uri": "http://zotero.org/users/4752290/items/QZRMDF8P",
          "path": "/Users/zengh/Zotero/storage/QZRMDF8P/10960721.html",
          "select": "zotero://select/library/items/QZRMDF8P"
        }
      ],
      "notes": [
        {
          "key": "KSIBJW8K",
          "version": 0,
          "itemType": "note",
          "parentItem": "S7GQBUGC",
          "note": "<h2>AI 管家 - Spatial-aware conformal prediction for trustworthy hyperspectral image classification</h2>\n<div><p>好的，这是一份关于该文章的简洁易懂且数学化的中文总结。</p>\n<h3>0. 标题、作者及摘要</h3>\n<ul>\n<li><strong>标题 (英文)</strong>: Spatial-Aware Conformal Prediction for Trustworthy Hyperspectral Image Classification</li>\n<li><strong>作者</strong>: Kangdao Liu, Tianhao Sun, Hao Zeng, Yongshan Zhang, Chi-Man Pun, Chi-Man Vong</li>\n<li><strong>摘要总结</strong>: 高光谱图像（HSI）分类的深度学习模型虽然准确率高，但缺乏对其预测的严格置信度量化，这限制了其在安全关键领域的应用。本文首次从理论上证明了新兴的不确定性量化技术——保形预测（Conformal Prediction）在HSI分类任务中的有效性。在此基础上，文章提出了一个名为“空间感知保形预测”（Spatial-Aware Conformal Prediction, SACP）的框架。该框架通过聚合具有高空间相关性像素的非符合性分数，有效地利用了HSI数据中固有的空间信息，从而在保证用户指定的覆盖率（例如95%）的同时，提高了预测集的效率（即减小了预测集的大小）。</li>\n<li><strong>贡献和创新总结</strong>: 本文首次验证了保形预测在高光谱图像分类中的理论有效性，并提出一种融合空间信息的SACP框架，以生成更高效（更小）且有理论保证的预测集。</li>\n</ul>\n<h3>1. 任务和模型 (任务和模型)</h3>\n<ul>\n<li><strong>基本任务</strong>: 文章旨在解决高光谱图像（HSI）分类中的不确定性量化问题。传统的分类任务是为每个像素预测一个单一的类别标签，而本文的任务是为每个像素生成一个<strong>预测集</strong> (Prediction Set) <span class=\"math\">$C(x)$</span>，并提供理论保证，确保真实标签 <span class=\"math\">$Y$</span> 以用户指定的概率 <span class=\"math\">$1-\\alpha$</span> 包含在这个集合中，即 <pre class=\"math\">$<span class=\"math\">$P(Y \\in C(X)) \\ge 1-\\alpha$</span>$</pre>。</li>\n<li><strong>模型设定</strong>: 该方法设定在一个“后处理”（post-hoc）框架下。它不改变任何预先训练好的HSI分类器（如CNN、Transformer等），而是将其输出的概率分布作为输入，通过保形预测的统计框架来生成预测集。该框架是<strong>分布无关</strong>的，不依赖任何关于数据分布或模型结构的假设。</li>\n<li><strong>简单例子</strong>:<ul>\n<li><strong>数据</strong>: 一张Indian Pines高光谱图像，其中每个像素点周围的一个小立方体（cuboid）<span class=\"math\">$B_i$</span> 是一个数据样本，其真实标签 <span class=\"math\">$y_i$</span> 是对应的地物类别（如“玉米”、“大豆”等）。</li>\n<li><strong>任务</strong>: 传统的分类器可能会预测像素 <span class=\"math\">$i$</span> 的类别是“玉米”。而本文的任务是生成一个集合，例如 <span class=\"math\">$C(B_i) = \\{\\text{玉米}, \\text{大豆}\\}$</span>，并保证真实标签有95%的概率落入这个集合中。一个更高效的方法应该在满足95%覆盖率的同时，让这个集合尽可能小（例如，只包含“玉米”）。</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法 (方法)</h3>\n<p>该研究的核心方法是<strong>空间感知保形预测 (SACP)</strong>，它改进了标准的保形预测流程。</p>\n<ol>\n<li><strong>标准保形预测流程</strong>:<ul>\n<li><strong>非符合性分数 (Non-conformity Score)</strong>: 定义一个分数函数 <span class=\"math\">$S(x,y)$</span> 来衡量样本 <span class=\"math\">$x$</span> 与标签 <span class=\"math\">$y$</span> 的不匹配程度。分数越高，表示 <span class=\"math\">$y$</span> 越不可能是 <span class=\"math\">$x$</span> 的真实标签。例如，常用的APS分数为：\n<pre class=\"math\">$<span class=\"math\">$S_{APS}(x,y) = \\sum_{y' \\neq y} \\pi_{\\theta, y'}(x) + u \\cdot \\pi_{\\theta, y}(x)$</span>$</pre>\n其中 <span class=\"math\">$\\pi_{\\theta,y}(x)$</span> 是模型预测 <span class=\"math\">$x$</span> 属于类别 <span class=\"math\">$y$</span> 的概率，<span class=\"math\">$u \\sim U[0,1]$</span> 是一个微小的随机扰动。</li>\n<li><strong>阈值校准</strong>: 使用一个独立的校准集 <span class=\"math\">$D_{cal} = \\{(x_i, y_i)\\}_{i=1}^n$</span>，计算每个样本的非符合性分数 <span class=\"math\">$s_i = S(x_i, y_i)$</span>。然后找到这些分数的 <span class=\"math\">$\\frac{\\lceil(n+1)(1-\\alpha)\\rceil}{n}$</span> 分位数作为阈值 <span class=\"math\">$\\tau$</span>。\n<pre class=\"math\">$<span class=\"math\">$\\tau = \\inf\\left\\{s \\mid \\frac{|\\{i: s_i \\le s\\}|}{n} \\ge \\frac{\\lceil(n+1)(1-\\alpha)\\rceil}{n}\\right\\}$</span>$</pre></li>\n<li><strong>生成预测集</strong>: 对于一个新的测试样本 <span class=\"math\">$x_{test}$</span>，其预测集包含所有非符合性分数不超过阈值 <span class=\"math\">$\\tau$</span> 的候选标签：\n<pre class=\"math\">$<span class=\"math\">$C(x_{test}) = \\{y \\in \\mathcal{Y} \\mid S(x_{test}, y) \\le \\tau\\}$</span>$</pre></li>\n</ul>\n</li>\n<li><strong>空间感知保形预测 (SACP)</strong>:\nSACP认为标准流程忽略了HSI中像素间的空间相关性。它通过一个<strong>分数聚合算子 (Score Aggregation Operator) <span class=\"math\">$V_k$</span></strong> 来迭代地聚合邻域信息，从而优化非符合性分数。<ul>\n<li><strong>初始化</strong>: 设 <span class=\"math\">$V_0(B_i, y) = S(B_i, y)$</span>，即初始分数为标准非符合性分数，<span class=\"math\">$B_i$</span> 是像素 <span class=\"math\">$i$</span> 的数据块。</li>\n<li><strong>迭代聚合</strong>:\n<pre class=\"math\">$<span class=\"math\">$V_k(B_i, y) = (1-\\lambda)V_{k-1}(B_i, y) + \\frac{\\lambda}{|N_i|} \\sum_{B_j \\in N_i} V_{k-1}(B_j, y)$</span>$</pre>\n其中，<span class=\"math\">$k$</span> 是迭代次数，<span class=\"math\">$N_i$</span> 是像素 <span class=\"math\">$i$</span> 的邻域，<span class=\"math\">$λ \\in [0,1]$</span> 是权衡中心像素和邻域信息的超参数。这个过程实质上是对非符合性分数在空间上进行平滑。</li>\n<li>SACP使用聚合后的分数 <span class=\"math\">$V_k(B_i, y)$</span> 替代标准分数 <span class=\"math\">$S(B_i, y)$</span> 来执行校准和预测步骤，从而得到更小的预测集。</li>\n</ul>\n</li>\n</ol>\n<h3>3. 理论保证 (理论)</h3>\n<ul>\n<li><strong>为什么该方法有效？</strong><ol>\n<li><strong>保形预测在HSI中的有效性 (理论贡献1)</strong>: 标准保形预测要求校准集和测试集数据是<strong>可交换的 (exchangeable)</strong>。但在HSI分类中，模型训练时通常会接触到整张图像，这可能破坏该假设。<strong>定理2</strong> 证明，只要非符合性分数函数 <span class=\"math\">$S(B,y)$</span> 的计算对于校准集和测试集的划分是<strong>排列不变的</strong>（即打乱校准集和测试集样本的顺序不影响分数计算），那么从这些样本计算出的<strong>非符合性分数仍然是可交换的</strong>。这为保形预测在HSI场景下的应用提供了坚实的理论基础，保证了覆盖率 <span class=\"math\">$P(Y \\in C(X)) \\geq 1-\\alpha$</span>。</li>\n<li><strong>SACP的有效性 (理论贡献2)</strong>: <strong>命题1</strong> 从理论上解释了为什么融合空间信息是有效的。它指出，通过聚合邻域信息（即使用平滑后的分数 <span class=\"math\">$\\tilde{S}$</span>），一个来自校准集的分数 <span class=\"math\">$s_{cal}$</span> 大于一个来自<strong>错误匹配</strong>的测试对 <span class=\"math\">$(x_{test}, y_{wrong})$</span> 的分数 <span class=\"math\">$s_{test}$</span> 的经验概率会降低。这意味着错误标签的分数被系统性地“推高”了，因此它们更容易被阈值排除，从而使得预测集更小、更高效。</li>\n<li><strong>SACP的覆盖率保证 (理论贡献3)</strong>: <strong>命题2</strong> 通过数学归纳法证明，SACP的分数聚合算子 <span class=\"math\">$V_k$</span> 保持了分数的<strong>可交换性</strong>。因此，即使在聚合邻域信息后，SACP生成的预测集依然能满足用户指定的覆盖率保证 <pre class=\"math\">$<span class=\"math\">$P(Y \\in C(X)) \\ge 1-\\alpha$</span>$</pre>。</li>\n</ol>\n</li>\n</ul>\n<h3>4. 算法 (算法)</h3>\n<p>SACP的完整算法流程 (算法1) 如下：\n<strong>输入</strong>: 训练集 <span class=\"math\">$D_{train}$</span>，校准集 <span class=\"math\">$D_{cal}$</span>，测试数据块 <span class=\"math\">$B_{n+1}$</span>，错误率 <span class=\"math\">$\\alpha$</span>，聚合迭代次数 <span class=\"math\">$k$</span> 和权重 <span class=\"math\">$\\lambda$</span>。\n<strong>输出</strong>: 预测集 <span class=\"math\">$\\hat{C}_{1-\\alpha}(B_{n+1}; \\hat{\\tau})$</span>。</p>\n<ol>\n<li><strong>训练模型</strong>: 使用 <span class=\"math\">$D_{train}$</span> 训练一个深度HSI分类器 <span class=\"math\">$\\pi_{\\theta}$</span>。</li>\n<li><strong>定义分数函数</strong>: 基于 <span class=\"math\">$\\pi_{\\theta}$</span> 定义一个基础非符合性分数函数 <span class=\"math\">$S$</span> (如APS)。</li>\n<li><strong>计算聚合分数</strong>:<ul>\n<li>对于校准集 <span class=\"math\">$D_{cal}$</span> 中的每一个样本 <span class=\"math\">$(B_i, y_i)$</span>，使用分数聚合算子 <span class=\"math\">$V_k$</span> 计算其聚合后的分数\n<pre class=\"math\">$<span class=\"math\">$\\hat{s}_i = V_k(B_i, y_i)$</span>$</pre></li>\n</ul>\n</li>\n<li><strong>确定阈值</strong>: 基于聚合后的校准分数集 <span class=\"math\">$\\{\\hat{s}_i \\}_{i=1}^{N_2}$</span> (其中 <span class=\"math\">$N_2 = |D_{cal}|$</span>) 计算阈值 <span class=\"math\">$\\hat{\\tau}$</span>：\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\tau} = \\text{Quantile}(\\{\\hat{s}_i\\}, \\frac{\\lceil(N_2+1)(1-\\alpha)\\rceil}{N_2})$</span>$</pre></li>\n<li><strong>生成预测集</strong>: 对于测试数据块 <span class=\"math\">$B_{n+1}$</span>，计算所有候选标签 <span class=\"math\">$y \\in \\mathcal{Y}$</span> 的聚合分数，并构建预测集：\n<pre class=\"math\">$<span class=\"math\">$\\hat{C}_{1-\\alpha}(B_{n+1}; \\hat{\\tau}) := \\{y \\in \\mathcal{Y} \\mid V_k(B_{n+1}, y) \\le \\hat{\\tau}\\}$</span>$</pre></li>\n</ol>\n<h3>5. 实验 (实验)</h3>\n<ul>\n<li><strong>实验设计</strong>:<ul>\n<li><strong>数据集</strong>: 使用了三个经典的HSI数据集：Indian Pines (IP), Pavia University (PU), 和 Salinas (SA)。</li>\n<li><strong>基础模型</strong>: 为了验证方法的普适性，实验在四种不同的HSI分类器上进行：1D-CNN, 3D-CNN, HybridSN (混合CNN), 和 SSTN (Transformer)。</li>\n<li><strong>对比方法</strong>: 主要对比了<strong>标准保形预测 (SCP)</strong> 和本文提出的 <strong>SACP</strong>。</li>\n<li><strong>评价指标</strong>:<ul>\n<li><strong>Coverage (覆盖率)</strong>: 真实标签被包含在预测集中的样本比例，应接近 <span class=\"math\">$1-\\alpha$</span>。</li>\n<li><strong>Size (尺寸)</strong>: 预测集的平均大小，越小越好。</li>\n<li><strong>SSCV (尺寸分层覆盖偏差)</strong>: 衡量不同尺寸预测集的条件覆盖率与目标覆盖率的最大偏差，越小越好。</li>\n</ul>\n</li>\n<li><strong>实验设置</strong>: 错误率 <span class=\"math\">$\\alpha$</span> 设置为0.05和0.1。SACP的超参数默认设置为 <span class=\"math\">$k=1, \\lambda=0.5$</span>。</li>\n</ul>\n</li>\n<li><strong>实验结果</strong>:<ol>\n<li><strong>有效性验证</strong>: 实验结果（表III）表明，无论是SCP还是SACP，在所有数据集和模型上都能<strong>稳定地达到预设的覆盖率</strong>（例如，当 <span class=\"math\">$\\alpha=0.05$</span> 时，覆盖率约等于0.95）。这有力地验证了文章的理论。</li>\n<li><strong>SACP效率更高</strong>: SACP在保持相同覆盖率的前提下，<strong>显著减小了预测集的平均尺寸</strong>。例如，在IP数据集上，使用3D-CNN和APS分数，当 <span class=\"math\">$\\alpha=0.05$</span> 时，SCP的平均尺寸为5.73，而SACP降至3.27，尺寸减小了42.9%。这说明SACP能生成更精确、更高效的预测集。</li>\n<li><strong>可视化分析</strong>: 图2的可视化结果直观地展示了SACP的优势。与SCP相比，SACP生成的预测集尺寸图（c, g）整体颜色更暗，表示预测集尺寸普遍更小，尤其是在地物类别单一的平滑区域。</li>\n<li><strong>鲁棒性分析</strong>: 实验还表明，SACP对超参数 <span class=\"math\">$k, \\lambda$</span> 和校准集大小不敏感（图3，表IV），在很大范围内都能稳定地优于SCP，显示了其在实际应用中的鲁棒性和易用性。</li>\n</ol>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-11T02:46:04Z",
          "dateModified": "2025-11-11T02:46:04Z",
          "uri": "http://zotero.org/users/4752290/items/KSIBJW8K"
        }
      ],
      "citationKey": "liu2025spatialaware",
      "itemKey": "S7GQBUGC",
      "libraryID": 1,
      "select": "zotero://select/library/items/S7GQBUGC"
    },
    {
      "key": "7RFYDCPX",
      "version": 41574,
      "itemType": "computerProgram",
      "title": "MTAFT: data-driven estimation for multi-threshold accelerate failure time model",
      "abstractNote": "Developed a data-driven estimation framework for the multi-threshold accelerate failure time (MTAFT) model. The MTAFT model features different linear forms in different subdomains, and one of the major challenges is determining the number of threshold effects. The package introduces a data-driven approach that utilizes a Schwarz' information criterion, which demonstrates consistency under mild conditions. Additionally, a cross-validation (CV) criterion with an order-preserved sample-splitting scheme is proposed to achieve consistent estimation, without the need for additional parameters. The package establishes the asymptotic properties of the parameter estimates and includes an efficient score-type test to examine the existence of threshold effects. The methodologies are supported by numerical experiments and theoretical results, showcasing their reliable performance in finite-sample cases.",
      "date": "2023-11-13",
      "shortTitle": "MTAFT",
      "archive": "CRAN",
      "libraryCatalog": "R-Packages",
      "url": "https://cran.r-project.org/web/packages/MTAFT/index.html",
      "accessDate": "2024-08-06T20:02:55Z",
      "rights": "GPL-3",
      "versionNumber": "0.1.0",
      "creators": [
        {
          "firstName": "Chuang",
          "lastName": "Wan",
          "creatorType": "programmer"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "programmer"
        },
        {
          "firstName": "Wei",
          "lastName": "Zhong",
          "creatorType": "programmer"
        },
        {
          "firstName": "Changliang",
          "lastName": "Zou",
          "creatorType": "programmer"
        }
      ],
      "tags": [],
      "relations": {},
      "inPublications": true,
      "dateAdded": "2024-08-06T20:02:55Z",
      "dateModified": "2025-08-13T02:22:31Z",
      "uri": "http://zotero.org/users/4752290/items/7RFYDCPX",
      "itemID": 1117,
      "attachments": [],
      "notes": [],
      "citationKey": "wan2023mtaft",
      "itemKey": "7RFYDCPX",
      "libraryID": 1,
      "select": "zotero://select/library/items/7RFYDCPX"
    },
    {
      "key": "GGHGTVWM",
      "version": 44335,
      "itemType": "journalArticle",
      "title": "Data‐driven estimation for multithreshold accelerated failure time model",
      "abstractNote": "Abstract\n            This article develops a novel estimation framework for the multithreshold accelerated failure time model, which has distinct linear forms within different subdomains. One major challenge is to determine the number of threshold effects. We first show the selection consistency of a modified Bayesian information criterion under mild conditions. It is useful sometimes but heavily depends on the penalization magnitude, which usually varies from the model configuration and data distribution. To address this issue, we leverage a cross‐validation criterion alongside an order‐preserved sample‐splitting scheme to yield a consistent estimation. The new criterion is completely data driven without additional parameters and thus robust to model setting and data distributions. The asymptotic properties for the parameter estimates are also carefully established. Additionally, we propose an efficient score‐type test to examine the existence of threshold effects. The new statistic is free of estimating any potential threshold effects and is thus suitable for multithreshold scenarios. Numerical experiments validate the reliable finite‐sample performance of our methodologies, which corroborates the theoretical results.",
      "date": "2024-11-10",
      "language": "en",
      "libraryCatalog": "DOI.org (Crossref)",
      "url": "https://onlinelibrary.wiley.com/doi/10.1111/sjos.12758",
      "accessDate": "2024-12-19T02:37:59Z",
      "extra": "GSCC: 0000000 2025-10-19T06:09:16.098Z 0.00",
      "pages": "sjos.12758",
      "publicationTitle": "Scandinavian Journal of Statistics",
      "DOI": "10.1111/sjos.12758",
      "journalAbbreviation": "Scandinavian J Statistics",
      "ISSN": "0303-6898, 1467-9469",
      "creators": [
        {
          "firstName": "Chuang",
          "lastName": "Wan",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Wenyang",
          "lastName": "Zhang",
          "creatorType": "author"
        },
        {
          "firstName": "Wei",
          "lastName": "Zhong",
          "creatorType": "author"
        },
        {
          "firstName": "Changliang",
          "lastName": "Zou",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "#model/threshold"
        },
        {
          "tag": "#task/accelerated-failure-time-model"
        }
      ],
      "relations": {},
      "inPublications": true,
      "dateAdded": "2024-12-19T02:37:59Z",
      "dateModified": "2025-10-19T06:09:16Z",
      "uri": "http://zotero.org/users/4752290/items/GGHGTVWM",
      "itemID": 4257,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "2024, Wan et al., Data‐driven estimation for multithreshold accelerated failure time model.pdf",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-03-05T11:25:56Z",
          "dateModified": "2025-03-05T11:25:57Z",
          "uri": "http://zotero.org/users/4752290/items/6NRHXHUT",
          "path": "/Users/zengh/Zotero/storage/6NRHXHUT/2024_Wan et al._Data‐driven estimation for multithreshold accelerated failure time model.pdf",
          "select": "zotero://select/library/items/6NRHXHUT"
        }
      ],
      "notes": [
        {
          "key": "8T4CU42P",
          "version": 45346,
          "itemType": "note",
          "parentItem": "GGHGTVWM",
          "note": "<h2>AI 管家 - Data‐driven estimation for multithreshold accelerated failure time model</h2>\n<div><p>好的，这是一篇关于多阈值加速失效时间模型的数据驱动估计方法的论文总结。</p>\n<h3>0. 标题、作者、摘要及贡献</h3>\n<ul>\n<li><strong>标题</strong>: Data-driven estimation for multithreshold accelerated failure time model</li>\n<li><strong>作者</strong>: Chuang Wan, Hao Zeng, Wenyang Zhang, Wei Zhong, Changliang Zou</li>\n<li><strong>摘要总结</strong>: 本文为多阈值加速失效时间模型（multithreshold accelerated failure time model）开发了一个新的估计框架。该模型在由某个阈值变量划分的不同子域中具有不同的线性形式。一个核心挑战是确定阈值（thresholds）的数量。文章首先证明了一个修正的贝叶斯信息准则（mBIC）在温和条件下对选择阈值个数是一致的，但其实用性受限于惩罚项大小的设定。为了解决这个问题，文章提出了一种基于有序样本分割（order-preserved sample-splitting）的交叉验证准则（OPCV），它能够一致地估计阈值数量。该准则完全由数据驱动，无需调整额外参数。文章还建立了参数估计的渐近性质，并提出了一个高效的得分型检验（score-type test）来判断是否存在阈值效应。</li>\n<li><strong>一句话总结贡献和创新</strong>: 本文提出了一种数据驱动的、基于有序交叉验证（OPCV）的稳健方法来一致地估计多阈值加速失效时间模型中的阈值数量，并开发了一个无需估计阈值的得分检验来判断阈值效应的存在性。</li>\n</ul>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><strong>基本任务</strong>: 本文的主要任务是在一个多阈值加速失效时间模型中，以数据驱动的方式估计未知的<strong>阈值数量</strong> <span class=\"math\">$K^*$</span>、<strong>阈值位置</strong> <span class=\"math\">$\\tau_k^*$</span> 和每个子域内的<strong>回归系数</strong> <span class=\"math\">$\\beta_k^*$</span>。最核心的挑战是确定阈值的数量 <span class=\"math\">$K^*$</span>。</li>\n<li><strong>模型设定</strong>: 文章设定在<strong>多阈值加速失效时间模型 (multithreshold accelerated failure time, AFT)</strong> 下，并考虑了<strong>右删失 (right-censoring)</strong> 数据。<ul>\n<li><strong>模型</strong>: 设 <span class=\"math\">$T_i$</span> 为第 <span class=\"math\">$i$</span> 个体的真实（未删失）事件时间，<span class=\"math\">$X_i$</span> 是协变量向量，<span class=\"math\">$Z_i$</span> 是一个单变量阈值变量，<span class=\"math\">$\\epsilon_i$</span> 是随机误差。模型被定义为分段线性的形式：\n<pre class=\"math\">$<span class=\"math\">$T_i = X_i^\\top \\beta_k^* + \\epsilon_i, \\quad \\text{当 } \\tau_k^* < Z_i \\le \\tau_{k+1}^* \\text{ 时，对于 } k = 0, \\dots, K^*$</span>$</pre>\n其中，<span class=\"math\">$K^*$</span> 是未知的阈值数量，<span class=\"math\">$\\tau_k^*$</span> 是未知的阈值点，<span class=\"math\">$\\beta_k^*$</span> 是第 <span class=\"math\">$k$</span> 个子域对应的未知回归系数向量。</li>\n<li><strong>数据</strong>: 由于存在删失，我们观测到的数据是 <span class=\"math\">$Y_i = \\min(T_i, C_i)$</span> 和事件指示符 <span class=\"math\">$\\delta_i = \\mathbb{I}(T_i \\le C_i)$</span>，其中 <span class=\"math\">$C_i$</span> 是删失时间。</li>\n</ul>\n</li>\n<li><strong>简单例子</strong>:<ul>\n<li><strong>数据</strong>: 收集一批乳腺癌患者的数据。对于每个患者 <span class=\"math\">$i$</span>，我们有：<ul>\n<li>观测到的生存时间 <span class=\"math\">$Y_i$</span>（如36个月）。</li>\n<li>生存状态 <span class=\"math\">$\\delta_i$</span>（1代表去世，0代表失访或研究结束时仍存活）。</li>\n<li>协变量 <span class=\"math\">$X_i$</span>（如治疗方案、肿瘤大小、基因表达水平）。</li>\n<li>一个特殊的阈值变量 <span class=\"math\">$Z_i$</span>（如诊断时的年龄）。</li>\n</ul>\n</li>\n<li><strong>任务</strong>: 我们想知道患者的年龄 <span class=\"math\">$Z_i$</span> 是否会改变协变量 <span class=\"math\">$X_i$</span> 对其生存时间 <span class=\"math\">$T_i$</span> 的影响。例如，是否存在一个年龄阈值（比如59岁），使得59岁以下和59岁以上的患者，其治疗方案的效果（即对应的系数 <span class=\"math\">$\\beta_k^*$</span>）有显著不同？任务就是确定是否存在这样的阈值，有几个，以及它们分别是多少岁。</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法</h3>\n<p>本文提出了两种方法来确定阈值的数量 <span class=\"math\">$K$</span>，并提出了一种检验方法来判断是否存在阈值效应。</p>\n<ol>\n<li><strong>修正的贝叶斯信息准则 (modified Bayesian Information Criterion, mBIC)</strong><ul>\n<li>该方法通过最小化一个信息准则来选择最优的 <span class=\"math\">$K$</span>。这个准则在传统的对数似然项（这里是加权残差平方和）和一个惩罚项之间做权衡。</li>\n<li>数学表达为：\n<pre class=\"math\">$<span class=\"math\">$\\text{mBIC}(K) = \\log\\left\\{\\sum_{k=0}^{K} \\frac{b_k}{n} \\sum_{D_i \\in \\mathcal{D}(\\tau_k, \\tau_{k+1})} w_{[r_{y_i}, k]} (Y_i - X_i^\\top \\hat{\\beta}_k)^2\\right\\} + p(K+1)\\frac{c_0(\\log n)^{\\delta_0}}{n}$</span>$</pre>\n其中，第一项是模型的拟合优度度量，使用了处理删失数据的Kaplan-Meier权重 <span class=\"math\">$w_{[r_{y_i}, k]}$</span>；第二项是惩罚项，它随着模型复杂度（即 <span class=\"math\">$K$</span> 的增加）而增大，<span class=\"math\">$c_0$</span> 和 <span class=\"math\">$\\delta_0$</span> 是需要设定的惩罚参数。</li>\n</ul>\n</li>\n<li><strong>有序样本分割交叉验证 (Order-Preserved Cross-Validation, OPCV)</strong><ul>\n<li>这是本文的核心贡献，一个完全由数据驱动的方法。它不依赖于惩罚参数的选择。</li>\n<li><strong>核心思想</strong>: 不是随机划分数据，而是根据阈值变量 <span class=\"math\">$Z_i$</span> 的<strong>顺序</strong>，将样本分为奇数位置和偶数位置两个子集，分别作为训练集和验证集。这种划分方式能最大限度地保留原始数据的阈值结构。</li>\n<li><strong>步骤</strong>:<ol>\n<li>将数据按 <span class=\"math\">$Z_i$</span> 的值排序。将奇数序号的样本作为训练集 <span class=\"math\">$\\mathcal{D}_O$</span>，偶数序号的作为验证集 <span class=\"math\">$\\mathcal{D}_E$</span>。</li>\n<li>对于一个给定的 <span class=\"math\">$K$</span>，在训练集 <span class=\"math\">$\\mathcal{D}_O$</span> 上估计出模型 <span class=\"math\">$\\mathcal{M}_K^O$</span>（包括阈值位置）。</li>\n<li>在验证集 <span class=\"math\">$\\mathcal{D}_E$</span> 上计算该模型的预测误差 <span class=\"math\">$C(\\mathcal{M}_K^O; \\mathcal{D}_E)$</span>。</li>\n<li>交换训练集和验证集的角色，重复上述过程，得到误差 <span class=\"math\">$C(\\mathcal{M}_K^E; \\mathcal{D}_O)$</span>。</li>\n<li>选择使得总误差最小的 <span class=\"math\">$K$</span> 作为最优的阈值数量。</li>\n</ol>\n</li>\n<li>数学表达为：\n<pre class=\"math\">$<span class=\"math\">$\\hat{K}_{OPCV} = \\arg\\min_{K \\in \\mathcal{K}} \\left\\{ C(\\mathcal{M}_K^O; \\mathcal{D}_E) + C(\\mathcal{M}_K^E; \\mathcal{D}_O) \\right\\}$</span>$</pre>\n其中 <span class=\"math\">$C(\\cdot)$</span> 是一个基于得分函数（score function）的拟合优度度量，避免了反复估计回归系数 <span class=\"math\">$\\beta_k$</span>，提高了计算效率。</li>\n</ul>\n</li>\n<li><strong>检验阈值效应的存在性 (Score-type Test)</strong><ul>\n<li>在估计 <span class=\"math\">$K$</span> 之前，先检验是否存在任何阈值效应，即检验原假设 <span class=\"math\">$H_0: K=0$</span> vs 备择假设 <span class=\"math\">$H_1: K \\ge 1$</span>。</li>\n<li>本文提出了一个得分型检验统计量 <span class=\"math\">$L_n$</span>，它基于原假设下的残差构造。</li>\n<li>数学表达为：\n<pre class=\"math\">$<span class=\"math\">$L_n = \\sup_{\\tau \\in \\Gamma} \\|R_n(\\tau)\\|$</span>$</pre>\n其中 <span class=\"math\">$R_n(\\tau)$</span> 是一个在所有可能的阈值位置 <span class=\"math\">$\\tau$</span> 上计算的累积和过程，形式如下：\n<pre class=\"math\">$<span class=\"math\">$R_n(\\tau) = n^{-1/2} \\sum_{i=1}^n w_{[r_{y_i}]} \\{X_i \\mathbb{I}(Z_i \\le \\tau) - \\hat{Q}_1(\\tau)\\hat{Q}^{-1}X_i\\} \\hat{\\epsilon}_{0i}$</span>$</pre>\n这个统计量的优点在于计算它时<strong>无需估计备择假设下的任何参数</strong>，非常高效。</li>\n</ul>\n</li>\n</ol>\n<h3>3. 理论保证</h3>\n<ul>\n<li><strong>mBIC的有效性</strong>:<ul>\n<li><strong>理论保证</strong>: <strong>定理1</strong> 证明，在一定正则条件下，如果惩罚参数 <span class=\"math\">$\\delta_0 > 2$</span>，那么mBIC准则选择的阈值数量 <span class=\"math\">$\\hat{K}_{mBIC}$</span> 是一致的 (consistent)，即随着样本量 <span class=\"math\">$n \\to \\infty$</span>，<span class=\"math\">$\\Pr(\\hat{K}_{mBIC} = K^*) \\to 1$</span>。</li>\n<li><strong>理论贡献</strong>: 该定理从理论上阐明了传统的BIC (<span class=\"math\">$c_0=1, \\delta_0=1$</span>) 在这类问题中可能不具备一致性，因为它对模型过拟合的惩罚不够强。为了保证一致性，惩罚项需要比过拟合时残差平方和的下降速度更快，即惩罚项需要是 <span class=\"math\">$o(1/n)$</span> 但大于 <span class=\"math\">$O((\\log n)^2/n)$</span>。</li>\n</ul>\n</li>\n<li><strong>OPCV的有效性</strong>:<ul>\n<li><strong>理论保证</strong>: <strong>定理2</strong> 证明，在一定条件下，OPCV方法得到的阈值数量估计 <span class=\"math\">$\\hat{K}_{OPCV}$</span> 也是一致的。</li>\n<li><strong>理论贡献</strong>: 证明了这种数据驱动的交叉验证方法在理论上是可靠的。其有效性的直觉在于，当模型过拟合 (<span class=\"math\">$K > K^*$</span>) 时，交叉验证的预测误差项会扮演一个<strong>数据驱动的惩罚项</strong>角色，阻止选择过于复杂的模型。这避免了mBIC中需要人为设定惩罚力度的困难。</li>\n</ul>\n</li>\n<li><strong>参数估计的性质</strong>:<ul>\n<li><strong>理论保证</strong>: <strong>定理3</strong> 表明，当阈值数量 <span class=\"math\">$K^*$</span> 已知或被一致地估计出来后：<ol>\n<li>阈值位置的估计 <span class=\"math\">$\\hat{\\tau}_k$</span> 具有<strong>超一致性 (super-consistent)</strong>，其收敛速度为 <span class=\"math\">$O_p(n^{-1})$</span>。</li>\n<li>各子域的回归系数估计 <span class=\"math\">$\\hat{\\beta}_k$</span> 是<strong>渐近正态的 (asymptotically normal)</strong>，这为进行统计推断（如置信区间、假设检验）提供了理论基础。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><strong>得分检验的性质</strong>:<ul>\n<li><strong>理论保证</strong>: <strong>定理4</strong> 推导了检验统计量 <span class=\"math\">$L_n$</span> 在局部备择假设下的渐近分布。<strong>定理5</strong> 证明了用于计算临界值的Bootstrap重采样方法的有效性，因为 <span class=\"math\">$L_n$</span> 的极限分布依赖于未知参数（非枢轴量），无法直接使用。</li>\n</ul>\n</li>\n</ul>\n<h3>4. 算法</h3>\n<ol>\n<li><strong>OPCV确定阈值数量的算法 (Algorithm 1)</strong><ul>\n<li><strong>输入</strong>: 数据集 <span class=\"math\">$\\mathcal{D}$</span>，候选阈值数量集合 <span class=\"math\">$\\mathcal{K}$</span>。</li>\n<li><strong>步骤</strong>:<ol>\n<li>将数据按 <span class=\"math\">$Z_i$</span> 排序，划分为奇数集 <span class=\"math\">$\\mathcal{D}_O$</span> 和偶数集 <span class=\"math\">$\\mathcal{D}_E$</span>。</li>\n<li><strong>For</strong> 每个候选的 <span class=\"math\">$K \\in \\mathcal{K}$</span>:\na.  在 <span class=\"math\">$\\mathcal{D}_O$</span> 上使用一个变化点检测算法（如动态规划DP或二元分割WBS）找到 <span class=\"math\">$K$</span> 个阈值，构建模型 <span class=\"math\">$\\mathcal{M}_K^O$</span>。\nb.  在 <span class=\"math\">$\\mathcal{D}_E$</span> 上计算 <span class=\"math\">$\\mathcal{M}_K^O$</span> 的预测误差 <span class=\"math\">$C(\\mathcal{M}_K^O; \\mathcal{D}_E)$</span>。\nc.  交换角色，在 <span class=\"math\">$\\mathcal{D}_E$</span> 上构建模型 <span class=\"math\">$\\mathcal{M}_K^E$</span>，在 <span class=\"math\">$\\mathcal{D}_O$</span> 上计算预测误差 <span class=\"math\">$C(\\mathcal{M}_K^E; \\mathcal{D}_O)$</span>。\nd.  计算总误差 <span class=\"math\">$Err(K) = C(\\mathcal{M}_K^O; \\mathcal{D}_E) + C(\\mathcal{M}_K^E; \\mathcal{D}_O)$</span>。</li>\n<li><strong>输出</strong>: <span class=\"math\">$\\hat{K}_{OPCV} = \\arg\\min_{K \\in \\mathcal{K}} Err(K)$</span>。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><strong>模拟得分检验临界值的算法 (Algorithm 2)</strong><ul>\n<li><strong>输入</strong>: 原假设 <span class=\"math\">$H_0$</span> 下的估计量和残差。</li>\n<li><strong>步骤</strong>:<ol>\n<li>生成一组独立的标准正态随机变量 <span class=\"math\">$\\{v_i\\}_{i=1}^n$</span>。</li>\n<li>构造一个Bootstrap版本的检验统计量 <span class=\"math\">$L_n^*$</span>，它使用 <span class=\"math\">$v_i$</span> 替代真实残差 <span class=\"math\">$\\hat{\\epsilon}_{0i}$</span> 引入随机性：<span class=\"math\">$L_n^* = \\sup_{\\tau \\in \\Gamma} \\|R_n^*(\\tau)\\|$</span>。</li>\n<li>重复步骤1-2共 <span class=\"math\">$B$</span> 次，得到 <span class=\"math\">$L_n^*$</span> 的一个经验分布 <span class=\"math\">$\\{L_{n, b}^*\\}_{b=1}^B$</span>。</li>\n<li>通过比较原始数据计算出的 <span class=\"math\">$L_n$</span> 和这个经验分布，来计算p值: <span class=\"math\">$p = \\frac{1}{B} \\sum_{b=1}^B \\mathbb{I}(L_{n,b}^* \\ge L_n)$</span>。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ol>\n<h3>5. 实验设计与结果</h3>\n<p>实验分为模拟研究和真实数据分析两部分。</p>\n<ul>\n<li><strong>模拟研究设计</strong>:<ol>\n<li><strong>检验效力分析</strong>: 设计了<span class=\"math\">$K=1$</span>和<span class=\"math\">$K=2$</span>两种场景，通过调整一个参数<span class=\"math\">$a$</span>来控制阈值效应的大小（<span class=\"math\">$a=0$</span>表示没有阈值效应）。在不同样本量(200, 500)和删失率(20%, 40%)下，评估得分检验的性能。</li>\n<li><strong>选择一致性分析</strong>: 比较不同方法（带惩罚项的算法Pen和动态规划DP）结合不同准则（BIC, mBIC1, mBIC2, OPCV）在估计阈值数量 <span class=\"math\">$K$</span> 上的表现。考虑了多种数据生成设置（如不同的误差分布：正态分布和t分布）。</li>\n<li><strong>系数估计评估</strong>: 在使用OPCV正确估计出 <span class=\"math\">$K$</span> 的前提下，评估回归系数 <span class=\"math\">$\\hat{\\beta}_k$</span> 的估计偏差、标准差和置信区间覆盖率。</li>\n</ol>\n</li>\n<li><strong>模拟研究结果</strong>:<ol>\n<li><strong>检验效力</strong>: 得分检验在没有阈值效应时能很好地控制第一类错误率（接近5%），并且随着阈值效应增强、样本量增大或删失率降低，检验的效力（正确拒绝原假设的概率）会提高。</li>\n<li><strong>选择一致性</strong>:<ul>\n<li>传统的BIC准则总是倾向于<strong>高估</strong>阈值数量 <span class=\"math\">$K$</span>。</li>\n<li>mBIC表现优于BIC，但其结果对惩罚参数和误差分布<strong>非常敏感</strong>。</li>\n<li><strong>OPCV (DP+CV) 表现最为稳健和准确</strong>，在各种设置下都能高概率地选出正确的 <span class=\"math\">$K$</span>，且无需调参。其估计出的阈值位置误差（Hausdorff距离）也最小。</li>\n</ul>\n</li>\n<li><strong>系数估计</strong>: 使用OPCV方法后，回归系数的估计偏差很小，标准误的估计也很准确，置信区间的覆盖率接近95%，验证了理论的正确性。</li>\n</ol>\n</li>\n<li><strong>真实数据分析 (德国乳腺癌数据)</strong>:<ul>\n<li><strong>数据与任务</strong>: 使用德国乳腺癌数据集（686名患者），将诊断年龄作为阈值变量，分析协变量（年龄、治疗方案、肿瘤等级）对生存时间的影响是否随年龄变化。</li>\n<li><strong>分析结果</strong>:<ol>\n<li>得分检验表明存在阈值效应 (p-value=0.094)。</li>\n<li>不同方法给出了不同的阈值数量：惩罚方法估计为0个，BIC估计为4个，而<strong>OPCV估计出1个阈值，位于59岁</strong>。</li>\n<li>对年龄<span class=\"math\">$\\le 59$</span>和<span class=\"math\">$>59$</span>的两个亚组进行分析发现：协变量的影响确实存在异质性。例如，激素治疗对年轻患者组有显著的积极影响，但在年长患者组中不显著。</li>\n</ol>\n</li>\n<li><strong>结论</strong>: 这个例子表明，忽略阈值效应会掩盖重要的异质性信息，可能导致错误的医学结论。本文提出的OPCV方法成功地识别出了一个有临床意义的阈值点。</li>\n</ul>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:09:58Z",
          "dateModified": "2025-11-06T07:09:58Z",
          "uri": "http://zotero.org/users/4752290/items/8T4CU42P"
        }
      ],
      "citationKey": "wan2024datadriven",
      "itemKey": "GGHGTVWM",
      "libraryID": 1,
      "select": "zotero://select/library/items/GGHGTVWM"
    },
    {
      "key": "4XF9REAI",
      "version": 45853,
      "itemType": "conferencePaper",
      "title": "Exploring the noise robustness of online conformal prediction",
      "abstractNote": "Conformal prediction is an emerging technique for uncertainty quantification that constructs prediction sets guaranteed to contain the true label with a predefined probability. Recent work develops online conformal prediction methods that adaptively construct prediction sets to accommodate distribution shifts. However, existing algorithms typically assume *perfect label accuracy* which rarely holds in practice. In this work, we investigate the robustness of online conformal prediction under uniform label noise with a known noise rate. We show that label noise causes a persistent gap between the actual mis-coverage rate and the desired rate $\\alpha$, leading to either overestimated or underestimated coverage guarantees. To address this issue, we propose a novel loss function *robust pinball loss*, which provides an unbiased estimate of clean pinball loss without requiring ground-truth labels. Theoretically, we demonstrate that robust pinball loss enables online conformal prediction to eliminate the coverage gap under uniform label noise, achieving a convergence rate of $\\mathcal{O}(T^{-1/2})$ for both empirical and expected coverage errors (i.e., absolute deviation of the empirical and expected mis-coverage rate from the target level $\\alpha$). This loss offers a general solution to the uniform label noise, and is complementary to existing online conformal prediction methods. Extensive experiments demonstrate that the proposed loss enhances the noise robustness of various online conformal prediction methods by achieving a precise coverage guarantee.",
      "date": "2025-09-18",
      "language": "en",
      "libraryCatalog": "openreview.net",
      "url": "https://openreview.net/forum?id=3veDGO9KiK",
      "accessDate": "2025-10-14T10:50:39Z",
      "extra": "TLDR: Noise Robust Online Conformal Prediction is proposed by updating the threshold with a novel robust pinball loss, which provides an unbiased estimate of clean pinball loss without requiring ground-truth labels, and eliminates the coverage gap in both constant and dynamic learning rate schedules.\ntex.ids= 32ee173d-fa6b-47a0-8f10-f9af18ce6d1d, xi2025exploring\narXiv: 2501.18363 [cs]",
      "publisher": "arXiv",
      "proceedingsTitle": "The Thirty-ninth Annual Conference on Neural Information Processing Systems",
      "conferenceName": "Annual Conference on Neural Information Processing Systems",
      "creators": [
        {
          "firstName": "Huajun",
          "lastName": "Xi",
          "creatorType": "author"
        },
        {
          "firstName": "Kangdao",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Wenguang",
          "lastName": "Sun",
          "creatorType": "author"
        },
        {
          "firstName": "Hongxin",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "#method/conformal-prediction"
        }
      ],
      "relations": {
        "dc:replaces": [
          "http://zotero.org/users/4752290/items/SBII4R76"
        ]
      },
      "dateAdded": "2025-05-23T02:04:58Z",
      "dateModified": "2025-11-17T05:11:27Z",
      "uri": "http://zotero.org/users/4752290/items/4XF9REAI",
      "itemID": 5492,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "2025_Xi et al._Robust Online Conformal Prediction under Uniform Label Noise.pdf",
          "url": "http://arxiv.org/pdf/2501.18363v2",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-05-23T02:05:02Z",
          "dateModified": "2025-05-23T02:05:02Z",
          "uri": "http://zotero.org/users/4752290/items/2HAFD6TS",
          "path": "/Users/zengh/Zotero/storage/2HAFD6TS/2025_Xi et al._Robust Online Conformal Prediction under Uniform Label Noise.pdf",
          "select": "zotero://select/library/items/2HAFD6TS"
        },
        {
          "itemType": "attachment",
          "title": "10940_Exploring_the_Noise_Robu",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-05-22T18:05:01Z",
          "dateModified": "2025-11-11T02:12:23Z",
          "uri": "http://zotero.org/users/4752290/items/67NJJRWU",
          "path": "/Users/zengh/Zotero/storage/67NJJRWU/10940_Exploring_the_Noise_Robu.pdf",
          "select": "zotero://select/library/items/67NJJRWU"
        },
        {
          "itemType": "attachment",
          "title": "Preprint URL",
          "url": "http://arxiv.org/abs/2501.18363",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-11-11T02:12:23Z",
          "dateModified": "2025-11-11T02:12:23Z",
          "uri": "http://zotero.org/users/4752290/items/I7GW8LMT",
          "select": "zotero://select/library/items/I7GW8LMT"
        }
      ],
      "notes": [
        {
          "key": "XBVLVFFW",
          "version": 45624,
          "itemType": "note",
          "parentItem": "4XF9REAI",
          "note": "<h2>AI 管家 - Exploring the noise robustness of online conformal prediction</h2>\n<div><p>好的，这是一篇关于在线保形预测噪声鲁棒性的文章总结。</p>\n<h3>0. 标题、作者、摘要和贡献</h3>\n<ul>\n<li><strong>标题</strong>: Exploring the Noise Robustness of Online Conformal Prediction</li>\n<li><strong>作者</strong>: Anonymous Author(s)</li>\n<li><strong>摘要总结</strong>: 保形预测（Conformal prediction）是一种为模型预测提供量化不确定性的技术，它能构造一个以预定概率包含真实标签的预测集。现有的在线保形预测方法通常假设标签是完全准确的，但这在现实中很少成立。本文研究了在线保形预测在均匀标签噪声下的鲁棒性问题。研究发现，标签噪声会导致实际覆盖率与目标覆盖率之间产生持续的偏差。为解决此问题，本文提出了一种新颖的<strong>鲁棒弹球损失（robust pinball loss）</strong>，该损失函数能够在不知道真实标签的情况下，对干净标签下的弹球损失进行无偏估计。理论上，该方法可以消除标签噪声带来的覆盖率偏差，并使经验和期望覆盖误差均以 <span class=\"math\">$O(T^{-1/2})$</span> 的速度收敛。实验证明，该方法能有效提升多种在线保形预测方法的噪声鲁棒性，实现精确的覆盖率保障和更高的效率。</li>\n<li><strong>一句话贡献和创新</strong>: 本文提出了一种<strong>鲁棒弹球损失函数</strong>，首次从理论和实践上解决了已知噪声率的均匀标签噪声对在线保形预测的影响，实现了精确的覆盖率保证。</li>\n</ul>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><strong>基本任务</strong>: 本文的任务是在<strong>在线分类</strong>场景下，为模型预测构造一个<strong>预测集</strong>（Prediction Set）<span class=\"math\">$C_t(X_t)$</span>。这个预测集需要满足一个长期的<strong>覆盖率保证</strong>，即真实标签 <span class=\"math\">$Y_t$</span> 落在预测集 <span class=\"math\">$C_t(X_t)$</span> 内的概率接近一个用户预先设定的置信水平 <span class=\"math\">$1-\\alpha$</span>。数学上表示为：\n<pre class=\"math\">$<span class=\"math\">$ \\lim_{T\\to\\infty} \\frac{1}{T}\\sum_{t=1}^T \\mathbb{I}\\{Y_t \\in C_t(X_t)\\} = 1-\\alpha $</span>$</pre>\n其中 <span class=\"math\">$\\alpha$</span> 是用户可接受的错误率。</li>\n<li><strong>模型设定</strong>:<ol>\n<li><strong>在线学习（Online Learning）设定</strong>: 数据 <span class=\"math\">$(X_t, Y_t)$</span> 以数据流的形式依次到达。在第 <span class=\"math\">$t$</span> 步，模型接收输入 <span class=\"math\">$X_t$</span>，输出预测集 <span class=\"math\">$C_t(X_t)$</span>，然后才能观测到该步的标签（可能是带噪的）。</li>\n<li><strong>均匀标签噪声（Uniform Label Noise）模型</strong>: 算法在更新时观测到的标签 <span class=\"math\">$\\tilde{Y}_t$</span> 并非真实的 <span class=\"math\">$Y_t$</span>。它以 <span class=\"math\">$1-\\epsilon$</span> 的概率是真实的 <span class=\"math\">$Y_t$</span>，但以 <span class=\"math\">$\\epsilon$</span> 的概率变成一个从所有 <span class=\"math\">$K$</span> 个类别中随机均匀采样的新标签。其中，噪声率 <span class=\"math\">$\\epsilon$</span> 是已知的。数学上表示为：\n<pre class=\"math\">$<span class=\"math\">$ \\tilde{Y}_t = \\begin{cases} Y_t & \\text{with probability } 1-\\epsilon \\\\ \\bar{Y} & \\text{with probability } \\epsilon \\end{cases} $</span>$</pre>\n其中 <span class=\"math\">$\\bar{Y}$</span> 是从标签空间 <span class=\"math\">$\\mathcal{Y}=\\{1, ..., K\\}$</span> 中均匀随机抽取的标签。</li>\n</ol>\n</li>\n<li><strong>简单例子</strong>:<ul>\n<li><strong>数据</strong>: 一个图像分类器持续不断地接收新的图片（猫、狗、鸟），<span class=\"math\">$X_t$</span> 就是第 <span class=\"math\">$t$</span> 张图片。</li>\n<li><strong>任务</strong>: 对于每张图片 <span class=\"math\">$X_t$</span>，我们不只预测它是“猫”，而是输出一个标签集合，如 <span class=\"math\">$\\{$</span>猫, 狗<span class=\"math\">$\\}$</span>。我们的目标是使得在长期运行中，真实类别（比如图片确实是猫）有 95% 的时间都包含在我们给出的集合里（此时 <span class=\"math\">$\\alpha=0.05$</span>）。</li>\n<li><strong>噪声</strong>: 在我们做出预测后，系统提供给我们的“真实标签” <span class=\"math\">$\\tilde{Y}_t$</span> 有 10% 的概率是错的（<span class=\"math\">$\\epsilon=0.1$</span>）。比如，一张猫的图片可能被错误地标注为“鸟”。我们的算法必须在存在这种错误标注的情况下，依然能学习并保证 95% 的覆盖率。</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法</h3>\n<p>本文的核心解决方法是设计一个新的损失函数——<strong>鲁棒弹球损失（robust pinball loss）</strong>，用它来替代标准在线保形预测算法（如 ACI）中的标准弹球损失函数。</p>\n<ul>\n<li><strong>背景：标准方法</strong>: 标准的在线保形预测通过一个<strong>非整合分数（non-conformity score）</strong> <span class=\"math\">$S(X, Y)$</span> 来衡量样本 <span class=\"math\">$(X, Y)$</span> 的“异常”程度，分数越高越异常。预测集由分数低于某个动态阈值 <span class=\"math\">$\\hat{\\tau}_t$</span> 的所有类别构成：\n<pre class=\"math\">$<span class=\"math\">$C_t(X_t) = \\{y \\in \\mathcal{Y} : S(X_t, y) \\le \\hat{\\tau}_t\\}$</span>$</pre>\n阈值 <span class=\"math\">$\\hat{\\tau}_t$</span> 的更新依赖于<strong>弹球损失（pinball loss）</strong>:\n<pre class=\"math\">$<span class=\"math\">$l_{1-\\alpha}(\\tau, s) = \\alpha(\\tau-s)\\mathbf{1}\\{\\tau > s\\} + (1-\\alpha)(s-\\tau)\\mathbf{1}\\{\\tau \\le s\\}$</span>$</pre>\n其中 <span class=\"math\">$s=S(X_t, \\tilde{Y}_t)$</span> 是基于带噪标签计算的分数。由于 <span class=\"math\">$\\tilde{Y}_t$</span> 有噪声，导致对 <span class=\"math\">$l_{1-\\alpha}$</span> 的梯度估计有偏，从而使得覆盖率产生偏差。</li>\n<li><strong>核心方法：鲁棒弹球损失</strong>:\n作者发现，干净分数 <span class=\"math\">$S$</span> 的累积分布函数与带噪分数 <span class=\"math\">$\\tilde{S}$</span> 及所有类别的分数 <span class=\"math\">$\\{S_y\\}_{y=1}^K$</span> 的累积分布函数之间存在一个线性关系。基于此，他们构造了鲁棒弹球损失 <span class=\"math\">$\\tilde{l}_{1-\\alpha}$</span>，其核心思想是用带噪观测值来无偏地估计干净标签下的弹球损失。其数学表达式为（公式(4)）：\n<pre class=\"math\">$<span class=\"math\">$\\tilde{l}_{1-\\alpha}(\\tau, \\tilde{S}, \\{S_y\\}_{y=1}^K) = \\frac{1}{1-\\epsilon} l_{1-\\alpha}(\\tau, \\tilde{S}) - \\frac{\\epsilon}{K(1-\\epsilon)} \\sum_{y=1}^K l_{1-\\alpha}(\\tau, S_y)$</span>$</pre>\n其中，<span class=\"math\">$\\tilde{S}=S(X_t, \\tilde{Y}_t)$</span> 是基于带噪标签的分数，<span class=\"math\">$S_y=S(X_t, y)$</span> 是假设标签为 <span class=\"math\">$y$</span> 时的分数。该损失函数通过对带噪分数的损失进行加权放大，并减去一个由所有类别分数损失构成的修正项，来抵消噪声的影响。</li>\n<li><strong>最终方案</strong>: 将标准的在线保形预测算法（如ACI）中的更新规则的损失函数 <span class=\"math\">$l_{1-\\alpha}$</span> 替换为 <span class=\"math\">$\\tilde{l}_{1-\\alpha}$</span>。</li>\n</ul>\n<h3>3. 理论保证</h3>\n<p>该方法的有效性由其理论保证支持，核心理论贡献是证明了鲁棒弹球损失的<strong>无偏性</strong>以及使用该损失后在线保形预测的<strong>收敛性</strong>。</p>\n<ul>\n<li><strong>理论保证 (无偏性)</strong>: 鲁棒弹球损失的关键性质是，它在期望上等于干净标签下的真实弹球损失。这保证了使用它进行梯度更新在期望上是正确的。<strong>命题 4.1</strong> 指出：<ol>\n<li>损失值的期望相等:\n<pre class=\"math\">$<span class=\"math\">$\\mathbb{E}_S[l_{1-\\alpha}(\\tau, S)] = \\mathbb{E}_{\\tilde{S}, S_y}[\\tilde{l}_{1-\\alpha}(\\tau, \\tilde{S}, \\{S_y\\}_{y=1}^K)]$</span>$</pre></li>\n<li>梯度的期望相等:\n<pre class=\"math\">$<span class=\"math\">$\\mathbb{E}_S[\\nabla_\\tau l_{1-\\alpha}(\\tau, S)] = \\mathbb{E}_{\\tilde{S}, S_y}[\\nabla_\\tau \\tilde{l}_{1-\\alpha}(\\tau, \\tilde{S}, \\{S_y\\}_{y=1}^K)]$</span>$</pre>\n其中 <span class=\"math\">$S$</span> 是基于干净标签 <span class=\"math\">$Y_t$</span> 的分数。这意味着，尽管我们无法获取干净标签，但通过鲁棒弹球损失计算出的梯度在期望上与使用干净标签计算出的梯度完全一致。</li>\n</ol>\n</li>\n<li><strong>理论贡献 (收敛性)</strong>: 本文证明了，使用鲁棒弹球损失后，在线保形预测的<strong>经验覆盖误差 (EmErr)</strong> 和<strong>期望覆盖误差 (ExErr)</strong> 都能收敛到零。<ul>\n<li><strong>收敛速度</strong>: 无论使用恒定学习率还是动态学习率，覆盖误差都以 <span class=\"math\">$O(T^{-1/2})$</span> 的速度收敛。例如，对于经验覆盖误差（<strong>命题 4.3</strong>）：\n<pre class=\"math\">$<span class=\"math\">$EmErr(T) = \\left| \\frac{1}{T}\\sum_{t=1}^T \\mathbb{I}\\{Y_t \\notin C_t(X_t)\\} - \\alpha \\right| \\le O(T^{-1/2})$</span>$</pre>\n这为方法的有效性提供了强有力的理论支持，保证了算法在长期运行后能够精确地达到目标覆盖率 <span class=\"math\">$1-\\alpha$</span>。</li>\n</ul>\n</li>\n</ul>\n<h3>4. 算法</h3>\n<p>本文提出的算法是对现有在线保形预测算法（如ACI）的修正。核心是修改阈值 <span class=\"math\">$\\hat{\\tau}_t$</span> 的更新步骤。</p>\n<ul>\n<li><strong>标准ACI算法更新规则</strong>:\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\tau}_{t+1} = \\hat{\\tau}_t - \\eta \\cdot \\nabla_{\\hat{\\tau}_t} l_{1-\\alpha}(\\hat{\\tau}_t, S_t) = \\hat{\\tau}_t + \\eta \\cdot (\\mathbb{I}\\{Y_t \\notin C_t(X_t)\\} - \\alpha)$</span>$</pre>\n在标签带噪的情况下，上式中的 <span class=\"math\">$Y_t$</span> 被替换为 <span class=\"math\">$\\tilde{Y}_t$</span>。</li>\n<li><strong>本文提出的算法 (NR-OCP)</strong>: 将上述更新规则中的梯度替换为鲁棒弹球损失 <span class=\"math\">$\\tilde{l}_{1-\\alpha}$</span> 的梯度。以恒定学习率为例，其更新规则如<strong>公式 (5)</strong> 所示：\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\tau}_{t+1} = \\hat{\\tau}_t - \\eta \\cdot \\nabla_{\\hat{\\tau}_t} \\tilde{l}_{1-\\alpha}(\\hat{\\tau}_t, \\tilde{S}_t, \\{S_{t,y}\\}_{y=1}^K)$</span>$</pre>\n展开后为：\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\tau}_{t+1} = \\hat{\\tau}_t + \\eta \\left( \\frac{1}{1-\\epsilon} (\\mathbb{I}\\{\\tilde{Y}_t \\notin C_t(X_t)\\} - \\alpha) - \\frac{\\epsilon}{K(1-\\epsilon)} \\sum_{y=1}^K (\\mathbb{I}\\{y \\notin C_t(X_t)\\} - \\alpha) \\right)$</span>$</pre>\n其中 <span class=\"math\">$C_t(X_t)$</span> 是基于当前阈值 <span class=\"math\">$\\hat{\\tau}_t$</span> 构建的预测集。该算法在每一步接收带噪标签后，计算所有类别的非整合分数，然后使用上述规则更新阈值，用于下一步的预测。</li>\n</ul>\n<h3>5. 实验</h3>\n<p>实验设计旨在验证所提出的鲁棒弹球损失在不同设置下对在线保形预测的提升效果。</p>\n<ul>\n<li><strong>实验设计</strong>:<ol>\n<li><strong>数据集和模型</strong>: 在两个大规模图像分类数据集 <strong>CIFAR-100</strong> 和 <strong>ImageNet</strong> 上进行实验，使用了多种预训练的深度学习模型（如ResNet18, ResNet50等）。</li>\n<li><strong>噪声设置</strong>: 人为地向真实标签中注入不同水平的均匀标签噪声，噪声率 <span class=\"math\">$\\epsilon$</span> 分别取 <span class=\"math\">$\\{0.05, 0.1, 0.15\\}$</span>。</li>\n<li><strong>对比方法</strong>:<ul>\n<li><strong>Baseline</strong>: 标准的在线保形预测算法（ACI），直接使用带噪标签进行更新。</li>\n<li><strong>Ours</strong>: 使用本文提出的<strong>鲁棒弹球损失</strong>进行更新的ACI算法。</li>\n<li><strong>Clean (Oracle)</strong>: 使用完全干净的真实标签进行更新的ACI算法，作为性能的参照上限。</li>\n</ul>\n</li>\n<li><strong>评估场景</strong>: 实验覆盖了多种情况，包括：<ul>\n<li>两种学习率策略：恒定学习率和动态学习率。</li>\n<li>多种在线保形预测框架：除了ACI，还应用到了更先进的SAOCP。</li>\n<li>多种非整合分数函数：如LAC, APS, RAPS, SAPS。</li>\n</ul>\n</li>\n<li><strong>评估指标</strong>:<ul>\n<li><strong>覆盖率差距 (CovGap)</strong>: 最终的实际覆盖率与目标覆盖率 <span class=\"math\">$1-\\alpha$</span> 之间的绝对差值，越小越好。</li>\n<li><strong>预测集大小 (Size)</strong>: 预测集包含的平均类别数，越小表示预测越精确，效率越高。</li>\n<li><strong>长期/局部覆盖率</strong>: 观察覆盖率随时间变化的动态过程，看其是否能稳定在 <span class=\"math\">$1-\\alpha$</span> 附近。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><strong>实验结果</strong>:<ol>\n<li><strong>有效性</strong>: 实验结果（如图2和表1）清晰地表明，<strong>Baseline</strong>方法的覆盖率会随着噪声率 <span class=\"math\">$\\epsilon$</span> 的增大而严重偏离目标值 <span class=\"math\">$1-\\alpha$</span>。而<strong>Ours</strong>方法几乎完全消除了这个偏差，其覆盖率曲线与使用干净标签的<strong>Clean</strong>方法高度重合，精确地达到了目标水平。</li>\n<li><strong>效率</strong>: 在实现精确覆盖的同时，<strong>Ours</strong>方法生成的预测集大小（Size）显著小于<strong>Baseline</strong>方法。例如，在ImageNet上，当噪声率 <span class=\"math\">$\\epsilon=0.15$</span>，错误率 <span class=\"math\">$\\alpha=0.1$</span> 时，Baseline的预测集平均大小为171.2，而Ours仅为13.10。这说明该方法不仅修正了覆盖率，还大幅提升了预测的效率和信息量。</li>\n<li><strong>通用性</strong>: 该方法在不同的数据集、模型、保形预测算法、非整合分数和学习率策略下都表现出了一致的优越性，证明了其通用性和鲁棒性。</li>\n</ol>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:09:52Z",
          "dateModified": "2025-11-11T02:12:23Z",
          "uri": "http://zotero.org/users/4752290/items/XBVLVFFW"
        },
        {
          "key": "BF3W33SH",
          "version": 45210,
          "itemType": "note",
          "parentItem": "4XF9REAI",
          "note": "<h2>AI 管家 - Robust online conformal prediction under uniform label noise</h2>\n<div><p>好的，这是对该篇文章的总结：</p>\n<h3>0. 标题、作者、摘要及贡献总结</h3>\n<ul>\n<li><strong>标题 (英文)</strong>: Robust Online Conformal Prediction under Uniform Label Noise</li>\n<li><strong>作者</strong>: Huajun Xi, Kangdao Liu, Hao Zeng, Wenguang Sun, Hongxin Wei</li>\n<li><strong>摘要总结</strong>: 传统的在线共形预测（Online Conformal Prediction）方法能够为预测集提供理论上的覆盖率保证（即真实标签以预设概率落在预测集中），但这些方法通常假设标签是完全准确的。本文研究了在均匀标签噪声（Uniform Label Noise）下在线共形预测的鲁棒性问题。研究发现，标签噪声会导致实际覆盖率与目标覆盖率之间产生一个持续的偏差（coverage gap）。为了解决此问题，作者提出了<strong>噪声鲁棒的在线共形预测（Noise-Robust Online Conformal Prediction, NR-OCP）<strong>方法。该方法通过一个新颖的</strong>鲁棒 pinball loss</strong> 来更新阈值，它能够在不依赖真实标签的情况下，对干净标签下的 pinball loss 进行无偏估计。理论分析表明，NR-OCP 能够消除由标签噪声引起的覆盖率偏差，并使经验和期望覆盖误差都达到 <span class=\"math\">$O(T^{-1/2})$</span> 的收敛速度。</li>\n<li><strong>一句话贡献和创新</strong>: 本文的贡献在于提出了一种鲁棒的 pinball loss，用于在均匀标签噪声环境下无偏地估计真实 pinball loss 的梯度，从而校正了在线共形预测的覆盖率偏差，并提供了理论收敛保证。</li>\n</ul>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><strong>基本任务</strong>: 本文的任务是在<strong>在线学习（online learning）<strong>的设定下进行</strong>共形预测（conformal prediction）</strong>。具体而言，数据点 <span class=\"math\">$(X_t, Y_t)$</span> 按时间序列 <span class=\"math\">$t=1, 2, \\dots$</span> 到达，算法需要在每个时间步 <span class=\"math\">$t$</span> 为数据 <span class=\"math\">$X_t$</span> 构建一个预测集 <span class=\"math\">$C_t(X_t)$</span>，目标是使得真实标签 <span class=\"math\">$Y_t$</span> 长期来看落在预测集中的概率等于预设的置信水平 <span class=\"math\">$1-\\alpha$</span>（即长期错误覆盖率 Mis-coverage Rate 为 <span class=\"math\">$\\alpha$</span>）。\n<pre class=\"math\">$$\n    \\lim_{T\\to\\infty} \\frac{1}{T}\\sum_{t=1}^T \\mathbb{I}\\{Y_t \\in C_t(X_t)\\} = 1-\\alpha\n    $$</pre></li>\n<li><strong>模型设定</strong>: 本文的核心设定是在标准的在线共形预测之上，引入了<strong>均匀标签噪声（uniform label noise）</strong>。这意味着我们观测到的标签 <span class=\"math\">$\\tilde{Y}_t$</span> 并非真实的 <span class=\"math\">$Y_t$</span>，而是以一个已知的概率 <span class=\"math\">$\\epsilon$</span> 被一个从所有 <span class=\"math\">$K$</span> 个类别中随机均匀采样的标签所替代。\n<pre class=\"math\">$$\n    \\tilde{Y}_t = \\begin{cases} Y_t & \\text{with probability } 1-\\epsilon \\\\ \\text{Uniform}(\\{1, \\dots, K\\}) & \\text{with probability } \\epsilon \\end{cases}\n    $$</pre></li>\n<li><strong>问题示例</strong>:<ul>\n<li><strong>数据</strong>: 假设任务是图像分类，在时间步 <span class=\"math\">$t$</span>，我们收到一张新的猫的图片 <span class=\"math\">$X_t$</span>，其真实标签是 <span class=\"math\">$Y_t=\\text{'猫'}$</span>。</li>\n<li><strong>噪声</strong>: 由于标签噪声的存在（例如，标注员手误），我们观测到的标签可能是 <span class=\"math\">$\\tilde{Y}_t=\\text{'狗'}$</span>（以概率 <span class=\"math\">$\\epsilon$</span> 发生）。</li>\n<li><strong>任务</strong>: 算法需要输出一个标签集合 <span class=\"math\">$C_t(X_t)$</span>，例如 <span class=\"math\">$\\{\\text{'猫'}, \\text{'狗'}, \\text{'狐狸'}\\}$</span>。我们的目标是，即使我们用来学习和调整的数据标签是带噪声的（比如用&#39;狗&#39;来更新模型），长期来看，我们生成的预测集包含真实标签（&#39;猫&#39;）的频率也要稳定在 <span class=\"math\">$1-\\alpha$</span>（例如90%）。</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法</h3>\n<p>标准的在线共形预测通过在线梯度下降更新一个阈值 <span class=\"math\">$\\hat{\\tau}_t$</span> 来构建预测集 <span class=\"math\">$C_t(X_t) = \\{y: S(X_t, y) \\le \\hat{\\tau}_t\\}$</span>，其中 <span class=\"math\">$S$</span> 是一个不一致性分数（non-conformity score）。更新依赖于 <strong>pinball loss</strong> <span class=\"math\">$l_{1-\\alpha}$</span> 的梯度。在有噪声的情况下，我们只能计算基于噪声分数 <span class=\"math\">$\\tilde{S}_t = S(X_t, \\tilde{Y}_t)$</span> 的梯度，这导致了偏差。\n本文的解决方法是设计一个<strong>鲁棒的 pinball loss</strong> <span class=\"math\">$\\tilde{l}_{1-\\alpha}$</span>，其在期望上等价于使用干净标签时的 pinball loss。</p>\n<ol>\n<li><strong>核心思想</strong>: 作者发现，干净分数 <span class=\"math\">$S$</span> 的分布可以通过带噪分数 <span class=\"math\">$\\tilde{S}$</span> 和所有类别的分数 <span class=\"math\">$\\{S_y\\}_{y=1}^K$</span> 的分布线性表示。这启发他们用后两者的 pinball loss 来构造一个对干净 pinball loss 的无偏估计。</li>\n<li><strong>鲁棒 Pinball Loss</strong>: 作者将鲁棒 pinball loss 定义为两部分的差：\n<pre class=\"math\">$$\n    \\tilde{l}_{1-\\alpha}(\\tau, \\tilde{S}, \\{S_y\\}_{y=1}^K) = l_1(\\tau, \\tilde{S}) - l_2(\\tau, \\{S_y\\}_{y=1}^K)\n    $$</pre>\n其中，<span class=\"math\">$l_1$</span> 是对带噪分数的 pinball loss 进行缩放，<span class=\"math\">$l_2$</span> 是对所有类别分数的 pinball loss 的加权平均：\n<pre class=\"math\">$$\n    l_1(\\tau, \\tilde{S}) = \\frac{1}{1-\\epsilon}l_{1-\\alpha}(\\tau, \\tilde{S})\n    $$</pre>\n<pre class=\"math\">$$\n    l_2(\\tau, \\{S_y\\}_{y=1}^K) = \\frac{\\epsilon}{K(1-\\epsilon)}\\sum_{y=1}^K l_{1-\\alpha}(\\tau, S_y)\n    $$</pre>\n通过使用这个鲁棒 pinball loss 的梯度来更新阈值 <span class=\"math\">$\\hat{\\tau}_t$</span>，算法可以抵抗标签噪声的影响。</li>\n</ol>\n<h3>3. 理论保证</h3>\n<p>该方法的有效性主要基于以下理论保证：</p>\n<ol>\n<li><strong>无偏估计 (Unbiased Estimation)</strong>: 提出的鲁棒 pinball loss <span class=\"math\">$\\tilde{l}_{1-\\alpha}$</span> 及其梯度是对干净 pinball loss <span class=\"math\">$l_{1-\\alpha}$</span> 及其梯度的无偏估计。这是该方法的核心理论基石（Proposition 3.2）。<ul>\n<li><strong>损失值的无偏性</strong>:\n<pre class=\"math\">$$\n        \\mathbb{E}_{\\tilde{S},S_y}[\\tilde{l}_{1-\\alpha}(\\tau, \\tilde{S}, \\{S_y\\}_{y=1}^K)] = \\mathbb{E}_{S}[l_{1-\\alpha}(\\tau, S)]\n        $$</pre></li>\n<li><strong>梯度的无偏性</strong>:\n<pre class=\"math\">$$\n        \\mathbb{E}_{\\tilde{S},S_y}[\\nabla_{\\tau}\\tilde{l}_{1-\\alpha}(\\tau, \\tilde{S}, \\{S_y\\}_{y=1}^K)] = \\mathbb{E}_{S}[\\nabla_{\\tau}l_{1-\\alpha}(\\tau, S)]\n        $$</pre>\n这意味着，在期望意义上，使用鲁棒 loss 进行梯度更新等价于在无噪声环境下进行更新。</li>\n</ul>\n</li>\n<li><strong>理论贡献 (Convergence Guarantee)</strong>: 本文的主要理论贡献是证明了 NR-OCP 方法能够消除标签噪声导致的覆盖率偏差，并且<strong>经验覆盖误差 (Empirical Coverage Error)</strong> 和<strong>期望覆盖误差 (Expected Coverage Error)</strong> 都能以 <span class=\"math\">$O(T^{-1/2})$</span> 的速度收敛到零。\n<pre class=\"math\">$$\n    \\text{EmErr}(T) = \\left| \\frac{1}{T}\\sum_{t=1}^T \\mathbb{I}\\{Y_t \\notin C_t(X_t)\\} - \\alpha \\right| \\le O(T^{-1/2})\n    $$</pre>\n<pre class=\"math\">$$\n    \\text{ExErr}(T) = \\left| \\frac{1}{T}\\sum_{t=1}^T \\mathbb{P}\\{Y_t \\notin C_t(X_t)\\} - \\alpha \\right| \\le O(T^{-1/2})\n    $$</pre>\n这个结论在恒定学习率和动态学习率两种设定下都成立。</li>\n</ol>\n<h3>4. 算法</h3>\n<p>本文提出的 <strong>NR-OCP 算法</strong>是一个在线更新过程。在每个时间步 <span class=\"math\">$t$</span>，算法执行以下步骤：</p>\n<ol>\n<li>接收新数据 <span class=\"math\">$X_t$</span>，并获得其带噪声的标签 <span class=\"math\">$\\tilde{Y}_t$</span>。</li>\n<li>为所有可能的类别 <span class=\"math\">$y \\in \\{1,\\dots,K\\}$</span> 计算不一致性分数 <span class=\"math\">$S_{t,y} = S(X_t, y)$</span>。同时，得到带噪声的分数 <span class=\"math\">$\\tilde{S}_t = S(X_t, \\tilde{Y}_t)$</span>。</li>\n<li>使用鲁棒 pinball loss 的梯度更新阈值 <span class=\"math\">$\\hat{\\tau}_t$</span>：\n<pre class=\"math\">$$\n    \\hat{\\tau}_{t+1} = \\hat{\\tau}_t - \\eta_t \\cdot \\nabla_{\\tau}\\tilde{l}_{1-\\alpha}(\\hat{\\tau}_t, \\tilde{S}_t, \\{S_{t,y}\\}_{y=1}^K)\n    $$</pre>\n其中，梯度 <span class=\"math\">$\\nabla_{\\tau}\\tilde{l}_{1-\\alpha}$</span> 具体展开为：\n<pre class=\"math\">$$\n    \\nabla_{\\tau}\\tilde{l}_{1-\\alpha}(\\dots) = \\frac{1}{1-\\epsilon}[\\mathbb{I}\\{\\tilde{S}_t \\le \\hat{\\tau}_t\\} - (1-\\alpha)] - \\frac{\\epsilon}{K(1-\\epsilon)}\\sum_{y=1}^K [\\mathbb{I}\\{S_{t,y} \\le \\hat{\\tau}_t\\} - (1-\\alpha)]\n    $$</pre></li>\n<li>使用更新后的阈值 <span class=\"math\">$\\hat{\\tau}_{t+1}$</span> 为下一个数据点服务。</li>\n</ol>\n<h3>5. 实验设计与结果</h3>\n<ul>\n<li><strong>实验设计</strong>:<ul>\n<li><strong>数据集</strong>: 在两个标准图像分类数据集 CIFAR-100 和 ImageNet 上进行。</li>\n<li><strong>噪声设置</strong>: 人为地向标签中注入不同比例（<span class=\"math\">$\\epsilon \\in \\{0.05, 0.1, 0.15\\}$</span>）的均匀标签噪声。</li>\n<li><strong>对比方法</strong>:<ul>\n<li><strong>Baseline</strong>: 标准的在线共形预测方法，但直接使用带噪声的标签 <span class=\"math\">$\\tilde{Y}_t$</span> 来更新阈值。</li>\n<li><strong>Ours (NR-OCP)</strong>: 本文提出的噪声鲁棒方法。</li>\n<li><strong>Clean (Oracle)</strong>: 作为参照，使用真实的、无噪声的标签 <span class=\"math\">$Y_t$</span> 进行更新，代表了理想情况下的性能上限。</li>\n</ul>\n</li>\n<li><strong>评估指标</strong>:<ul>\n<li><strong>CovGap (覆盖率差距)</strong>: 实际的长期覆盖率与目标覆盖率 <span class=\"math\">$1-\\alpha$</span> 之间的绝对差值。值越小，说明覆盖率控制得越精确。</li>\n<li><strong>Size (预测集大小)</strong>: 预测集 <span class=\"math\">$C_t(X_t)$</span> 中包含的平均类别数量。在满足覆盖率的前提下，尺寸越小，说明预测越有效率和信息量。</li>\n</ul>\n</li>\n<li><strong>实验维度</strong>: 实验在不同模型架构（如 ResNet, DenseNet）、不同不一致性分数函数（如 LAC, APS）、不同错误率 <span class=\"math\">$\\alpha$</span> 以及恒定和动态学习率下进行，以验证方法的普适性。</li>\n</ul>\n</li>\n<li><strong>实验结果</strong>:<ul>\n<li><strong>覆盖率精确性</strong>: Baseline 方法随着噪声率 <span class=\"math\">$\\epsilon$</span> 的增加，其 <code>CovGap</code> 显著增大，实际覆盖率严重偏离目标。相比之下，本文提出的 NR-OCP 方法在所有噪声水平下都能将 <code>CovGap</code> 控制在接近于零的水平，几乎完美地达到了预设的目标覆盖率，表现与使用干净标签的 Clean 方法相当。</li>\n<li><strong>预测集效率</strong>: 在实现精确覆盖的同时，NR-OCP 生成的预测集 <code>Size</code> 也显著小于 Baseline。例如，在 ImageNet 上，当 <span class=\"math\">$\\alpha=0.1, \\epsilon=0.15$</span> 时，Baseline 的预测集平均大小为 318，而 NR-OCP 仅为 90.5，效率大幅提升。</li>\n<li><strong>总体结论</strong>: 实验结果有力地证明了 NR-OCP 不仅成功解决了标签噪声导致的覆盖率偏差问题，还提高了预测的效率（生成的预测集更小），在各种设置下都表现出优越的性能和鲁棒性。</li>\n</ul>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-05T22:51:45Z",
          "dateModified": "2025-11-05T22:51:45Z",
          "uri": "http://zotero.org/users/4752290/items/BF3W33SH"
        }
      ],
      "citationKey": "xi2025exploring",
      "itemKey": "4XF9REAI",
      "libraryID": 1,
      "select": "zotero://select/library/items/4XF9REAI"
    },
    {
      "key": "B9Z6EA2I",
      "version": 44333,
      "itemType": "journalArticle",
      "title": "Robust integrative analysis via quantile regression with homogeneity and sparsity",
      "abstractNote": "Integrative analysis plays a critical role in integrating heterogeneous data from multiple datasets to provide a comprehensive view of the overall data features. However, in multiple datasets, outliers and heavy-tailed data can render least squares estimation unreliable. In response, we propose a Robust Integrative Analysis via Quantile Regression (RIAQ) that accounts for homogeneity and sparsity in multiple datasets. The RIAQ approach is not only able to identify latent homogeneous coefficient structures but also recover the sparsity of high-dimensional covariates via double penalty terms. The integration of sample information across multiple datasets improves estimation efficiency, while a sparse model improves model interpretability. Furthermore, quantile regression allows the detection of subgroup structures under different quantile levels, providing a comprehensive picture of the relationship between response and high-dimensional covariates. We develop an efficient alternating direction method of multipliers (ADMM) algorithm to solve the optimization problem and study its convergence. We also derive the parameter selection consistency of the modified Bayesian information criterion. Numerical studies demonstrate that our proposed estimator has satisfactory finite-sample performance, especially in heavy-tailed cases.",
      "date": "2024-06-01",
      "language": "en-US",
      "libraryCatalog": "ScienceDirect",
      "url": "https://www.sciencedirect.com/science/article/pii/S0378375824000533",
      "accessDate": "2024-07-29T16:24:05Z",
      "extra": "GSCC: 0000003 2025-10-19T06:09:07.168Z 0.04 \ntitleTranslation: 稳健整合分析：基于同质性和稀疏性的分位数回归",
      "volume": "234",
      "pages": "106196",
      "publicationTitle": "Journal of Statistical Planning and Inference",
      "DOI": "10.1016/j.jspi.2024.106196",
      "journalAbbreviation": "Journal of Statistical Planning and Inference",
      "ISSN": "0378-3758",
      "creators": [
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Chuang",
          "lastName": "Wan",
          "creatorType": "author"
        },
        {
          "firstName": "Wei",
          "lastName": "Zhong",
          "creatorType": "author"
        },
        {
          "firstName": "Tuo",
          "lastName": "Liu",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "inPublications": true,
      "dateAdded": "2024-07-29T16:24:05Z",
      "dateModified": "2025-10-19T06:09:07Z",
      "uri": "http://zotero.org/users/4752290/items/B9Z6EA2I",
      "itemID": 21,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "PDF",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-08-08T10:03:07Z",
          "dateModified": "2024-08-08T10:03:07Z",
          "uri": "http://zotero.org/users/4752290/items/E7ASRA53",
          "path": "/Users/zengh/Zotero/storage/E7ASRA53/2025 - Zeng et al. - Robust Integrative Analysis via Quantile Regression with Homogeneity and Sparsity - Journal of Statistical Planning and Inference.pdf",
          "select": "zotero://select/library/items/E7ASRA53"
        }
      ],
      "notes": [
        {
          "key": "P75M3T2J",
          "version": 45343,
          "itemType": "note",
          "parentItem": "B9Z6EA2I",
          "note": "<h2>AI 管家 - Robust integrative analysis via quantile regression with homogeneity and sparsity</h2>\n<div><p>好的，这是一篇关于稳健整合分析的统计学论文，以下是我对其进行的简洁易懂且数学化的总结。</p>\n<h3>0. 标题、作者、摘要及贡献总结</h3>\n<ul>\n<li><strong>标题 (英文)</strong>: Robust Integrative Analysis via Quantile Regression with Homogeneity and Sparsity</li>\n<li><strong>作者</strong>: Hao Zeng, Chuang Wan, Wei Zhong, Tuo Liu</li>\n<li><strong>摘要总结</strong>: 传统的整合分析在使用最小二乘法时，容易受到多个数据集中异常值和重尾数据的影响。为解决此问题，本文提出了一种基于<strong>分位数回归的稳健整合分析方法 (RIAQ)</strong>。该方法能够通过双重惩罚项，同时识别多个数据集回归系数中潜在的<strong>同质性</strong>（即哪些系数在不同数据集中是相同的）和<strong>稀疏性</strong>（即哪些系数是无效的）。通过整合多个数据集的样本信息，该方法提高了估计效率；稀疏模型则提升了可解释性。此外，分位数回归的框架允许在不同分位数水平下探究变量关系的全貌。作者为此开发了高效的交替方向乘子法 (ADMM) 算法，并证明了其收敛性。同时，文章推导了改进的贝叶斯信息准则 (BIC) 在选择调节参数时的相合性。</li>\n<li><strong>一句话贡献和创新</strong>: 本文提出了一种基于分位数回归的稳健整合分析框架（RIAQ），通过双重惩罚项同时识别多个高维数据集中的同质性结构和稀疏性，并为此开发了高效的ADMM算法及提供了理论保证。</li>\n</ul>\n<hr>\n<h3>1. 任务和模型</h3>\n<p>这篇文章的基本任务是在存在多个（<span class=\"math\">$K$</span>个）独立数据集的场景下，进行<strong>高维线性回归分析</strong>。这些数据集可能具有异质性，即回归系数在不同数据集中不完全相同，但又存在潜在的共同结构（同质性），同时许多协变量可能是无关的（稀疏性）。由于数据可能包含异常值或服从重尾分布，模型需要具备<strong>稳健性</strong>。\n模型设定在<strong>分位数回归 (Quantile Regression)</strong> 框架下。对于给定的分位数水平 <span class=\"math\">$\\tau \\in (0,1)$</span>，模型如下：\n<pre class=\"math\">$<span class=\"math\">$y_{ik} = \\mathbf{x}_{ik}^\\top \\beta_k + \\epsilon_{ik}^{(\\tau)}$</span>$</pre>\n其中：</p>\n<ul>\n<li><span class=\"math\">$k=1, \\dots, K$</span> 表示数据集的索引。</li>\n<li><span class=\"math\">$i=1, \\dots, n_k$</span> 表示第 <span class=\"math\">$k$</span> 个数据集中样本的索引。</li>\n<li><span class=\"math\">$y_{ik} \\in \\mathbb{R}$</span> 是第 <span class=\"math\">$k$</span> 个数据集中第 <span class=\"math\">$i$</span> 个样本的响应变量。</li>\n<li><span class=\"math\">$\\mathbf{x}_{ik} \\in \\mathbb{R}^p$</span> 是对应的 <span class=\"math\">$p$</span> 维协变量向量。</li>\n<li><span class=\"math\">$\\beta_k \\in \\mathbb{R}^p$</span> 是第 <span class=\"math\">$k$</span> 个数据集的回归系数向量。</li>\n<li><span class=\"math\">$\\epsilon_{ik}^{(\\tau)}$</span> 是模型误差，满足条件 <span class=\"math\">$\\text{Pr}(\\epsilon_{ik}^{(\\tau)} < 0 | \\mathbf{x}_{ik}) = \\tau$</span>。\n<strong>核心假设</strong>:</li>\n</ul>\n<ol>\n<li><strong>同质性 (Homogeneity)</strong>: 对于某个协变量 <span class=\"math\">$j$</span>，其对应的系数在某些数据子集中是相同的，即 <span class=\"math\">$\\beta_{kj} = \\beta_{k'j}$</span> 对某些 <span class=\"math\">$k \\neq k'$</span> 成立。</li>\n<li><strong>稀疏性 (Sparsity)</strong>: 许多系数为零，即 <span class=\"math\">$\\beta_{kj} = 0$</span>。\n<strong>简单例子</strong>:</li>\n</ol>\n<ul>\n<li><strong>数据</strong>: 假设我们有来自 <span class=\"math\">$K=3$</span> 个不同城市（数据集）的房价数据。每个数据包含房屋特征 (面积、地段、房龄等，构成协变量 <span class=\"math\">$\\mathbf{x}_{ik}$</span>) 和房价 (响应变量 <span class=\"math\">$y_{ik}$</span>)。</li>\n<li><strong>任务</strong>: 建立每个城市的房价预测模型。</li>\n<li><strong>模型设定</strong>:<ul>\n<li>我们可能发现“房屋面积”对房价的影响在三个城市中是完全一样的（同质性）。</li>\n<li>“附近是否有公园”这个特征可能只在城市1和城市2有影响，但在城市3没有影响（稀疏性+异质性）。</li>\n<li>房价数据中可能存在一些极端高或低的异常值，使用分位数回归（如中位数回归 <span class=\"math\">$\\tau=0.5$</span>）比均值回归（最小二乘）更稳健。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>2. 解决方法</h3>\n<p>为了同时识别同质性和稀疏性，文章提出了一种<strong>双重惩罚分位数回归</strong>方法。其目标是最小化以下优化函数：\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\beta} = \\arg\\min_{\\beta} \\left( \\frac{1}{n} \\sum_{k=1}^K \\sum_{i=1}^{n_k} \\rho_\\tau(y_{ik} - \\mathbf{x}_{ik}^\\top \\beta_k) + \\sum_{j=1}^p \\sum_{k<k'} p_\\lambda(|\\beta_{kj} - \\beta_{k'j}|) + \\sum_{j=1}^p \\sum_{k=1}^K p_\\gamma(|\\beta_{kj}|) \\right)$</span>$</pre>\n该目标函数由三部分组成：</p>\n<ol>\n<li><strong>分位数损失项</strong>: <span class=\"math\">$\\frac{1}{n} \\sum \\sum \\rho_\\tau(y_{ik} - \\mathbf{x}_{ik}^\\top \\beta_k)$</span>，其中 <span class=\"math\">$\\rho_\\tau(u) = u(\\tau - I(u<0))$</span> 是分位数回归的&quot;check function&quot;。这部分保证了模型对异常值和重尾误差的稳健性。</li>\n<li><strong>融合惩罚项 (Fusion Penalty)</strong>: <span class=\"math\">$\\sum_{j=1}^p \\sum_{k<k'} p_\\lambda(|\\beta_{kj} - \\beta_{k'j}|)$</span>。该项惩罚了<strong>成对系数之间的差异</strong>。如果两个系数 <span class=\"math\">$\\beta_{kj}$</span> 和 <span class=\"math\">$\\beta_{k'j}$</span> 的真实值相同，这个惩罚项会驱使它们的估计值也相等，从而实现系数的分组（同质性识别）。<span class=\"math\">$\\lambda$</span> 是控制融合程度的调节参数。</li>\n<li><strong>稀疏惩罚项 (Sparsity Penalty)</strong>: <span class=\"math\">$\\sum_{j=1}^p \\sum_{k=1}^K p_\\gamma(|\\beta_{kj}|)$</span>。该项惩罚了<strong>系数的绝对大小</strong>，能够将不重要的系数压缩至零，从而实现变量选择（稀疏性识别）。<span class=\"math\">$\\gamma$</span> 是控制稀疏程度的调节参数。\n文章中使用的惩罚函数 <span class=\"math\">$p_\\lambda(\\cdot)$</span> 和 <span class=\"math\">$p_\\gamma(\\cdot)$</span> 是非凸的，如 <strong>SCAD</strong> 或 <strong>MCP</strong>，这比传统的 L1 惩罚（Lasso）具有更好的统计性质（如更小的估计偏差）。</li>\n</ol>\n<hr>\n<h3>3. 理论保证</h3>\n<p>该方法的有效性由以下两个核心理论保证支持：</p>\n<ol>\n<li><strong>神谕性质 (Oracle Properties)</strong>:\n该理论（<strong>Theorem 1</strong>）指出，在一定的正则条件下，并选择合适的调节参数 <span class=\"math\">$\\lambda$</span> 和 <span class=\"math\">$\\gamma$</span>，通过该方法得到的估计量 <span class=\"math\">$\\hat{\\beta}$</span> 具有神谕性质。这意味着，该估计量能够表现得如同我们<strong>事先已经知道</strong>：<ul>\n<li>哪些系数是零。</li>\n<li>哪些非零系数在哪些数据集中是相等的。\n这个性质保证了模型结构识别的准确性。数学上，这意味着在概率趋近于1的情况下，所提出的估计量 <span class=\"math\">$\\hat{\\beta}$</span> 与知道真实模型结构后得出的“神谕估计量” <span class=\"math\">$\\tilde{\\beta}$</span> 是一致的，即 <span class=\"math\">$P(\\tilde{\\beta} \\in B_n(\\lambda, \\gamma)) \\to 1$</span>，<span class=\"math\">$B_n$</span>是优化问题的解集。</li>\n</ul>\n</li>\n<li><strong>调节参数选择的相合性 (Selection Consistency of BIC)</strong>:\n如何选择最优的调节参数 <span class=\"math\">$(\\lambda, \\gamma)$</span> 是一个关键问题。文章为此提出了一个修正的贝叶斯信息准则 (<strong>modified BIC</strong>):\n<pre class=\"math\">$<span class=\"math\">$\\text{BIC}\\{\\hat{\\beta}(\\lambda, \\gamma)\\} = \\log\\left(\\frac{1}{n}\\sum_{k=1}^K\\sum_{i=1}^{n_k} \\rho_\\tau(y_{ik} - \\mathbf{x}_{ik}^\\top \\hat{\\beta}_k)\\right) + S_{\\lambda,\\gamma} \\cdot \\phi_n$</span>$</pre>\n其中 <span class=\"math\">$S_{\\lambda,\\gamma}$</span> 是估计出的独立非零系数的个数，<span class=\"math\">$\\phi_n$</span> 是一个惩罚项，如 <span class=\"math\">$\\phi_n = n^{-1}c \\log[\\log(Kp)]\\log(n)$</span>。\n该理论（<strong>Theorem 2</strong>）证明，通过最小化这个 BIC 选出的模型结构，与真实模型结构是一致的，即 <span class=\"math\">$P\\left( \\inf_{G \\neq G_0} \\text{BIC}(G) > \\text{BIC}(G_0) \\right) \\to 1$</span>。这为在实践中选择合适的 <span class=\"math\">$\\lambda$</span> 和 <span class=\"math\">$\\gamma$</span> 提供了理论依据。</li>\n</ol>\n<hr>\n<h3>4. 算法</h3>\n<p>直接最小化该目标函数是困难的，因为损失函数非平滑，惩罚项非凸且非可分。因此，本文设计了一个高效的 <strong>ADMM (Alternating Direction Method of Multipliers) 算法</strong>来求解。\n<strong>核心思想</strong>:</p>\n<ol>\n<li><strong>引入辅助变量</strong>: 引入辅助变量 <span class=\"math\">$\\alpha_{kk'j}$</span>, <span class=\"math\">$\\eta_{kj}$</span>, <span class=\"math\">$z_{ik}$</span>，将原问题转化为一个带等式约束的优化问题：\n<pre class=\"math\">$$\n    \\begin{aligned}\n    \\min_{\\beta,\\alpha,\\eta,z} \\quad & \\frac{1}{n} \\sum_{k,i} \\rho_\\tau(z_{ik}) + \\sum_{j,k<k'} p_\\lambda(|\\alpha_{kk'j}|) + \\sum_{j,k} p_\\gamma(|\\eta_{kj}|) \\\\\n    \\text{s.t.} \\quad & \\beta_{kj} - \\beta_{k'j} = \\alpha_{kk'j} \\\\\n    & \\beta_{kj} = \\eta_{kj} \\\\\n    & y_{ik} - \\mathbf{x}_{ik}^\\top \\beta_k = z_{ik}\n    \\end{aligned}\n    $$</pre></li>\n<li><strong>增广拉格朗日函数</strong>: 基于上述约束问题，构建增广拉格朗日函数 <span class=\"math\">$L_{\\rho}(\\beta, \\alpha, \\eta, z, \\theta, \\nu, \\delta)$</span>。</li>\n<li><strong>交替迭代更新</strong>: ADMM 算法通过交替最小化增广拉格朗日函数来更新每一组变量，直到收敛。在第 <span class=\"math\">$(t+1)$</span> 轮迭代中：<ul>\n<li><strong>更新 <span class=\"math\">$\\beta$</span></strong>: 固定其他变量，关于 <span class=\"math\">$\\beta$</span> 的子问题是一个二次规划，有闭式解：\n<pre class=\"math\">$<span class=\"math\">$\\beta^{(t+1)} = (A_1 + \\rho_3 \\tilde{X}^\\top \\tilde{X})^{-1} \\text{vec}(A_2^{(t)})$</span>$</pre></li>\n<li><strong>更新 <span class=\"math\">$\\alpha, \\eta$</span></strong>: 这两步是关于惩罚项的近端操作（proximal operator），对于 SCAD 或 MCP 惩罚，它们有解析解。例如，更新 <span class=\"math\">$\\alpha$</span>：\n<pre class=\"math\">$<span class=\"math\">$\\alpha^{(t+1)} = \\text{prox}_{p_\\lambda/\\rho_1} (E\\beta^{(t+1)} + \\theta^{(t)}/\\rho_1)$</span>$</pre></li>\n<li><strong>更新 <span class=\"math\">$z$</span></strong>: 这一步是关于分位数损失的近端操作，同样有解析解。\n<pre class=\"math\">$<span class=\"math\">$z_{ik}^{(t+1)} = \\text{prox}_{\\rho_\\tau/n\\rho_3}(y_{ik} - \\mathbf{x}_{ik}^\\top\\beta_k^{(t+1)} + \\delta_{ik}^{(t)}/\\rho_3)$</span>$</pre></li>\n<li><strong>更新对偶变量 <span class=\"math\">$\\theta, \\nu, \\delta$</span></strong>: 这些是简单的梯度上升步骤。\n<pre class=\"math\">$<span class=\"math\">$\\theta^{(t+1)} = \\theta^{(t)} + \\rho_1 (E \\beta^{(t+1)} - \\alpha^{(t+1)})$</span>$</pre></li>\n</ul>\n</li>\n</ol>\n<h2>算法的收敛性在 <strong>Proposition 1</strong> 中得到了证明。</h2>\n<h3>5. 实验设计与结果</h3>\n<p>实验分为<strong>模拟研究</strong>和<strong>实证分析</strong>两部分。\n<strong>1. 模拟研究</strong>:</p>\n<ul>\n<li><strong>实验设计</strong>:<ul>\n<li>生成 <span class=\"math\">$K=10$</span> 个数据集，比较本文提出的 RIAQ 方法和基于均值回归的 YYH 方法。</li>\n<li>设置了三种误差分布来检验稳健性：(1) <strong>标准正态分布</strong> (常规情况)；(2) <strong>t(2)分布</strong> (重尾情况)；(3) <strong>正态与柯西混合分布</strong> (重尾+异常值)。</li>\n<li>预设了真实的系数结构，包含同质性（部分变量系数跨组相同）、异质性（部分变量系数跨组不同）和稀疏性（大量系数为0）。</li>\n<li>评估指标包括：<strong>RMSE</strong> (均方根误差，衡量估计精度)，<strong>Rand Index (RI)</strong> (兰德指数，衡量分组准确性)，<strong>AMS</strong> (平均模型大小，衡量稀疏性识别能力)。</li>\n</ul>\n</li>\n<li><strong>实验结果</strong>:<ul>\n<li>在标准正态误差下，RIAQ 和 YYH 表现相似。</li>\n<li>在重尾和含异常值的误差设置下，<strong>RIAQ 方法全面优于 YYH 方法</strong>：RMSE 更低，RI 更接近1（分组更准），AMS 更接近真实非零系数个数。</li>\n<li>结果表明，RIAQ 在处理非正态、含污染数据时具有显著的稳健性和优越性。此外，RIAQ 在不同分位数水平 (<span class=\"math\">$\\tau=0.5, 0.75, 0.9$</span>) 下均表现良好。\n<strong>2. 实证分析</strong>:</li>\n</ul>\n</li>\n<li><strong>数据</strong>: 使用了 UCI 的“社区与犯罪”数据集，包含美国49个州（分为 <span class=\"math\">$K=9$</span> 个地理分区）的社区数据。响应变量是暴力犯罪率（该变量呈重尾分布），协变量是101个社会经济指标。</li>\n<li><strong>实验设计</strong>: 应用 RIAQ 方法分析不同社会经济因素对暴力犯罪率的影响，并探究这些影响在不同地理分区之间是否存在同质性或异质性。</li>\n<li><strong>实验结果</strong>:<ul>\n<li>模型识别出了16个显著影响犯罪率的协变量。</li>\n<li><strong>发现同质性效应</strong>: “双亲家庭儿童比例 (PctKids2Par)” 和 “房屋空置率 (HousVacant)” 这两个变量对犯罪率的影响在所有9个地理分区中是<strong>相同</strong>的。前者与犯罪率负相关，后者正相关，这与犯罪学常识相符。</li>\n<li><strong>发现异质性效应</strong>: “非洲裔人口比例 (racepctblack)”、“西班牙裔人口比例 (racePctHisp)” 等种族相关变量的影响在不同地理分区存在显著差异。</li>\n<li>与简单的汇总数据分位数回归相比，RIAQ 的平均分位数残差 (AQR) 更小，说明模型拟合效果更好。</li>\n</ul>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:08:11Z",
          "dateModified": "2025-11-06T07:08:11Z",
          "uri": "http://zotero.org/users/4752290/items/P75M3T2J"
        }
      ],
      "citationKey": "zeng2024robust",
      "itemKey": "B9Z6EA2I",
      "libraryID": 1,
      "select": "zotero://select/library/items/B9Z6EA2I"
    },
    {
      "key": "9I93IDBI",
      "version": 45442,
      "itemType": "preprint",
      "title": "Transfer learning for spatial autoregressive models with application to U.S. presidential election prediction",
      "abstractNote": "It is important to incorporate spatial geographic information into U.S. presidential election analysis, especially for swing states. The state-level analysis also faces significant challenges of limited spatial data availability. To address the challenges of spatial dependence and small sample sizes in predicting U.S. presidential election results using spatially dependent data, we propose a novel transfer learning framework within the SAR model, called as tranSAR. Classical SAR model estimation often loses accuracy with small target data samples. Our framework enhances estimation and prediction by leveraging information from similar source data. We introduce a two-stage algorithm, consisting of a transferring stage and a debiasing stage, to estimate parameters and establish theoretical convergence rates for the estimators. Additionally, if the informative source data are unknown, we propose a transferable source detection algorithm using spatial residual bootstrap to maintain spatial dependence and derive its detection consistency. Simulation studies show our algorithm substantially improves the classical two-stage least squares estimator. We demonstrate our method's effectiveness in predicting outcomes in U.S. presidential swing states, where it outperforms traditional methods. In addition, our tranSAR model predicts that the Democratic party will win the 2024 U.S. presidential election.",
      "date": "2024-09-07",
      "language": "en-US",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2405.15600",
      "accessDate": "2024-12-19T03:24:32Z",
      "extra": "GSCC: 0000003 2025-10-19T06:09:11.136Z 0.05 \narXiv:2405.15600 [stat]\nTLDR: This work proposes a novel transfer learning framework within the SAR model, called as tranSAR, which enhances estimation and prediction by leveraging information from similar source data and substantially improves the classical two-stage least squares estimator.\nremark: TL SAR",
      "DOI": "10.48550/arXiv.2405.15600",
      "repository": "arXiv",
      "archiveID": "arXiv:2405.15600",
      "creators": [
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Wei",
          "lastName": "Zhong",
          "creatorType": "author"
        },
        {
          "firstName": "Xingbai",
          "lastName": "Xu",
          "creatorType": "author"
        }
      ],
      "tags": [
        {
          "tag": "#task/transfer&multi-task-learning"
        }
      ],
      "relations": {},
      "inPublications": true,
      "dateAdded": "2024-12-19T03:24:32Z",
      "dateModified": "2025-10-19T06:09:11Z",
      "uri": "http://zotero.org/users/4752290/items/9I93IDBI",
      "itemID": 4263,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Preprint PDF",
          "url": "http://arxiv.org/pdf/2405.15600v2",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-12-19T03:24:34Z",
          "dateModified": "2024-12-19T03:24:34Z",
          "uri": "http://zotero.org/users/4752290/items/5J53S5BZ",
          "path": "/Users/zengh/Zotero/storage/5J53S5BZ/2024 - Zeng et al. - Transfer Learning for Spatial Autoregressive Models with Application to U.S. Presidential Election Prediction.pdf",
          "select": "zotero://select/library/items/5J53S5BZ"
        },
        {
          "itemType": "attachment",
          "title": "Snapshot",
          "url": "https://arxiv.org/abs/2405.15600",
          "tags": [],
          "relations": {},
          "dateAdded": "2024-12-19T03:24:41Z",
          "dateModified": "2024-12-19T03:24:41Z",
          "uri": "http://zotero.org/users/4752290/items/4I93R9TG",
          "path": "/Users/zengh/Zotero/storage/4I93R9TG/2405.html",
          "select": "zotero://select/library/items/4I93R9TG"
        }
      ],
      "notes": [
        {
          "key": "FGNTIQG4",
          "version": 45343,
          "itemType": "note",
          "parentItem": "9I93IDBI",
          "note": "<h2>AI 管家 - Transfer learning for spatial autoregressive models with application to U.S. presidential election p...</h2>\n<div><p>好的，这是对这篇文章的中文总结。</p>\n<h3>0. 标题、作者、摘要及贡献</h3>\n<ul>\n<li><strong>标题</strong>: Transfer Learning for Spatial Autoregressive Models with Application to U.S. Presidential Election Prediction (空间自回归模型的迁移学习及其在美国总统选举预测中的应用)</li>\n<li><strong>作者</strong>: Hao Zeng¹, Wei Zhong² and Xingbai Xu² (¹南方科技大学, ²厦门大学)</li>\n<li><strong>摘要总结</strong>: 本文针对美国总统选举预测中存在的空间依赖性和摇摆州样本量小的挑战，提出了一种名为 tranSAR 的新型迁移学习框架。该框架在空间自回归（SAR）模型下，通过利用来自其他州（源数据）的信息来提高对摇摆州（目标数据）的参数估计和预测精度。作者设计了一个包含“迁移”和“去偏”的<strong>两阶段估计算法</strong>，并为该估计量建立了理论收敛速度。当信息丰富的源数据未知时，作者提出了一种基于<strong>空间残差自举 (spatial residual bootstrap)</strong> 的可迁移源检测算法，以保证空间依赖结构并实现了检测一致性。模拟和实证研究表明，该方法显著优于传统方法，并预测民主党将赢得2024年美国总统大选。</li>\n<li><strong>一句话贡献与创新</strong>: 首次将迁移学习框架引入空间自回归模型，以解决空间依赖数据下的小样本学习问题，并提出了一种基于空间自举的可迁移源识别方法。</li>\n</ul>\n<hr>\n<h3>1. 任务和模型</h3>\n<ul>\n<li><strong>基本任务</strong>: 本文的核心任务是在目标数据集样本量有限的情况下，提高空间自回归 (Spatial Autoregressive, SAR) 模型的参数估计和预测的准确性。其主要应用是利用来自全美各州的历史选举和人口数据，来预测摇摆州在总统选举中的投票结果。</li>\n<li><strong>模型设定</strong>: 文章在<strong>空间自回归 (SAR) 模型</strong>的框架下设定问题。<ul>\n<li><strong>目标模型 (Target Model)</strong>: 针对一个指定的摇摆州（索引为 <span class=\"math\">$0$</span>），其数据由以下 SAR 模型生成：\n<pre class=\"math\">$<span class=\"math\">$Y^{(0)} = \\sum_{l=1}^{p} \\lambda_{l0} W_l^{(0)} Y^{(0)} + \\sum_{j=1}^{q} X_j^{(0)} \\beta_{j0} + V^{(0)}$</span>$</pre>\n其中，<span class=\"math\">$Y^{(0)}$</span> 是目标州各县的响应向量（如两党支持率差异），<span class=\"math\">$W_l^{(0)}$</span> 是已知的空间权重矩阵（表示县之间的地理邻近关系），<span class=\"math\">$X_j^{(0)}$</span> 是外生协变量向量（如人口、经济数据），<span class=\"math\">$V^{(0)}$</span> 是误差项。待估参数为 <span class=\"math\">$\\theta_0 = (\\lambda_0^\\top, \\beta_0^\\top)^\\top$</span>。</li>\n<li><strong>源模型 (Source Models)</strong>: 其他 <span class=\"math\">$K$</span> 个州（源数据）也服从 SAR 模型，但参数可能与目标模型略有不同：\n<pre class=\"math\">$<span class=\"math\">$Y^{(k)} = \\sum_{l=1}^{p} \\lambda_{l}^{(k)} W_l^{(k)} Y^{(k)} + \\sum_{j=1}^{q} X_j^{(k)} \\beta_{j}^{(k)} + V^{(k)}, \\quad k \\in [K]$</span>$</pre>\n其中，源模型的参数 <span class=\"math\">$\\omega^{(k)} = ((\\lambda^{(k)})^\\top, (\\beta^{(k)})^\\top)^\\top$</span> 与目标参数 <span class=\"math\">$\\theta_0$</span> “相似但不完全相同”。</li>\n</ul>\n</li>\n<li><strong>问题示例</strong>:<ul>\n<li><em>数据</em>:<ul>\n<li><strong>目标数据</strong>: 宾夕法尼亚州（一个摇摆州）在2020年所有县的选举结果（<span class=\"math\">$Y^{(0)}$</span>），以及各县的人口密度、收入水平等数据（<span class=\"math\">$X^{(0)}$</span>）。</li>\n<li><strong>源数据</strong>: 其他47个州在2020年的同类数据（<span class=\"math\">$\\{Y^{(k)}, X^{(k)}\\}_{k=1}^{47}$</span>）。</li>\n</ul>\n</li>\n<li><em>任务</em>: 利用宾夕法尼亚州自身的数据以及其他47个州的数据，更准确地估计宾夕法尼亚州的 SAR 模型参数 <span class=\"math\">$\\theta_0$</span>，并用此模型预测其在2024年大选中的结果。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>2. 解决方法</h3>\n<p>文章提出了一种名为 <strong>tranSAR</strong> 的两阶段迁移学习方法。当“有用的”源数据（即信息性源，informative sources）已知时，使用 <strong>A-TranSAR</strong> 算法；当其未知时，先使用<strong>可迁移源检测算法</strong>进行识别。</p>\n<ol>\n<li><strong>A-TranSAR 估计算法 (假设信息性源集合 <span class=\"math\">$\\mathcal{A}$</span> 已知)</strong><ul>\n<li><strong>第一阶段：迁移 (Transferring Stage)</strong>\n首先，汇集所有来自信息性源集合 <span class=\"math\">$\\mathcal{A}$</span> 的数据，得到一个初始的、可能有偏的参数估计量 <span class=\"math\">$\\tilde{\\omega}$</span>。\n<pre class=\"math\">$<span class=\"math\">$\\tilde{\\omega} = \\arg\\min_{\\omega \\in \\mathbb{R}^{p+q}} \\left\\{ \\frac{1}{2n_A} \\sum_{k \\in \\mathcal{A}} l_1(\\mathcal{D}^{(k)} | \\omega) + \\lambda_{\\omega} \\|\\omega\\|_1 \\right\\}$</span>$</pre>\n其中 <span class=\"math\">$l_1$</span> 是损失函数（如2SLS损失），<span class=\"math\">$n_A = \\sum_{k \\in \\mathcal{A}} n_k$</span> 是信息性源的总样本量，<span class=\"math\">$\\lambda_{\\omega}$</span> 是正则化参数。</li>\n<li><strong>第二阶段：去偏 (Debiasing Stage)</strong>\n然后，利用目标数据 <span class=\"math\">$\\mathcal{D}^{(0)}$</span> 来修正第一阶段的估计偏差，得到一个偏差修正项 <span class=\"math\">$\\hat{\\delta}$</span>。\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\delta} = \\arg\\min_{\\delta \\in \\mathbb{R}^{p+q}} \\frac{1}{2n_0} l_2(\\mathcal{D}^{(0)} | \\tilde{\\omega} + \\delta) + \\lambda_{\\delta} \\|\\delta\\|_1$</span>$</pre>\n这里假定真实参数的差异 <span class=\"math\">$\\delta_0 = \\theta_0 - \\tilde{\\omega}$</span> 是稀疏的，因此用 <span class=\"math\">$L_1$</span> 惩罚项来估计。</li>\n<li><strong>最终估计量</strong>:\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\theta}_{\\mathcal{A}\\text{-TranSAR}} = \\tilde{\\omega} + \\hat{\\delta}$</span>$</pre></li>\n</ul>\n</li>\n<li><strong>可迁移源检测算法 (当 <span class=\"math\">$\\mathcal{A}$</span> 未知时)</strong>\n该算法的核心思想是：如果一个源数据与目标数据相似，那么将它与目标数据合并后，在新模型上的交叉验证损失不应显著增加。<ul>\n<li>首先在目标数据上通过<strong>空间残差自举(spatial residual bootstrap)</strong> 计算基准损失 <span class=\"math\">$L^{(0)}$</span> 及其标准差 <span class=\"math\">$\\hat{\\sigma}$</span>。</li>\n<li>对于每一个源数据 <span class=\"math\">$k$</span>，将其与自举生成的目标数据合并，计算新的交叉验证损失 <span class=\"math\">$L^{(k)}$</span>。</li>\n<li>如果损失增加量在一个阈值内，则认为该源是可迁移的。估计的信息性源集合为：\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\mathcal{A}} = \\{k = 1, \\dots, K \\mid L^{(k)} - L^{(0)} \\le (\\hat{\\sigma} \\vee 0.01)\\}$</span>$</pre></li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3>3. 理论保证</h3>\n<ul>\n<li><strong>方法有效性原因</strong>: 该方法通过“借用”大量相似的源数据，有效降低了因目标数据样本量小而导致的估计<strong>方差</strong>。同时，通过第二阶段的“去偏”步骤，修正了因源模型与目标模型不完全一致而引入的<strong>偏差</strong>。这种偏差-方差权衡使得最终估计量比仅使用目标数据的估计量更准确。</li>\n<li><strong>理论保证</strong>: 文章为所提出的估计量提供了严格的理论保证。<ul>\n<li><strong>估计量的收敛速度 (A-TranSAR)</strong>: 在一定正则条件下，文章证明了 A-TranSAR 估计量的收敛速度（以 <span class=\"math\">$L_2$</span> 范数平方误差衡量）：\n<pre class=\"math\">$<span class=\"math\">$||\\hat{\\theta} - \\theta_0||_2^2 = O_p\\left( \\left(\\sqrt{\\frac{\\log q}{n_0}}h\\right) \\wedge \\left(s\\frac{\\log q}{n_0}\\right) \\vee h^2 + a_{n_A}^{(2)} \\right)$</span>$</pre>\n其中 <span class=\"math\">$n_0$</span> 是目标样本量，<span class=\"math\">$n_A$</span> 是源样本量，<span class=\"math\">$s$</span> 是参数稀疏度，<span class=\"math\">$h$</span> 是迁移水平（衡量源和目标参数的差异）。这个结果表明，当源数据量 <span class=\"math\">$n_A$</span> 足够大且与目标差异 <span class=\"math\">$h$</span> 较小时，迁移学习的误差率优于传统方法（其误差率约为 <span class=\"math\">$s\\log q/n_0$</span>）。</li>\n<li><strong>检测算法的一致性</strong>: 文章证明了所提出的可迁移源检测算法是一致的，即在大样本下，该算法能以趋向于1的概率准确地识别出所有真正的信息性源。\n<pre class=\"math\">$<span class=\"math\">$P(\\hat{\\mathcal{A}} = \\mathcal{A}) \\to 1, \\quad \\text{as } n \\to \\infty$</span>$</pre>\n这为 tranSAR 方法在实际应用中的可靠性提供了理论基础，避免了“负迁移”（即使用不相似的源数据反而降低模型性能）的风险。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>4. 算法</h3>\n<p>文章提出了两个核心算法：A-TranSAR (信息源已知) 和 TranSAR (信息源未知)。</p>\n<ul>\n<li><strong>算法 1: A-TranSAR</strong><ol>\n<li><strong>输入</strong>: 目标数据集 <span class=\"math\">$\\mathcal{D}^{(0)}$</span>，信息性源数据集 <span class=\"math\">$\\{\\mathcal{D}^{(k)}, k \\in \\mathcal{A}\\}$</span>。</li>\n<li><strong>迁移阶段</strong>: 联合所有信息性源数据，求解优化问题（\n公式4）得到初始估计量 <span class=\"math\">$\\tilde{\\omega}$</span>。</li>\n<li><strong>去偏阶段</strong>: 使用目标数据，求解优化问题（公式5）得到偏差修正项 <span class=\"math\">$\\hat{\\delta}$</span>。</li>\n<li><strong>输出</strong>: 最终估计量 <span class=\"math\">$\\hat{\\theta}_{\\mathcal{A}\\text{-TranSAR}} = \\tilde{\\omega} + \\hat{\\delta}$</span>。</li>\n</ol>\n</li>\n<li><strong>算法 2: TranSAR</strong><ol>\n<li><strong>输入</strong>: 目标数据集 <span class=\"math\">$\\mathcal{D}^{(0)}$</span>，所有源数据集 <span class=\"math\">$\\{\\mathcal{D}^{(k)}, k \\in [K]\\}$</span>。</li>\n<li><strong>计算基准损失</strong>: 在目标数据上运行空间残差自举，通过交叉验证方式计算基准损失 <span class=\"math\">$L^{(0)}$</span> 和标准差 <span class=\"math\">$\\hat{\\sigma}$</span>。</li>\n<li><strong>评估每个源</strong>: 对每个源 <span class=\"math\">$k=1, \\dots, K$</span>，将其与自举的目标数据合并，计算交叉验证损失 <span class=\"math\">$L^{(k)}$</span>。</li>\n<li><strong>识别信息性源</strong>: 根据判据 <span class=\"math\">$L^{(k)} - L^{(0)} \\le (\\hat{\\sigma} \\vee 0.01)$</span>，确定信息性源集合 <span class=\"math\">$\\hat{\\mathcal{A}}$</span>。</li>\n<li><strong>最终估计</strong>: 将识别出的 <span class=\"math\">$\\hat{\\mathcal{A}}$</span> 作为输入，运行 <strong>算法 1 (A-TranSAR)</strong>。</li>\n<li><strong>输出</strong>: 最终估计量 <span class=\"math\">$\\hat{\\theta}_{\\text{TranSAR}}$</span>。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h3>5. 实验设计与结果</h3>\n<ul>\n<li><strong>模拟实验</strong>:<ul>\n<li><strong>设计</strong>: 作者生成了服从 SAR 模型的人工数据。比较了以下几种方法：<ol>\n<li><strong>TranSAR (本文方法)</strong>: 使用数据驱动的源检测算法。</li>\n<li><strong>Oracle TranSAR</strong>: 假设已知真实信息性源集合的理想情况。</li>\n<li><strong>SAR</strong>: 仅使用目标数据的传统2SLS估计方法。</li>\n<li><strong>[K]-TranSAR</strong>: 使用所有源数据的“朴素”汇集方法，用于展示负迁移。</li>\n<li><strong>glmtrans</strong>: 忽略空间依赖性的另一种迁移学习方法。</li>\n</ol>\n</li>\n<li><strong>结果</strong>: 模拟结果 (图2) 表明:<ul>\n<li>随着信息性源数量的增加，<strong>TranSAR</strong> 和 <strong>Oracle TranSAR</strong> 的均方根误差 (RMSE) 显著降低，远优于仅使用目标数据的 <strong>SAR</strong> 方法和忽略空间信息的 <strong>glmtrans</strong>。</li>\n<li><strong>TranSAR</strong> 的性能非常接近理想的 <strong>Oracle TranSAR</strong>，证明了其源检测算法的有效性。</li>\n<li>当存在大量非信息性源时，<strong>[K]-TranSAR</strong> 表现很差，说明了准确识别信息性源以避免负迁移的重要性。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>美国总统选举预测实证应用</strong>:<ul>\n<li><strong>设计</strong>: 将摇摆州作为目标，其他州作为源。使用2016年的选举数据作为训练集，预测2020年摇摆州各县的投票结果，并与真实结果比较。</li>\n<li><strong>结果</strong>:<ol>\n<li><strong>县级预测精度 (RMSE)</strong>: 在所有测试的摇摆州（如佛罗里达、密歇根、俄亥俄等）中，<strong>tranSAR</strong> 的县级预测RMSE均低于传统的 <strong>SAR</strong> 方法 (表2)，表明预测更准确。</li>\n<li><strong>州级胜者预测</strong>: <strong>tranSAR</strong> 在预测州级选举胜者方面也表现更优，例如正确预测了密歇根州和明尼苏达州的胜者，而传统SAR方法预测错误 (表4)。</li>\n<li><strong>2024年大选预测</strong>: 作者使用训练好的模型和最新的2022年人口地理数据，对2024年大选进行了预测。结果显示，民主党预计将获得309张选举人票，超过269票的获胜门槛，因此预测<strong>民主党将赢得2024年大选</strong>。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T07:08:15Z",
          "dateModified": "2025-11-06T07:08:15Z",
          "uri": "http://zotero.org/users/4752290/items/FGNTIQG4"
        }
      ],
      "citationKey": "zeng2024transfer",
      "itemKey": "9I93IDBI",
      "libraryID": 1,
      "select": "zotero://select/library/items/9I93IDBI"
    },
    {
      "key": "RS69A4HH",
      "version": 44913,
      "itemType": "preprint",
      "title": "PAC reasoning: controlling the performance loss for efficient reasoning",
      "abstractNote": "Large reasoning models (LRMs) have achieved remarkable progress in complex problem-solving tasks. Despite this success, LRMs typically suffer from high computational costs during deployment, highlighting a need for efficient inference. A popular direction of efficiency improvement is to switch the LRM between thinking and nonthinking modes dynamically. However, such approaches often introduce additional reasoning errors and lack statistical guarantees for the performance loss, which are critical for high-stakes applications. In this work, we propose Probably Approximately Correct (PAC) reasoning that controls the performance loss under the user-specified performance loss tolerance. In particular, we construct an upper confidence bound on the performance loss, formulated as a monotone function of the uncertainty score, and subsequently determine a threshold for switching to the nonthinking model. Theoretically, using the threshold to switch between the thinking and nonthinking modes ensures bounded performance loss in a distribution-free manner. Our comprehensive experiments on reasoning benchmarks show that the proposed method can save computational budgets and control the user-specified performance loss.",
      "date": "2025-10-10",
      "language": "en-US",
      "shortTitle": "PAC reasoning",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2510.09133",
      "accessDate": "2025-10-13T12:05:06Z",
      "extra": "arXiv:2510.09133 [cs]\nTLDR: This work constructs an upper confidence bound on the performance loss, formulated as a monotone function of the uncertainty score, and subsequently determines a threshold for switching to the nonthinking model, and proposes Probably Approximately Correct (PAC) reasoning that controls the performance loss under the user-specified performance loss tolerance.",
      "DOI": "10.48550/arXiv.2510.09133",
      "repository": "arXiv",
      "archiveID": "arXiv:2510.09133",
      "creators": [
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Jianguo",
          "lastName": "Huang",
          "creatorType": "author"
        },
        {
          "firstName": "Bingyi",
          "lastName": "Jing",
          "creatorType": "author"
        },
        {
          "firstName": "Hongxin",
          "lastName": "Wei",
          "creatorType": "author"
        },
        {
          "firstName": "Bo",
          "lastName": "An",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "dateAdded": "2025-10-13T12:05:06Z",
      "dateModified": "2025-11-12T16:50:12Z",
      "uri": "http://zotero.org/users/4752290/items/RS69A4HH",
      "itemID": 6863,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "Preprint PDF",
          "url": "http://arxiv.org/pdf/2510.09133v1",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-10-13T12:05:09Z",
          "dateModified": "2025-10-13T12:05:09Z",
          "uri": "http://zotero.org/users/4752290/items/6TBZU242",
          "path": "/Users/zengh/Zotero/storage/6TBZU242/2025_Zeng et al._PAC Reasoning Controlling the Performance Loss for Efficient Reasoning.pdf",
          "select": "zotero://select/library/items/6TBZU242"
        }
      ],
      "notes": [],
      "citationKey": "zeng2025pac",
      "itemKey": "RS69A4HH",
      "libraryID": 1,
      "select": "zotero://select/library/items/RS69A4HH"
    },
    {
      "key": "PD5463XM",
      "version": 44886,
      "itemType": "conferencePaper",
      "title": "Parametric scaling law of tuning bias in conformal prediction",
      "abstractNote": "Conformal prediction is a popular framework of uncertainty quantification that constructs prediction sets with coverage guarantees. To uphold the exchangeability assumption, many conformal prediction methods necessitate an additional hold-out set for parameter tuning. Yet, the impact of violating this principle on coverage remains underexplored, making it ambiguous in practical applications. In this work, we empirically find that the tuning bias - the coverage gap introduced by leveraging the same dataset for tuning and calibration, is negligible for simple parameter tuning in many conformal prediction methods. In particular, we observe the scaling law of the tuning bias: this bias increases with parameter space complexity and decreases with calibration set size. Formally, we establish a theoretical framework to quantify the tuning bias and provide rigorous proof for the scaling law of the tuning bias by deriving its upper bound. In the end, we discuss how to reduce the tuning bias, guided by the theories we developed.",
      "date": "2025-06-18",
      "language": "en",
      "libraryCatalog": "openreview.net",
      "url": "https://openreview.net/forum?id=jnJLZXSOin",
      "accessDate": "2025-07-22T09:24:20Z",
      "proceedingsTitle": "Forty-second International Conference on Machine Learning",
      "conferenceName": "International Conference on Machine Learning",
      "creators": [
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Kangdao",
          "lastName": "Liu",
          "creatorType": "author"
        },
        {
          "firstName": "Bingyi",
          "lastName": "Jing",
          "creatorType": "author"
        },
        {
          "firstName": "Hongxin",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {
        "dc:replaces": [
          "http://zotero.org/users/4752290/items/XHSHHAEA"
        ]
      },
      "dateAdded": "2025-05-23T02:25:46Z",
      "dateModified": "2025-09-16T01:40:52Z",
      "uri": "http://zotero.org/users/4752290/items/PD5463XM",
      "itemID": 5510,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "2025_Zeng et al._Parametric Scaling Law of Tuning Bias in Conformal Prediction.pdf",
          "url": "https://openreview.net/pdf?id=jnJLZXSOin",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-05-22T18:25:46Z",
          "dateModified": "2025-07-23T12:14:00Z",
          "uri": "http://zotero.org/users/4752290/items/ENGVVMWB",
          "path": "/Users/zengh/Zotero/storage/ENGVVMWB/2025_Zeng et al._Parametric Scaling Law of Tuning Bias in Conformal Prediction.pdf",
          "select": "zotero://select/library/items/ENGVVMWB"
        },
        {
          "itemType": "attachment",
          "title": "Snapshot",
          "url": "http://arxiv.org/abs/2502.03023",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-05-23T02:26:27Z",
          "dateModified": "2025-05-23T02:26:27Z",
          "uri": "http://zotero.org/users/4752290/items/GYBQT424",
          "path": "/Users/zengh/Zotero/storage/GYBQT424/2502.html",
          "select": "zotero://select/library/items/GYBQT424"
        }
      ],
      "notes": [
        {
          "key": "VSQEDTEE",
          "version": 45249,
          "itemType": "note",
          "parentItem": "PD5463XM",
          "note": "<h2>AI 管家 - Parametric scaling law of tuning bias in conformal prediction</h2>\n<div><p>好的，这是一篇关于保形预测中调参偏差的参数化缩放定律的学术文章总结。</p>\n<h3>0. 标题、作者、摘要与贡献</h3>\n<ul>\n<li><strong>标题 (英文)</strong>: Parametric Scaling Law of Tuning Bias in Conformal Prediction</li>\n<li><strong>作者</strong>: Hao Zeng, Kangdao Liu, Bingyi Jing, Hongxin Wei</li>\n<li><strong>摘要总结</strong>:\n保形预测（Conformal Prediction）是一种量化不确定性的框架，它能保证预测集达到预设的覆盖率，其理论基础是数据的“可交换性”假设。然而，在实践中，许多保形预测方法需要调整超参数（例如，置信度校准的温度系数、分数函数中的正则化项等），标准的做法是使用一个独立的“验证集”来调参，以避免破坏用于保形校准的数据的可交换性。本文研究了一个常见的、但理论上不严谨的做法：<strong>复用同一份数据来进行参数调整和保形校准</strong>。作者发现，这种数据复用会破坏可交换性假设，从而引入额外的覆盖率偏差，并将其定义为**“调参偏差”（Tuning Bias）<strong>。文章通过实验和理论证明，这个偏差存在一个</strong>“参数化缩放定律”<strong>：调参偏差会随着</strong>参数空间复杂度的增加而增大**，并随着<strong>校准集规模的增大而减小</strong>。作者为此建立了一个理论框架，通过经验过程理论严格推导了该偏差的上界，从而为这一定律提供了理论依据。</li>\n<li><strong>一句话贡献和创新</strong>:\n<strong>本文首次识别、量化并从理论上证明了在保形预测中因数据复用导致的“调参偏差”的存在及其“参数化缩放定律”，即偏差与参数空间复杂度成正比，与校准集大小成反比。</strong></li>\n</ul>\n<h3>1. 任务和模型 (任务和模型)</h3>\n<ul>\n<li><strong>基本任务</strong>:\n本文的任务不是提出一个新的算法，而是<strong>分析和量化</strong>在分裂式保形预测（split conformal prediction）框架下，当<strong>复用同一数据集进行参数调整（tuning）和保形校准（calibration）时，所引入的覆盖率偏差（coverage gap），即“调参偏差”</strong>。</li>\n<li><strong>模型设定</strong>:\n设定在标准的分裂式保形预测模型下。该模型通常需要一个“不确定性分数函数”（non-conformity score function）<span class=\"math\">$S(x, y)$</span>，该函数衡量样本 <span class=\"math\">$(x, y)$</span> 的“异常”程度。在许多现代方法中，这个分数函数 <span class=\"math\">$S$</span> 自身带有一组可调参数 <span class=\"math\">$\\lambda \\in \\Lambda$</span>，记为 <span class=\"math\">$S^\\lambda$</span>。<ul>\n<li><strong>标准做法 (Hold-out)</strong>：使用一个独立的验证集 <span class=\"math\">$D_{tune}$</span> 来寻找最优参数 <span class=\"math\">$\\hat{\\lambda}$</span>，然后在一个独立的校准集 <span class=\"math\">$D_{cal}$</span> 上计算分数并确定阈值，以保证可交换性。</li>\n<li><strong>本文研究的做法 (Same/Reuse)</strong>：使用同一个校准集 <span class=\"math\">$D_{cal}$</span> 来同时完成寻找最优参数 <span class=\"math\">$\\hat{\\lambda}$</span> 和计算保形阈值这两个步骤。这种做法破坏了可交换性，是本文研究偏差的来源。</li>\n</ul>\n</li>\n<li><strong>问题示例</strong>:<ul>\n<li><strong>数据</strong>: CIFAR-100 图片分类数据集。一个样本是（图片 <span class=\"math\">$x$</span>，标签 <span class=\"math\">$y$</span>）。我们有一个校准集 <span class=\"math\">$D_{cal} = \\{(x_i, y_i)\\}_{i=1}^n$</span>。</li>\n<li><strong>任务</strong>: 对于一张新图片 <span class=\"math\">$x_{test}$</span>，我们希望给出一个预测标签集合 <span class=\"math\">$C(x_{test})$</span>，并保证真实标签 <span class=\"math\">$y_{test}$</span> 在这个集合中的概率不低于 <span class=\"math\">$90\\%$</span>（即覆盖率 <span class=\"math\">$\\mathbb{P}(y \\in C(x)) \\ge 1-\\alpha=0.9$</span>）。</li>\n<li><strong>带参数的分数函数</strong>: 比如使用“温度缩放（Temperature Scaling）”来校准模型的置信度，这会引入一个温度参数 <span class=\"math\">$\\lambda$</span>。我们需要先确定最优的 <span class=\"math\">$\\lambda$</span>。如果我们在 <span class=\"math\">$D_{cal}$</span>上选择了一个能让模型校准得最好的<span class=\"math\">$\\hat{\\lambda}$</span>，然后再用这个<span class=\"math\">$\\hat{\\lambda}$</span> 和 同一个 <span class=\"math\">$D_{cal}$</span>来计算保形预测的阈值，那么最终的覆盖率可能会低于 <span class=\"math\">$90\\%$</span>，这个偏差就是本文研究的核心。</li>\n</ul>\n</li>\n</ul>\n<h3>2. 解决方法 (方法)</h3>\n<p>文章通过数学化的方法来定义、分解和量化“调参偏差”。</p>\n<ol>\n<li><strong>定义调参偏差 (Tuning Bias)</strong>:\n首先定义覆盖率缺口 <span class=\"math\">$CovGap(C) = |(1-\\alpha) - \\mathbb{P}(y \\in C(x))|$</span>。调参偏差被定义为<strong>数据复用</strong>策略（记其预测器为 <span class=\"math\">$\\hat{C}$</span>）与<strong>标准hold-out</strong>策略（记其预测器为 <span class=\"math\">$C_{hold-out}$</span>）的覆盖率缺口之差：\n<pre class=\"math\">$<span class=\"math\">$TuningBias(\\hat{C}) = CovGap(\\hat{C}) - CovGap(C_{hold-out})$</span>$</pre>\n由于 <span class=\"math\">$C_{hold-out}$</span> 是理论有效的，其偏差很小，所以调参偏差主要由 <span class=\"math\">$CovGap(\\hat{C})$</span> 决定。</li>\n<li><strong>分解覆盖率缺口的上界</strong>:\n文章的核心理论贡献是将数据复用下的覆盖率缺口 <span class=\"math\">$CovGap(\\hat{C})$</span> 分解。通过理论推导（定理 4.1），他们证明其上界可以被分解为两部分：\n<pre class=\"math\">$<span class=\"math\">$CovGap(\\hat{C}) \\le \\mathcal{R}_{\\Lambda} + \\epsilon_{\\alpha, n}$</span>$</pre><ul>\n<li><span class=\"math\">$\\epsilon_{\\alpha, n} \\approx \\frac{1}{n+1}$</span> 是标准保形预测中由有限样本导致的固有偏差。</li>\n<li><span class=\"math\">$\\mathcal{R}_{\\Lambda}$</span> 是由于在数据相关的参数 <span class=\"math\">$\\hat{\\lambda}$</span> 下破坏了可交换性而引入的<strong>额外偏差项</strong>。这一项直接关联到调参偏差。</li>\n</ul>\n</li>\n<li><strong>使用经验过程理论进行量化</strong>:\n作者将 <span class=\"math\">$\\mathcal{R}_{\\Lambda}$</span> 与经典的经验过程理论联系起来。<span class=\"math\">$\\mathcal{R}_{\\Lambda}$</span> 被表达为一个经验过程（empirical process）的上确界：\n<pre class=\"math\">$<span class=\"math\">$\\mathcal{R}_{\\Lambda} = \\mathbb{E} \\left[ \\sup_{\\lambda \\in \\Lambda, t \\in \\mathcal{T}} \\left| \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{S^\\lambda(x_i, y_i) \\le t\\} - \\mathbb{P}(S^\\lambda(x, y) \\le t) \\right| \\right]$</span>$</pre>\n其中，<span class=\"math\">$\\mathbf{1}\\{\\cdot\\}$</span> 是指示函数，<span class=\"math\">$\\Lambda$</span> 是参数空间。这个公式衡量了由参数 <span class=\"math\">$\\lambda$</span> 和阈值 <span class=\"math\">$t$</span> 定义的函数类在经验分布和真实分布之间的最大差异。通过分析 <span class=\"math\">$\\mathcal{R}_{\\Lambda}$</span>，就可以揭示调参偏差的规律。</li>\n</ol>\n<h3>3. 为什么这个方法是有效果的？其理论保证是什么？ (理论)</h3>\n<p>这个分析方法是有效的，因为它成功地将一个复杂的现象（调参偏差）转化为了一个可以用成熟数学工具（经验过程理论）来分析的量。其理论保证来自于对 <span class=\"math\">$\\mathcal{R}_{\\Lambda}$</span> 的上界分析，这直接揭示了“参数化缩放定律”。</p>\n<ul>\n<li><strong>理论贡献</strong>: 本文的核心理论贡献是推导出了调参偏差在不同参数空间下的上界，从而在数学上证明了“参数化缩放定律”。</li>\n</ul>\n<ol>\n<li><strong>对于有限参数空间</strong>:\n当参数空间 <span class=\"math\">$\\Lambda$</span> 是有限的（例如，网格搜索中的候选参数），使用 Dvoretzky-Kiefer-Wolfowitz (DKW) 不等式和联合界（union bound），推导出调参偏差的上界（命题 4.2）：\n<pre class=\"math\">$<span class=\"math\">$TuningBias(\\hat{C}) \\le \\mathcal{O}\\left(\\sqrt{\\frac{\\log(|\\Lambda|)}{n}}\\right)$</span>$</pre>\n这个界清晰地表明，偏差随参数空间大小 <span class=\"math\">$|\\Lambda|$</span> 的对数增长，随校准集大小 <span class=\"math\">$n$</span> 的平方根倒数减小。</li>\n<li><strong>对于无限参数空间</strong>:\n当参数空间 <span class=\"math\">$\\Lambda \\subseteq \\mathbb{R}^d$</span> 是无限的（例如，神经网络的权重），使用 VC 维（Vapnik-Chervonenkis dimension）理论，推导出调参偏差的上界（命题 4.6）：\n<pre class=\"math\">$<span class=\"math\">$TuningBias(\\hat{C}) \\le \\mathcal{O}\\left(\\sqrt{\\frac{d}{n}}\\right)$</span>$</pre>\n其中 <span class=\"math\">$d$</span> 是与参数空间 <span class=\"math\">$\\Lambda$</span> 相关的 VC 维（通常与参数维度有关）。这个界表明，偏差随参数空间的维度 <span class=\"math\">$d$</span> 的平方根增长，随校准集大小 <span class=\"math\">$n$</span> 的平方根倒数减小。\n这两个理论结果共同构成了<strong>参数化缩放定律的理论基础</strong>，并与实验现象高度吻合。</li>\n</ol>\n<h3>4. 使用了什么算法？ (算法)</h3>\n<p>本文没有提出新算法，而是<strong>分析了以下数据复用流程</strong>：\n给定一个参数化的分数函数族 <span class=\"math\">$S^\\lambda, \\lambda \\in \\Lambda$</span>，一个校准集 <span class=\"math\">$D_{cal}$</span>，以及一个损失函数 <span class=\"math\">$\\ell(\\lambda)$</span>（例如，预测集大小或负对数似然）。</p>\n<ol>\n<li><strong>参数调优 (Parameter Tuning)</strong>: 在校准集 <span class=\"math\">$D_{cal}$</span> 上寻找最优参数 <span class=\"math\">$\\hat{\\lambda}$</span>：\n<pre class=\"math\">$<span class=\"math\">$\\hat{\\lambda} := \\arg\\min_{\\lambda \\in \\Lambda} \\ell(\\lambda, S^\\lambda; D_{cal})$</span>$</pre>\n这一步使得 <span class=\"math\">$\\hat{\\lambda}$</span> 与 <span class=\"math\">$D_{cal}$</span> 相关。</li>\n<li><strong>分数计算</strong>: 使用找到的参数 <span class=\"math\">$\\hat{\\lambda}$</span>，在<strong>同一个</strong>校准集 <span class=\"math\">$D_{cal}$</span> 上计算每个样本的不确定性分数：\n<pre class=\"math\">$<span class=\"math\">$\\mathcal{S}_{\\hat{\\lambda}} = \\{s_i = S^{\\hat{\\lambda}}(x_i, y_i) \\mid (x_i, y_i) \\in D_{cal}\\}$</span>$</pre></li>\n<li><strong>阈值确定</strong>: 计算分数集 <span class=\"math\">$\\mathcal{S}_{\\hat{\\lambda}}$</span> 的 <span class=\"math\">$\\lceil(n+1)(1-\\alpha)\\rceil/n$</span> 分位数作为阈值 <span class=\"math\">$\\hat{t}$</span>：\n<pre class=\"math\">$<span class=\"math\">$\\hat{t} = \\text{Quantile}(\\mathcal{S}_{\\hat{\\lambda}}, \\frac{\\lceil(n+1)(1-\\alpha)\\rceil}{n})$</span>$</pre></li>\n<li><strong>构建预测集</strong>: 对新的测试样本 <span class=\"math\">$x_{test}$</span>，其预测集为：\n<pre class=\"math\">$<span class=\"math\">$C(x_{test}) = \\{y' \\in \\mathcal{Y} \\mid S^{\\hat{\\lambda}}(x_{test}, y') \\le \\hat{t}\\}$</span>$</pre>\n这个流程就是导致“调参偏差”的根源。</li>\n</ol>\n<h3>5. 实验是如何设计的？ (实验)</h3>\n<p>实验设计旨在通过控制变量法，实证地验证“参数化缩放定律”。</p>\n<ul>\n<li><strong>实验设计</strong>:<ol>\n<li><strong>对比设置</strong>:<ul>\n<li><strong><code>hold-out</code> (基准)</strong>: 标准做法。将数据分为独立的调参集和校准集。这是理论正确的参照组。</li>\n<li><strong><code>same</code> (或 <code>reuse</code>)</strong>: 本文研究的核心。使用同一份数据进行调参和校准。</li>\n</ul>\n</li>\n<li><strong>核心度量</strong>: <strong>调参偏差 (Tuning Bias)</strong>，计算为 <code>same</code> 设置下的覆盖率缺口减去 <code>hold-out</code> 设置下的覆盖率缺口。一个大的正值意味着数据复用带来了显著的负面影响。</li>\n<li><strong>控制变量</strong>:<ul>\n<li><strong>参数空间复杂度</strong>:<ul>\n<li><strong>方法对比</strong>: 比较不同参数复杂度的保形预测方法。例如，只有一个参数的<strong>温度缩放 (TS)</strong> 与有 <span class=\"math\">$2K$</span> 个参数（<span class=\"math\">$K$</span>为类别数）的<strong>向量缩放 (VS)</strong> 进行对比。</li>\n<li><strong>参数数量控制</strong>: 在向量缩放中，通过“冻结”一部分参数，人为地改变参与优化的参数数量（例如，从总参数的 60% 增加到 100%），直接观察偏差如何随参数数量变化。</li>\n</ul>\n</li>\n<li><strong>校准集大小 (<span class=\"math\">$n$</span>)</strong>:<ul>\n<li>固定调参方法（如向量缩放），逐步增大数据集 <span class=\"math\">$D_{cal}$</span> 的大小（例如，从 6000 增加到 10000），观察调参偏差的变化趋势。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>数据集与模型</strong>: 实验在 CIFAR-100 和 ImageNet 等标准图像分类数据集上进行，使用 ResNet-18 作为基础模型。</li>\n</ol>\n</li>\n<li><strong>实验结果</strong>:<ol>\n<li><strong>关于参数复杂度 (图1 和 图2a)</strong>:<ul>\n<li>实验表明，参数简单的模型（如 RAPS、TS）其 <code>same</code> 和 <code>hold-out</code> 两种设置下的覆盖率缺口几乎没有差别，即调参偏差很小。</li>\n<li>而参数复杂的模型（如 VS、ConfTr-ft），<code>same</code> 设置下的覆盖率缺口远大于 <code>hold-out</code> 设置，表现出巨大的调参偏差。</li>\n<li>在控制参数数量的实验中，随着 VS 中可调参数的比例增加，调参偏差呈<strong>明显上升趋势</strong>。</li>\n</ul>\n</li>\n<li><strong>关于校准集大小 (图2b)</strong>:<ul>\n<li>对于一个固定的复杂模型（如 VS），当校准集的大小 <span class=\"math\">$n$</span> 增加时，调参偏差<strong>显著下降</strong>，并趋向于零。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><strong>结论</strong>:\n实验结果有力地支持了理论推导出的<strong>参数化缩放定律</strong>：调参偏差与参数空间的复杂度正相关，与校准集的大小负相关。这为在实践中（尤其是在数据稀缺场景下）是否可以复用数据提供了重要的经验和理论指导。</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-06T00:06:46Z",
          "dateModified": "2025-11-06T00:06:46Z",
          "uri": "http://zotero.org/users/4752290/items/VSQEDTEE"
        }
      ],
      "citationKey": "zeng2025parametric",
      "itemKey": "PD5463XM",
      "libraryID": 1,
      "select": "zotero://select/library/items/PD5463XM"
    },
    {
      "key": "5V3E8HGT",
      "version": 41568,
      "itemType": "preprint",
      "title": "Semi-supervised conformal prediction with unlabeled nonconformity score",
      "abstractNote": "Conformal prediction (CP) is a powerful framework for uncertainty quantification, providing prediction sets with coverage guarantees when calibrated on sufficient labeled data. However, in real-world applications where labeled data is often limited, standard CP can lead to coverage deviation and output overly large prediction sets. In this paper, we extend CP to the semi-supervised setting and propose SemiCP, leveraging both labeled data and unlabeled data for calibration. Specifically, we introduce a novel nonconformity score function, NNM, designed for unlabeled data. This function selects labeled data with similar pseudo-label scores to estimate nonconformity scores, integrating them into the calibration process to overcome sample size limitations. We theoretically demonstrate that, under mild assumptions, SemiCP provide asymptotically coverage guarantee for prediction sets. Extensive experiments further validate that our approach effectively reduces instability and inefficiency under limited calibration data, can be adapted to conditional coverage settings, and integrates seamlessly with existing CP methods.",
      "date": "2025-05-27",
      "libraryCatalog": "arXiv.org",
      "url": "http://arxiv.org/abs/2505.21147",
      "accessDate": "2025-06-18T07:54:06Z",
      "extra": "arXiv:2505.21147 [cs]\nTLDR: This paper introduces a novel nonconformity score function, NNM, designed for unlabeled data, and theoretically demonstrates that, under mild assumptions, SemiCP provide asymptotically coverage guarantee for prediction sets.",
      "DOI": "10.48550/arXiv.2505.21147",
      "repository": "arXiv",
      "archiveID": "arXiv:2505.21147",
      "creators": [
        {
          "firstName": "Xuanning",
          "lastName": "Zhou",
          "creatorType": "author"
        },
        {
          "firstName": "Hao",
          "lastName": "Zeng",
          "creatorType": "author"
        },
        {
          "firstName": "Xiaobo",
          "lastName": "Xia",
          "creatorType": "author"
        },
        {
          "firstName": "Bingyi",
          "lastName": "Jing",
          "creatorType": "author"
        },
        {
          "firstName": "Hongxin",
          "lastName": "Wei",
          "creatorType": "author"
        }
      ],
      "tags": [],
      "relations": {},
      "inPublications": true,
      "dateAdded": "2025-06-18T07:54:06Z",
      "dateModified": "2025-08-13T02:04:59Z",
      "uri": "http://zotero.org/users/4752290/items/5V3E8HGT",
      "itemID": 5752,
      "attachments": [
        {
          "itemType": "attachment",
          "title": "2025_Zhou et al._Semi-Supervised Conformal Prediction With Unlabeled Nonconformity Score.pdf",
          "url": "http://arxiv.org/pdf/2505.21147v1",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-06-18T07:54:10Z",
          "dateModified": "2025-06-18T07:54:10Z",
          "uri": "http://zotero.org/users/4752290/items/822XR3IC",
          "path": "/Users/zengh/Zotero/storage/822XR3IC/2025_Zhou et al._Semi-Supervised Conformal Prediction With Unlabeled Nonconformity Score.pdf",
          "select": "zotero://select/library/items/822XR3IC"
        },
        {
          "itemType": "attachment",
          "title": "Snapshot",
          "url": "http://arxiv.org/abs/2505.21147",
          "tags": [],
          "relations": {},
          "dateAdded": "2025-06-18T07:54:54Z",
          "dateModified": "2025-06-18T07:54:54Z",
          "uri": "http://zotero.org/users/4752290/items/7W7JVJU3",
          "path": "/Users/zengh/Zotero/storage/7W7JVJU3/2505.html",
          "select": "zotero://select/library/items/7W7JVJU3"
        }
      ],
      "notes": [
        {
          "key": "XT5BZFF3",
          "version": 45236,
          "itemType": "note",
          "parentItem": "5V3E8HGT",
          "note": "<h2>AI 管家 - Semi-supervised conformal prediction with unlabeled nonconformity score</h2>\n<div><p>好的，这是对这篇文章的简洁易懂且数学化的中文总结。</p>\n<h3>0. 标题、作者及摘要</h3>\n<ul>\n<li><strong>标题 (Original Title):</strong> Semi-Supervised Conformal Prediction With Unlabeled Nonconformity Score</li>\n<li><strong>作者 (Authors):</strong> Xuanning Zhou¹,², Hao Zeng¹, Xiaobo Xia³, Bingyi Jing¹, Hongxin Wei¹†<ul>\n<li>¹南方科技大学 (Southern University of Science and Technology)</li>\n<li>²哈尔滨工业大学（深圳）(Harbin Institute of Technology, Shenzhen)</li>\n<li>³新加坡国立大学 (National University of Singapore)</li>\n</ul>\n</li>\n<li><strong>摘要总结 (Abstract Summary):</strong><ul>\n<li>传统的保形预测（Conformal Prediction, CP）在有足够多标注数据时能提供带有覆盖率保证的预测集。但在现实中，标注数据稀少会导致覆盖率不稳定且预测集过大。本文将保形预测扩展到半监督场景，提出了 SemiCP 框架，同时利用少量有标签数据和大量无标签数据进行校准。其核心是为无标签数据设计了一种新的不一致性分数函数 NNM (Nearest Neighbor Matching)。该函数通过为每个无标签样本匹配一个具有相似伪标签分数的有标签样本，并利用该有标签样本的“偏差”来修正无标签样本的不一致性分数。理论上证明了该方法能提供渐近的覆盖率保证。实验证明，SemiCP 能有效减少因校准数据稀少导致的不稳定性和低效率。</li>\n</ul>\n</li>\n<li><strong>贡献和创新总结:</strong><ul>\n<li>本文首次提出一个利用无标签数据来增强保形预测的框架（SemiCP），其核心创新是为无标签样本设计了一个名为 NNM 的不一致性分数估计方法，解决了在标注数据稀少场景下保形预测性能不佳的问题。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>1. 这篇文章的基本任务是什么？是在什么模型下设定的？（任务和模型）</h3>\n<ul>\n<li><strong>基本任务:</strong><ul>\n<li>任务是 <strong>保形预测 (Conformal Prediction, CP)</strong>，具体来说是多分类问题中的预测集构建。目标是对于一个输入样本 <span class=\"math\">$x$</span>，给出一个包含其真实标签 <span class=\"math\">$y$</span> 的集合 <span class=\"math\">$C(x)$</span>，并保证这个集合的 <strong>边际覆盖率 (marginal coverage)</strong> 不低于用户指定的水平 <span class=\"math\">$1-\\alpha$</span>，即 <span class=\"math\">$P(y \\in C(x)) \\ge 1-\\alpha$</span>。</li>\n</ul>\n</li>\n<li><strong>模型设定:</strong><ul>\n<li>设定在 <strong>半监督分裂式保形预测 (semi-supervised split conformal prediction)</strong> 框架下。</li>\n<li>该设定中，有一个预训练好的模型 <span class=\"math\">$f$</span>，一个规模很小、带标签的校准数据集 <span class=\"math\">$D_{\\text{labeled}} = \\{(\\boldsymbol{x}_i, y_i)\\}_{i=1}^n$</span>，以及一个规模较大、不带标签的数据集 <span class=\"math\">$D_{\\text{unlabeled}} = \\{\\tilde{\\boldsymbol{x}}_i\\}_{i=1}^N$</span>。</li>\n<li>核心挑战是：因为 <span class=\"math\">$n$</span> 很小，标准的保形预测方法会产生不稳定的覆盖率和过大的预测集。</li>\n</ul>\n</li>\n<li><strong>简单例子:</strong><ul>\n<li><strong>数据:</strong> 假设我们有一个图像分类任务，校准集里有 20 张带标签的图片（如“猫”、“狗”），还有 10000 张不带标签的图片。测试样本是一张新的图片。</li>\n<li><strong>任务:</strong> 我们希望生成一个标签集合，并有 95% 的把握（即 <span class=\"math\">$1-\\alpha = 0.95$</span>）确信这个集合里包含了这张新图片的真实标签。</li>\n<li><strong>标准 CP 的困境:</strong> 只用 20 张带标签的图片，计算出的阈值波动很大，可能导致最终的预测集非常大（例如 <code>{&#39;狗&#39;, &#39;狼&#39;, &#39;狐狸&#39;, &#39;郊狼&#39;}</code>），或者在不同次实验中覆盖率忽高忽低。</li>\n<li><strong>本文目标:</strong> 利用那 10000 张无标签图片的信息，来获得一个更稳定、更精确的阈值，从而生成更小、更可靠的预测集（例如 <code>{&#39;狗&#39;, &#39;狼&#39;}</code>）。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>2. 解决方法是什么？数学化地表达出来。（方法）</h3>\n<p>解决方法是提出 <strong>SemiCP</strong> 框架，其核心是利用有标签和无标签数据共同计算保形预测的阈值 <span class=\"math\">$\\hat{q}$</span>。关键在于如何为无标签数据估计一个可靠的 <strong>不一致性分数 (nonconformity score)</strong>。</p>\n<ol>\n<li><strong>半监督阈值计算:</strong><ul>\n<li>首先为 <span class=\"math\">$n$</span> 个有标签样本计算真实的不一致性分数 <span class=\"math\">$s_i = S(\\boldsymbol{x}_i, y_i)$</span>。</li>\n<li>然后为 <span class=\"math\">$N$</span> 个无标签样本估计不一致性分数 <span class=\"math\">$\\tilde{s}_i = \\tilde{S}(\\tilde{\\boldsymbol{x}}_i)$</span>。</li>\n<li>将两组分数合并，计算分位数作为最终阈值 <span class=\"math\">$\\hat{q}_{\\text{SemiCP}}$</span>：\n<pre class=\"math\">$$\n        \\hat{q}_{\\text{SemiCP}} = \\text{Quantile} \\left( \\{s_i\\}_{i=1}^n \\cup \\{\\tilde{s}_i\\}_{i=1}^N, \\frac{\\lceil(n+N+1)(1-\\alpha)\\rceil}{n+N} \\right)\n        $$</pre></li>\n</ul>\n</li>\n<li><strong>为无标签数据估计分数 (NNM 方法):</strong><ul>\n<li>直接使用模型的预测（伪标签 <span class=\"math\">$\\hat{y}_i$</span>）来计算分数 <span class=\"math\">$S(\\tilde{\\boldsymbol{x}}_i, \\hat{y}_i)$</span> 会产生系统性偏差，因为模型对其预测总是最“自信”的，导致分数偏低。</li>\n<li>本文定义了 <strong>伪偏差 (pseudo bias)</strong> 的概念。对于一个有标签样本 <span class=\"math\">$(\\boldsymbol{x}_j, y_j)$</span>，其伪偏差是真实分数与伪标签分数之差：\n<pre class=\"math\">$$\n        \\Delta(\\boldsymbol{x}_j) = S(\\boldsymbol{x}_j, y_j) - S(\\boldsymbol{x}_j, \\hat{y}_j)\n        $$</pre>\n这个偏差可以看作是对模型预测错误的一种“修正量”。</li>\n<li><strong>最近邻匹配 (Nearest Neighbor Matching, NNM)</strong> 的核心思想是：对于一个无标签样本 <span class=\"math\">$\\tilde{\\boldsymbol{x}}_i$</span>，在有标签数据中找到一个在“伪标签分数”上最接近它的样本 <span class=\"math\">$\\boldsymbol{x}_j$</span>，然后用 <span class=\"math\">$\\boldsymbol{x}_j$</span> 的伪偏差来修正 <span class=\"math\">$\\tilde{\\boldsymbol{x}}_i$</span> 的分数。<ul>\n<li><strong>第一步：找到最近邻</strong>。这个“近”不是在特征空间，而是在伪标签分数空间：\n<pre class=\"math\">$$\n            j = \\arg \\min_{k \\in \\{1,\\dots,n\\}} |S(\\tilde{\\boldsymbol{x}}_i, \\hat{y}_i) - S(\\boldsymbol{x}_k, \\hat{y}_k)|\n            $$</pre></li>\n<li><strong>第二步：计算 NNM 分数</strong>。用找到的邻居的偏差来修正无标签样本的伪标签分数：\n<pre class=\"math\">$$\n            \\tilde{S}_{nnm}(\\tilde{\\boldsymbol{x}}_i) = S(\\tilde{\\boldsymbol{x}}_i, \\hat{y}_i) + \\Delta(\\boldsymbol{x}_j) = S(\\tilde{\\boldsymbol{x}}_i, \\hat{y}_i) + [S(\\boldsymbol{x}_j, y_j) - S(\\boldsymbol{x}_j, \\hat{y}_j)]\n            $$</pre></li>\n</ul>\n</li>\n<li>最终，用这个 <span class=\"math\">$\\tilde{S}_{nnm}(\\tilde{\\boldsymbol{x}}_i)$</span> 作为无标签样本的估计分数 <span class=\"math\">$\\tilde{s}_i$</span>。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3>3. 为什么这个方法是有效果的？其理论保证是什么？（理论）</h3>\n<ul>\n<li><strong>有效性原理:</strong><ul>\n<li>该方法之所以有效，是因为它巧妙地利用了大量无标签数据来“扩充”校准集，使得计算出的分位数阈值 <span class=\"math\">$\\hat{q}_{\\text{SemiCP}}$</span> 更加稳定和准确，从而减小了预测集的方差和大小。NNM 方法通过匹配相似的样本来估计偏差，比全局平均偏差修正或随机修正更具适应性和准确性。</li>\n</ul>\n</li>\n<li><strong>理论保证:</strong><ul>\n<li>本文提供了两个关键的理论命题来保证其有效性。</li>\n<li><strong>命题 1 (Proposition 1):</strong> 如果我们为无标签样本估计的不一致性分数 <span class=\"math\">$\\tilde{S}(\\tilde{\\boldsymbol{x}})$</span> 的分布与它们真实的（但未知的）不一致性分数 <span class=\"math\">$S(\\tilde{\\boldsymbol{x}}, \\tilde{y})$</span> 的分布完全相同，那么 SemiCP 框架就能提供有效的边际覆盖率保证。即，若分数 <span class=\"math\">$\\tilde{s}_i$</span> 和 <span class=\"math\">$s_i$</span> 的累积分布函数 (CDF) 相同 (<span class=\"math\">$F_{\\tilde{s}}(t) = F_s(t)$</span>)，则：\n<pre class=\"math\">$$\n        \\text{Pr}(y_{\\text{test}} \\in C_{\\text{SemiCP}}(\\boldsymbol{x}_{\\text{test}})) \\ge 1-\\alpha\n        $$</pre></li>\n<li><strong>命题 2 (Proposition 2) (主要理论贡献):</strong> 本文证明了其提出的 NNM 分数估计方法在温和的假设下，是<strong>渐近一致</strong>的。也就是说，当有标签校准集的大小 <span class=\"math\">$n \\to \\infty$</span> 时，通过 NNM 方法估计出的分数分布会收敛于真实分数的分布。令 <span class=\"math\">$F_{nnm}$</span> 为 NNM 分数的 CDF，<span class=\"math\">$F_S$</span> 为真实分数的 CDF，则：\n<pre class=\"math\">$$\n        F_{nnm}(t) \\to F_S(t), \\quad \\forall t \\in \\mathbb{R} \\quad \\text{as } n \\to \\infty\n        $$</pre>\n这个命题为 NNM 方法的合理性提供了坚实的理论基础，保证了 SemiCP 框架在有标签数据逐渐增多时，其覆盖率是可靠的。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>4. 使用了什么算法？数学化地表达出来。（算法）</h3>\n<p>本文的核心算法是 <strong>SemiCP 算法</strong> (在附录 Algorithm 1 中给出)。\n<strong>算法：SemiCP (Semi-supervised Conformal Prediction)</strong></p>\n<ul>\n<li><strong>输入:</strong><ul>\n<li>有标签校准集 <span class=\"math\">$D_{\\text{labeled}} = \\{(\\boldsymbol{x}_i, y_i)\\}_{i=1}^n$</span></li>\n<li>无标签校准集 <span class=\"math\">$D_{\\text{unlabeled}} = \\{\\tilde{\\boldsymbol{x}}_i\\}_{i=1}^N$</span></li>\n<li>不一致性分数函数 <span class=\"math\">$S(\\cdot, \\cdot)$</span></li>\n<li>预训练模型 <span class=\"math\">$f(\\cdot)$</span></li>\n<li>错误率 <span class=\"math\">$\\alpha$</span></li>\n<li>测试样本 <span class=\"math\">$\\boldsymbol{x}_{\\text{test}}$</span></li>\n</ul>\n</li>\n<li><strong>流程:</strong><ol>\n<li><strong>计算有标签分数:</strong> 对所有 <span class=\"math\">$i \\in \\{1,...,n\\}$</span>，计算 <span class=\"math\">$s_i = S(\\boldsymbol{x}_i, y_i)$</span>。</li>\n<li><strong>估计无标签分数:</strong> 对所有 <span class=\"math\">$i \\in \\{1,...,N\\}$</span>，执行以下操作来计算 <span class=\"math\">$\\tilde{s}_i$</span>:\na.   获取伪标签 <span class=\"math\">$\\hat{y}_i = \\arg\\max_{y \\in \\mathcal{Y}} f_y(\\tilde{\\boldsymbol{x}}_i)$</span>。\nb.   计算该无标签样本的伪标签分数 <span class=\"math\">$S(\\tilde{\\boldsymbol{x}}_i, \\hat{y}_i)$</span>。\nc.   找到其最近邻的有标签样本 <span class=\"math\">$\\boldsymbol{x}_j$</span>：\n <pre class=\"math\">$<span class=\"math\">$j = \\arg \\min_{k \\in \\{1,...,n\\}} |S(\\tilde{\\boldsymbol{x}}_i, \\hat{y}_i) - S(\\boldsymbol{x}_k, \\hat{y}_k)|$</span>$</pre>\nd.   计算其 NNM 估计分数：\n <pre class=\"math\">$<span class=\"math\">$\\tilde{s}_i = S(\\tilde{\\boldsymbol{x}}_i, \\hat{y}_i) + [S(\\boldsymbol{x}_j, y_j) - S(\\boldsymbol{x}_j, \\hat{y}_j)]$</span>$</pre></li>\n<li><strong>计算阈值:</strong> 合并所有分数，并计算分位数：\n<pre class=\"math\">$<span class=\"math\">$\\hat{q}_{\\text{SemiCP}} = \\text{Quantile} \\left( \\{s_i\\}_{i=1}^n \\cup \\{\\tilde{s}_i\\}_{i=1}^N, \\frac{\\lceil(n+N+1)(1-\\alpha)\\rceil}{n+N} \\right)$</span>$</pre></li>\n<li><strong>构建预测集:</strong>\n<pre class=\"math\">$<span class=\"math\">$C(\\boldsymbol{x}_{\\text{test}}) = \\{ y \\in \\mathcal{Y} \\mid S(\\boldsymbol{x}_{\\text{test}}, y) \\le \\hat{q}_{\\text{SemiCP}} \\}$</span>$</pre></li>\n</ol>\n</li>\n<li><strong>输出:</strong> 预测集 <span class=\"math\">$C(\\boldsymbol{x}_{\\text{test}})$</span>。</li>\n</ul>\n<hr>\n<h3>5. 实验是如何设计的？用简单易懂的语言描述实验设计和结果。（实验）</h3>\n<ul>\n<li><strong>实验设计:</strong><ul>\n<li><strong>对比方法:</strong><ol>\n<li><code>Standard</code>: 标准的分裂式保形预测，只使用少量有标签数据。这是基线。</li>\n<li><code>SemiCP</code>: 本文提出的方法，使用少量有标签数据和大量无标签数据。</li>\n<li><code>Oracle</code>: 理想情况下的上限，假设所有无标签数据都带标签，然后用全部数据做标准保形预测。</li>\n</ol>\n</li>\n<li><strong>数据集和模型:</strong> 在 CIFAR-10、CIFAR-100 和 ImageNet 这三个标准的图像分类数据集上进行实验。主要使用 ResNet50 模型，同时也测试了其他 9 种不同架构的模型以验证通用性。</li>\n<li><strong>评估指标:</strong><ol>\n<li><strong>覆盖率差距 (Coverage Gap):</strong> 实际覆盖率与目标覆盖率 <span class=\"math\">$1-\\alpha$</span> 之间的平均绝对差距。值越小，说明覆盖率越稳定，越接近目标。</li>\n<li><strong>平均集合大小 (Average Set Size):</strong> 预测集包含的平均标签数量。值越小，说明预测越精确、效率越高。</li>\n</ol>\n</li>\n<li><strong>核心变量:</strong> 实验系统地改变了有标签数据的数量（从10到100）和无标签数据的数量，来观察 SemiCP 的性能表现。</li>\n</ul>\n</li>\n<li><strong>实验结果 (具体且易懂):</strong><ol>\n<li><strong>显著提升稳定性和效率:</strong> 结果显示，与仅使用少量有标签数据的 <code>Standard</code> 方法相比，<code>SemiCP</code> 的 <strong>Coverage Gap</strong> 大幅降低，同时 <strong>Average Set Size</strong> 也更小。例如，在 CIFAR-10 数据集上，当只有 20 个有标签样本时，SemiCP 将覆盖率差距缩小了 76%，预测集大小减小了 7%。这说明 SemiCP 确实更稳定、更有效率。</li>\n<li><strong>无标签数据越多越好:</strong> 实验表明，增加无标签数据的数量可以持续地降低 Coverage Gap 和 Average Set Size。即使只加入很少的无标签数据（比如10个），也能带来明显的性能提升，证明了该方法的鲁棒性和数据效率。</li>\n<li><strong>通用性强:</strong><ul>\n<li><strong>模型无关:</strong> 在 ResNet、ViT、EfficientNet 等 10 种不同的模型架构上，SemiCP 都稳定地优于 Standard 方法。</li>\n<li><strong>方法兼容:</strong> SemiCP 不仅能用于保证边际覆盖率，还能无缝扩展到需要保证<strong>条件覆盖率</strong>（例如按类别或按组）的场景，并且可以和其他改进CP的方法（如 ClusterCP）结合使用，进一步提升性能。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n</div>",
          "tags": [
            {
              "tag": "AI-Generated"
            }
          ],
          "relations": {},
          "dateAdded": "2025-11-05T23:42:54Z",
          "dateModified": "2025-11-05T23:42:54Z",
          "uri": "http://zotero.org/users/4752290/items/XT5BZFF3"
        }
      ],
      "citationKey": "zhou2025semisupervised",
      "itemKey": "5V3E8HGT",
      "libraryID": 1,
      "select": "zotero://select/library/items/5V3E8HGT"
    }
  ]
}