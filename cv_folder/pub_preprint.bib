@article{chen2021match,
  title = {Match of the Bimaxillary Basal Bone Arches and Its Variations among Individuals},
  year = 2021,
  journal = {Scanning},
  volume = {2021},
  pages = {9625893},
  urldate = {2024-12-19},
  abstract = {Introduction. This study is aimed at illustrating the bimaxillary basal bone contours, to clarify the match of the basal bone arches of the upper and lower, especially the posterior segments, including the second molar and retromolar region. Methods. Based on 100 cone-beam computed tomography (CBCT) images (50 males and 50 females), we obtained 100 pairs of basal bone arches, which were the horizontal inner cortex contours passing the furcation of the first molar paralleled to the lower occlusal plane. The Generalized Procrustes Analysis (GPA) was applied to depict average contours and calculate the ratio and difference width of both upper and lower dental arches in different positions. Variations of the basal bone morphology among individuals were revealed using Principal Component Analysis (PCA). Results. The width discrepancy occurred at 7-7 segment (male: upper 65.62 mm and lower 68.81 mm and female: upper 62.98 mm and lower 68.38 mm) and the retromolar region (male: upper 64.67 mm and lower 71.96 mm and female: upper 62.34 mm and lower 71.44 mm). The ratio (p = 0.006) and difference value (p = 0.009) of 7-7 segment and the ratio of retromolar region (p = 0.044) differed in genders. Setting 2 mm overjet, the upper basal bone arch was wider than the lower by approximate 2 mm on both sides, except the second molar and retromolar region. According to PCA, the variation of basal bone arches appeared mainly at terminal segments. Conclusions. For both male and female, the bimaxillary basal bone matched except terminal segments. Mismatch of female bimaxillary posterior basal bone was more pronounced than male. The basal bone arches of male were wider and longer than that of female.},
  copyright = {Copyright \copyright{} 2021 Wenqian Chen et al.},
  language = {en},
  author = {Chen and Zeng and Sun and Xu and Chen and Sun and et al.}
}

@article{chen2022structural,
  title = {A Structural Equation Modeling Approach to Determine the Correlation between the Vertical and Sagittal Skeletal Patterns and Posterior Basal Bones Mismatching in Patients with Skeletal {{Class III}} Malocclusion},
  year = 2022,
  journal = {American Journal of Orthodontics and Dentofacial Orthopedics},
  volume = {162},
  pages = {e277-e294},
  urldate = {2024-12-15},
  abstract = {Introduction: Matching the maxillomandibular basal bone width is essential to the stability of orthodontic treatment. We aimed to determine the relationship between basal bone width mismatching and the vertical and sagittal skeletal pattern in patients with skeletal Class III malocclusion through shape analysis and structural equation modeling (SEM). Methods: Cone-beam computed tomography images were collected from 45 men and 51 women. Width mismatching of the basal bone was determined using generalized Procrustes analysis. Twenty-two parameters from the synthesized cephalogram were measured, followed by factor analysis and SEM. Results: Mismatch occurred at the second molar (men, 4.29 6 4.32 mm; women, 5.55 6 4.43 mm) and retromolar regions (men, 8.49 6 5.11 mm; women: 8.93 6 5.25 mm). The sum of angles had the largest loading for vertical-1 (extracted from 18 vertical cephalometric measurements) (men, 0.9477; women, 0.9489), followed by MP-SN angle (0.9408) in men and N-Me/S-Go (0.9342) in women. Wits appraisal and anteroposterior dysplasia indicator were largest for Sagittal-1. SEM showed a positive effect of male vertical-1 and 2 on width difference in the retromolar region (P \textbackslash 0.001; B .0). Female vertical-1 had a significant positive effect on DW7 (P \textbackslash 0.001; B 5 5.535) and DWR (P 5 0.016; B 5 3.427) as vertical-2. Sagittal-1 showed a negative correlation with DW7 in both genders (P \textbackslash 0.05; B \textbackslash 0) and with DWR in men. Conclusions: Basal bone width mismatching occurred at the second molar and retromolar regions, especially in low-angle and patients with severe skeletal Class III malocclusion.},
  language = {en},
  author = {Chen and Zeng and Wang and Xu and Liu and Zhang and et al.}
}

@article{gao2025exploring,
  title = {Exploring Imbalanced Annotations for Effective In-Context Learning},
  author = {Gao, Hongfu and Zhang, Feipeng and Zeng, Hao and Meng, Deyu and Jing, Bingyi and Wei, Hongxin},
  year = 2025,
  eprint = {2502.04037},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2025-05-23},
  abstract = {Large language models (LLMs) have shown impressive performance on downstream tasks through in-context learning (ICL), which heavily relies on the demonstrations selected from annotated datasets. Existing selection methods may hinge on the distribution of annotated datasets, which can often be long-tailed in real-world scenarios. In this work, we show that imbalanced class distributions in annotated datasets significantly degrade the performance of ICL across various tasks and selection methods. Moreover, traditional rebalance methods fail to ameliorate the issue of class imbalance in ICL. Our method is motivated by decomposing the distributional differences between annotated and test datasets into two-component weights: class-wise weights and conditional bias. The key idea behind our method is to estimate the conditional bias by minimizing the empirical error on a balanced validation dataset and to employ the two-component weights to modify the original scoring functions during selection. Our approach can prevent selecting too many demonstrations from a single class while preserving the effectiveness of the original selection methods. Extensive experiments demonstrate the effectiveness of our method, improving the average accuracy by up to 5.46 on common benchmarks with imbalanced datasets.},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2502.04037}
}

@article{huang2025selective,
  title = {Selective {{Labeling}} with {{False Discovery Rate Control}}},
  author = {Huang, Huipeng and Liao, Wenbo and Xi, Huajun and Zeng, Hao and Zhao, Mengchen and Wei, Hongxin},
  year = 2025,
  eprint = {2510.14581},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2025-10-27},
  abstract = {Obtaining high-quality labels for large datasets is expensive, requiring massive annotations from human experts. While AI models offer a cost-effective alternative by predicting labels, their label quality is compromised by the unavoidable labeling errors. Existing methods mitigate this issue through selective labeling, where AI labels a subset and human labels the remainder. However, these methods lack theoretical guarantees on the quality of AI-assigned labels, often resulting in unacceptably high labeling error within the AI-labeled subset. To address this, we introduce \textbackslash textbf\textbraceleft Conformal Labeling\textbraceright, a novel method to identify instances where AI predictions can be provably trusted. This is achieved by controlling the false discovery rate (FDR), the proportion of incorrect labels within the selected subset. In particular, we construct a conformal \$p\$-value for each test instance by comparing AI models' predicted confidence to those of calibration instances mislabeled by AI models. Then, we select test instances whose \$p\$-values are below a data-dependent threshold, certifying AI models' predictions as trustworthy. We provide theoretical guarantees that Conformal Labeling controls the FDR below the nominal level, ensuring that a predefined fraction of AI-assigned labels is correct on average. Extensive experiments demonstrate that our method achieves tight FDR control with high power across various tasks, including image and text labeling, and LLM QA.},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2510.14581}
}

@inproceedings{liu2025cadapter,
  title = {C-Adapter: {{Adapting}} Deep Classifiers for Efficient Conformal Prediction Sets},
  booktitle = {28th {{European Conference}} on {{Artificial Intelligence}}},
  author = {Liu, Kangdao and Zeng, Hao and Huang, Jianguo and Zhuang, Huiping and Vong, Chi Man and Wei, Hongxin},
  year = 2025,
  urldate = {2025-02-05},
  abstract = {Conformal prediction, as an emerging uncertainty quantification technique, typically functions as post-hoc processing for the outputs of trained classifiers. To optimize the classifier for maximum predictive efficiency, Conformal Training rectifies the training objective with a regularization that minimizes the average prediction set size at a specific error rate. However, the regularization term inevitably deteriorates the classification accuracy and leads to suboptimal efficiency of conformal predictors. To address this issue, we introduce \textbackslash textbf\textbraceleft Conformal Adapter\textbraceright{} (C-Adapter), an adapter-based tuning method to enhance the efficiency of conformal predictors without sacrificing accuracy. In particular, we implement the adapter as a class of intra order-preserving functions and tune it with our proposed loss that maximizes the discriminability of non-conformity scores between correctly and randomly matched data-label pairs. Using C-Adapter, the model tends to produce extremely high non-conformity scores for incorrect labels, thereby enhancing the efficiency of prediction sets across different coverage rates. Extensive experiments demonstrate that C-Adapter can effectively adapt various classifiers for efficient prediction sets, as well as enhance the conformal training method.},
  language = {en}
}

@article{liu2025highpower,
  title = {High-{{Power Training Data Identification}} with {{Provable Statistical Guarantees}}},
  author = {Liu, Zhenlong and Zeng, Hao and Huang, Weiran and Wei, Hongxin},
  year = 2025,
  eprint = {2510.09717},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2025-10-27},
  abstract = {Identifying training data within large-scale models is critical for copyright litigation, privacy auditing, and ensuring fair evaluation. The conventional approaches treat it as a simple binary classification task without statistical guarantees. A recent approach is designed to control the false discovery rate (FDR), but its guarantees rely on strong, easily violated assumptions. In this paper, we introduce Provable Training Data Identification (PTDI), a rigorous method that identifies a set of training data with strict false discovery rate (FDR) control. Specifically, our method computes p-values for each data point using a set of known unseen data, and then constructs a conservative estimator for the data usage proportion of the test set, which allows us to scale these p-values. Our approach then selects the final set of training data by identifying all points whose scaled p-values fall below a data-dependent threshold. This entire procedure enables the discovery of training data with provable, strict FDR control and significantly boosted power. Extensive experiments across a wide range of models (LLMs and VLMs), and datasets demonstrate that PTDI strictly controls the FDR and achieves higher power.},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2510.09717}
}

@article{liu2025spatialaware,
  title = {Spatial-Aware Conformal Prediction for Trustworthy Hyperspectral Image Classification},
  author = {Liu, Kangdao and Sun, Tianhao and Zeng, Hao and Zhang, Yongshan and Pun, Chi-Man and Vong, Chi-Man},
  year = 2025,
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {35},
  pages = {8754--8766},
  publisher = {IEEE},
  urldate = {2025-09-24},
  abstract = {Hyperspectral image (HSI) classification involves assigning unique labels to each pixel to identify various land cover categories. While deep classifiers have achieved high predictive accuracy in this field, they lack the ability to rigorously quantify confidence in their predictions. This limitation restricts their application in critical contexts where the cost of prediction errors is significant, as quantifying the uncertainty of model predictions is crucial for the safe deployment of predictive models. To address this limitation, a rigorous theoretical proof is presented first, which demonstrates the validity of Conformal Prediction, an emerging uncertainty quantification technique, in the context of HSI classification. Building on this foundation, a conformal procedure is designed to equip any pre-trained HSI classifier with trustworthy prediction sets, ensuring that the true labels are included with a user-defined probability (e.g., 95\%). Furthermore, a novel framework of Conformal Prediction specifically designed for HSI data, called Spatial-Aware Conformal Prediction ( SACP ), is proposed. This framework integrates essential spatial information of HSI by aggregating the non-conformity scores of pixels with high spatial correlation, effectively improving the statistical efficiency of prediction sets. Both theoretical and empirical results validate the effectiveness of the proposed approaches. The source code is available at https://github.com/J4ckLiu/SACP},
  language = {en-US}
}

@misc{wan2023mtaft,
  title = {{{MTAFT}}: Data-Driven Estimation for Multi-Threshold Accelerate Failure Time Model},
  author = {Wan, Chuang and Zeng, Hao and Zhong, Wei and Zou, Changliang},
  year = 2023,
  urldate = {2024-08-06},
  abstract = {Developed a data-driven estimation framework for the multi-threshold accelerate failure time (MTAFT) model. The MTAFT model features different linear forms in different subdomains, and one of the major challenges is determining the number of threshold effects. The package introduces a data-driven approach that utilizes a Schwarz' information criterion, which demonstrates consistency under mild conditions. Additionally, a cross-validation (CV) criterion with an order-preserved sample-splitting scheme is proposed to achieve consistent estimation, without the need for additional parameters. The package establishes the asymptotic properties of the parameter estimates and includes an efficient score-type test to examine the existence of threshold effects. The methodologies are supported by numerical experiments and theoretical results, showcasing their reliable performance in finite-sample cases.},
  copyright = {GPL-3}
}

@article{wan2024datadriven,
  title = {Data-driven Estimation for Multithreshold Accelerated Failure Time Model},
  author = {Wan, Chuang and Zeng, Hao and Zhang, Wenyang and Zhong, Wei and Zou, Changliang},
  year = 2024,
  journal = {Scandinavian Journal of Statistics},
  pages = {sjos.12758},
  urldate = {2024-12-19},
  abstract = {Abstract             This article develops a novel estimation framework for the multithreshold accelerated failure time model, which has distinct linear forms within different subdomains. One major challenge is to determine the number of threshold effects. We first show the selection consistency of a modified Bayesian information criterion under mild conditions. It is useful sometimes but heavily depends on the penalization magnitude, which usually varies from the model configuration and data distribution. To address this issue, we leverage a cross-validation criterion alongside an order-preserved sample-splitting scheme to yield a consistent estimation. The new criterion is completely data driven without additional parameters and thus robust to model setting and data distributions. The asymptotic properties for the parameter estimates are also carefully established. Additionally, we propose an efficient score-type test to examine the existence of threshold effects. The new statistic is free of estimating any potential threshold effects and is thus suitable for multithreshold scenarios. Numerical experiments validate the reliable finite-sample performance of our methodologies, which corroborates the theoretical results.},
  language = {en}
}

@inproceedings{xi2025exploring,
  ids = {32ee173d-fa6b-47a0-8f10-f9af18ce6d1d},
  title = {Exploring the Noise Robustness of Online Conformal Prediction},
  booktitle = {The {{Thirty-ninth Annual Conference}} on {{Neural Information Processing Systems}}},
  author = {Xi, HuaJun and Liu, Kangdao and Zeng, Hao and Sun, Wenguang and Wei, Hongxin},
  year = 2025,
  eprint = {2501.18363},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2025-10-14},
  abstract = {Conformal prediction is an emerging technique for uncertainty quantification that constructs prediction sets guaranteed to contain the true label with a predefined probability. Recent work develops online conformal prediction methods that adaptively construct prediction sets to accommodate distribution shifts. However, existing algorithms typically assume *perfect label accuracy* which rarely holds in practice. In this work, we investigate the robustness of online conformal prediction under uniform label noise with a known noise rate. We show that label noise causes a persistent gap between the actual mis-coverage rate and the desired rate \$\textbackslash alpha\$, leading to either overestimated or underestimated coverage guarantees. To address this issue, we propose a novel loss function *robust pinball loss*, which provides an unbiased estimate of clean pinball loss without requiring ground-truth labels. Theoretically, we demonstrate that robust pinball loss enables online conformal prediction to eliminate the coverage gap under uniform label noise, achieving a convergence rate of \$\textbackslash mathcal\textbraceleft O\textbraceright (T\textasciicircum\textbraceleft -1/2\textbraceright )\$ for both empirical and expected coverage errors (i.e., absolute deviation of the empirical and expected mis-coverage rate from the target level \$\textbackslash alpha\$). This loss offers a general solution to the uniform label noise, and is complementary to existing online conformal prediction methods. Extensive experiments demonstrate that the proposed loss enhances the noise robustness of various online conformal prediction methods by achieving a precise coverage guarantee.},
  archiveprefix = {arXiv},
  language = {en}
}

@article{zeng2024robust,
  title = {Robust Integrative Analysis via Quantile Regression with Homogeneity and Sparsity},
  author = {Zeng, Hao and Wan, Chuang and Zhong, Wei and Liu, Tuo},
  year = 2024,
  journal = {Journal of Statistical Planning and Inference},
  volume = {234},
  pages = {106196},
  urldate = {2024-07-29},
  abstract = {Integrative analysis plays a critical role in integrating heterogeneous data from multiple datasets to provide a comprehensive view of the overall data features. However, in multiple datasets, outliers and heavy-tailed data can render least squares estimation unreliable. In response, we propose a Robust Integrative Analysis via Quantile Regression (RIAQ) that accounts for homogeneity and sparsity in multiple datasets. The RIAQ approach is not only able to identify latent homogeneous coefficient structures but also recover the sparsity of high-dimensional covariates via double penalty terms. The integration of sample information across multiple datasets improves estimation efficiency, while a sparse model improves model interpretability. Furthermore, quantile regression allows the detection of subgroup structures under different quantile levels, providing a comprehensive picture of the relationship between response and high-dimensional covariates. We develop an efficient alternating direction method of multipliers (ADMM) algorithm to solve the optimization problem and study its convergence. We also derive the parameter selection consistency of the modified Bayesian information criterion. Numerical studies demonstrate that our proposed estimator has satisfactory finite-sample performance, especially in heavy-tailed cases.},
  language = {en-US}
}

@article{zeng2024transfer,
  title = {Transfer Learning for Spatial Autoregressive Models with Application to {{U}}.{{S}}. Presidential Election Prediction},
  author = {Zeng, Hao and Zhong, Wei and Xu, Xingbai},
  year = 2024,
  eprint = {2405.15600},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2024-12-19},
  abstract = {It is important to incorporate spatial geographic information into U.S. presidential election analysis, especially for swing states. The state-level analysis also faces significant challenges of limited spatial data availability. To address the challenges of spatial dependence and small sample sizes in predicting U.S. presidential election results using spatially dependent data, we propose a novel transfer learning framework within the SAR model, called as tranSAR. Classical SAR model estimation often loses accuracy with small target data samples. Our framework enhances estimation and prediction by leveraging information from similar source data. We introduce a two-stage algorithm, consisting of a transferring stage and a debiasing stage, to estimate parameters and establish theoretical convergence rates for the estimators. Additionally, if the informative source data are unknown, we propose a transferable source detection algorithm using spatial residual bootstrap to maintain spatial dependence and derive its detection consistency. Simulation studies show our algorithm substantially improves the classical two-stage least squares estimator. We demonstrate our method's effectiveness in predicting outcomes in U.S. presidential swing states, where it outperforms traditional methods. In addition, our tranSAR model predicts that the Democratic party will win the 2024 U.S. presidential election.},
  archiveprefix = {arXiv},
  language = {en-US},
  journal = {arXiv preprint arXiv:2405.15600}
}

@article{zeng2025pac,
  title = {{{PAC}} Reasoning: Controlling the Performance Loss for Efficient Reasoning},
  author = {Zeng, Hao and Huang, Jianguo and Jing, Bingyi and Wei, Hongxin and An, Bo},
  year = 2025,
  eprint = {2510.09133},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2025-10-13},
  abstract = {Large reasoning models (LRMs) have achieved remarkable progress in complex problem-solving tasks. Despite this success, LRMs typically suffer from high computational costs during deployment, highlighting a need for efficient inference. A popular direction of efficiency improvement is to switch the LRM between thinking and nonthinking modes dynamically. However, such approaches often introduce additional reasoning errors and lack statistical guarantees for the performance loss, which are critical for high-stakes applications. In this work, we propose Probably Approximately Correct (PAC) reasoning that controls the performance loss under the user-specified performance loss tolerance. In particular, we construct an upper confidence bound on the performance loss, formulated as a monotone function of the uncertainty score, and subsequently determine a threshold for switching to the nonthinking model. Theoretically, using the threshold to switch between the thinking and nonthinking modes ensures bounded performance loss in a distribution-free manner. Our comprehensive experiments on reasoning benchmarks show that the proposed method can save computational budgets and control the user-specified performance loss.},
  archiveprefix = {arXiv},
  language = {en-US},
  journal = {arXiv preprint arXiv:2510.09133}
}

@inproceedings{zeng2025parametric,
  title = {Parametric Scaling Law of Tuning Bias in Conformal Prediction},
  booktitle = {Forty-Second {{International Conference}} on {{Machine Learning}}},
  author = {Zeng, Hao and Liu, Kangdao and Jing, Bingyi and Wei, Hongxin},
  year = 2025,
  urldate = {2025-07-22},
  abstract = {Conformal prediction is a popular framework of uncertainty quantification that constructs prediction sets with coverage guarantees. To uphold the exchangeability assumption, many conformal prediction methods necessitate an additional hold-out set for parameter tuning. Yet, the impact of violating this principle on coverage remains underexplored, making it ambiguous in practical applications. In this work, we empirically find that the tuning bias - the coverage gap introduced by leveraging the same dataset for tuning and calibration, is negligible for simple parameter tuning in many conformal prediction methods. In particular, we observe the scaling law of the tuning bias: this bias increases with parameter space complexity and decreases with calibration set size. Formally, we establish a theoretical framework to quantify the tuning bias and provide rigorous proof for the scaling law of the tuning bias by deriving its upper bound. In the end, we discuss how to reduce the tuning bias, guided by the theories we developed.},
  language = {en}
}

@article{zhou2025semisupervised,
  title = {Semi-Supervised Conformal Prediction with Unlabeled Nonconformity Score},
  author = {Zhou, Xuanning and Zeng, Hao and Xia, Xiaobo and Jing, Bingyi and Wei, Hongxin},
  year = 2025,
  eprint = {2505.21147},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2025-06-18},
  abstract = {Conformal prediction (CP) is a powerful framework for uncertainty quantification, providing prediction sets with coverage guarantees when calibrated on sufficient labeled data. However, in real-world applications where labeled data is often limited, standard CP can lead to coverage deviation and output overly large prediction sets. In this paper, we extend CP to the semi-supervised setting and propose SemiCP, leveraging both labeled data and unlabeled data for calibration. Specifically, we introduce a novel nonconformity score function, NNM, designed for unlabeled data. This function selects labeled data with similar pseudo-label scores to estimate nonconformity scores, integrating them into the calibration process to overcome sample size limitations. We theoretically demonstrate that, under mild assumptions, SemiCP provide asymptotically coverage guarantee for prediction sets. Extensive experiments further validate that our approach effectively reduces instability and inefficiency under limited calibration data, can be adapted to conditional coverage settings, and integrates seamlessly with existing CP methods.},
  archiveprefix = {arXiv},
  journal = {arXiv preprint arXiv:2505.21147}
}
